<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>1.跟着NCS学作图：R语言UpSetR展示不同数据组交集</title>
      <link href="/2022-06-21-1-gen-zhao-ncs-xue-zuo-tu-r-yu-yan-upsetr-zhan-shi-bu-tong-shu-ju-zu-jiao-ji/"/>
      <url>/2022-06-21-1-gen-zhao-ncs-xue-zuo-tu-r-yu-yan-upsetr-zhan-shi-bu-tong-shu-ju-zu-jiao-ji/</url>
      
        <content type="html"><![CDATA[<font face="times new roman" size=3><span id="more"></span><p><strong>1.跟着NCS学作图：R语言UpSetR展示不同数据组交集</strong></p><!-- toc --><hr><h2 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h2><p><strong>Title:</strong> A highly conserved core bacterial microbiota with nitrogen-fixation capacity inhabits the xylem sap in maize plants. <strong><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9187771/">Nat Commun. 2022 Jun 11;13(1):3361</a></strong>.</p><h2 id="拟复现Figure"><a href="#拟复现Figure" class="headerlink" title="拟复现Figure"></a>拟复现Figure</h2><img src="/2022-06-21-1-gen-zhao-ncs-xue-zuo-tu-r-yu-yan-upsetr-zhan-shi-bu-tong-shu-ju-zu-jiao-ji/Figure2.jpg" class=""><h2 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h2><img src="/2022-06-21-1-gen-zhao-ncs-xue-zuo-tu-r-yu-yan-upsetr-zhan-shi-bu-tong-shu-ju-zu-jiao-ji/data_info.png" class=""><ul><li>第一列为基因名字</li><li>后面每一列分别为各数据分组</li></ul><h2 id="R代码-UpSetR"><a href="#R代码-UpSetR" class="headerlink" title="R代码-UpSetR"></a>R代码-<strong>UpSetR</strong></h2><pre class="line-numbers language-&#123;r"><code class="language-&#123;r">library(UpSetR) #R 3.5otu_RA <- read.delim('otu_RA.txt', header = TRUE, row.names = 1, sep = '\t')otu_RA[otu_RA > 0] <- 1p <- upset(otu_RA,   nset = 7,   nintersects = 10,   order.by = c('degree','freq'),   decreasing = c(TRUE, TRUE),  mb.ratio = c(0.7, 0.3),  point.size = 1.8,  line.size = 1,  mainbar.y.label = "Intersection size",   sets.x.label = "Set Size",   main.bar.color = "#2a83a2",   sets.bar.color = "#3b7960",  queries = list(list(query = intersects, params = list("BS","RS","RE","VE","SE","LE","P"), active = T,color="#d66a35", query.name = "BS vs RS vs RE vs VE vs SE vs LE vs P")))pselect_otu <- rownames(otu_RA[rowSums(otu_RA[1:7]) == 7, ])otu_select <- otu_RA[select_otu, ]write.table(as.matrix(otu_select),"otu_overlap.txt",sep = '\t',quote = FALSE,col.names = NA)dev.off()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="最终UpSetR图"><a href="#最终UpSetR图" class="headerlink" title="最终UpSetR图"></a>最终UpSetR图</h2><img src="/2022-06-21-1-gen-zhao-ncs-xue-zuo-tu-r-yu-yan-upsetr-zhan-shi-bu-tong-shu-ju-zu-jiao-ji/UpSetR.png" class=""><p>Vertical bars of upper plot show number of intersecting operational taxonomic units (OTUs) among plant compartments and soil, denoted by connected black circles below the histogram. Orange bars and circles represent OTUs that overlap among seven compartments, horizontal bars show OTUs set size.</p>]]></content>
      
      
      <categories>
          
          <category> 跟着NCS学作图 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> R语言 </tag>
            
            <tag> UpSetR包 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ancestry祖源分析|LASER</title>
      <link href="/2020-06-24-ancestry-zu-yuan-fen-xi-laser/"/>
      <url>/2020-06-24-ancestry-zu-yuan-fen-xi-laser/</url>
      
        <content type="html"><![CDATA[<font face="times new roman" size=4><span id="more"></span><p>Ancestry祖源分析|LASER</p><!-- toc --><hr><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h3><p>LASER (Locating Ancestry using SEquencing Reads)，是C++编译的软件包，可以直接从全基因组测序读取估算祖先，而无需调用基因型。该方法依赖于一组参考个体，这些参考个体的全基因组SNP基因型和祖先信息是已知的。我们首先通过将主成分分析（PCA）应用于参考个体的基因型数据来构建参考坐标系。</p><h3 id="2-下载"><a href="#2-下载" class="headerlink" title="2. 下载"></a>2. 下载</h3><p><a href="http://csg.sph.umich.edu//chaolong/LASER/">LASER Package</a>: Version 2.03</p><pre><code>wget -c https://sph.umich.edu/csg/software_pages/softwaredownloads/LASER-2.03.tar.gztar xzvf LASER-2.03.tar.gzmv LASER-2.03 laser# version-2.04: http://csg.sph.umich.edu/chaolong/LASER/LASER-2.04.tar.gz</code></pre><h3 id="3-LASER-workflow"><a href="#3-LASER-workflow" class="headerlink" title="3. LASER workflow"></a>3. LASER workflow</h3><p><img src="/Ancestry%E7%A5%96%E6%BA%90%E5%88%86%E6%9E%90-LASER/LASER-workflow.png" alt="LASER workflow"></p><h3 id="4-HGDP-reference-panel"><a href="#4-HGDP-reference-panel" class="headerlink" title="4. HGDP reference panel"></a>4. HGDP reference panel</h3><p><a href="http://csg.sph.umich.edu/chaolong/LASER/HGDP-938-632958.tar.gz">HGDP data</a>: Include 632,958 autosomal SNPs for 938 unrelated individuals from the Human Genome Diversity Project (HGDP).</p><p><img src="/Ancestry%E7%A5%96%E6%BA%90%E5%88%86%E6%9E%90-LASER/HGDP_Popualtions.png" alt="Human Genome Diversity Project"></p><h3 id="5-Preparing-input-files-for-LASER"><a href="#5-Preparing-input-files-for-LASER" class="headerlink" title="5. Preparing input files for LASER"></a>5. Preparing input files for LASER</h3><h3 id="5-1-liftOver-HGDP-hg19tohg38"><a href="#5-1-liftOver-HGDP-hg19tohg38" class="headerlink" title="5.1 liftOver HGDP hg19tohg38"></a>5.1 liftOver HGDP hg19tohg38</h3><h3 id="5-1-1-download-liftOver"><a href="#5-1-1-download-liftOver" class="headerlink" title="5.1.1 download liftOver"></a>5.1.1 download liftOver</h3><p>liftOver file:<a href="http://hgdownload.cse.ucsc.edu/goldenpath/hg19/liftOver/">http://hgdownload.cse.ucsc.edu/goldenpath/hg19/liftOver/</a></p><pre><code>wget -c http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/liftOver</code></pre><h3 id="5-1-2-download-HGDP-reference-file"><a href="#5-1-2-download-HGDP-reference-file" class="headerlink" title="5.1.2 download HGDP reference file"></a>5.1.2 download HGDP reference file</h3><pre><code>#wget -c http://hgdownload.cse.ucsc.edu/goldenpath/hg19/liftOver/hg19ToHg38.over.chain.gzLIFTOVER=/WORK/Project/youguoling/biosoft/liftover$LIFTOVER/liftOver.txt $LASERF/HGDP/HGDP_938chr.site hg19ToHg38.over.chain.gz HGDP_938chrhg38.site unlifted.bed$LIFTOVER/liftOver.txt $LASERF/HGDP/HGDP_938chr.bed hg19ToHg38.over.chain.gz HGDP_938chrhg38.bed unlifted.bed</code></pre><h3 id="5-1-3-或者-vcf-–-gt-geno"><a href="#5-1-3-或者-vcf-–-gt-geno" class="headerlink" title="5.1.3 或者 vcf –&gt; geno"></a>5.1.3 或者 vcf –&gt; geno</h3><p>This step prepares the reference panel by converting a VCF genotype file to a GENO file. We will skip this step and use a ready-to-use HGDP reference panel. A typical command to run the vcf2geno tool is given in the file “$LASERF&#x2F;vcf2geno&#x2F;cmd.sh”:</p><pre><code># $LASERF/vcf2geno/vcf2geno --inVcf exampleVCF/example.vcf.gz --updateID test.updateId --out test</code></pre><h3 id="5-2-bam-–-gt-pileup"><a href="#5-2-bam-–-gt-pileup" class="headerlink" title="5.2 : bam –&gt; pileup"></a>5.2 : bam –&gt; pileup</h3><p>This step uses samtools to generate pileup files from bam files.</p><pre><code>samtools mpileup -q 30 -Q 20 -f $REF -l $HGDP/HGDP_938.bed $BAM/121101035.recal.bam &gt; 121101035.recal.pileupsamtools mpileup -q 30 -Q 20 -f $REF -l $HGDP/HGDP_938.bed $BAM/121101043.recal.bam &gt; 121101043.recal.pileup samtools mpileup -q 30 -Q 20 -f $REF -l $HGDP/HGDP_938.bed $BAM/121101050.recal.bam &gt; 121101050.recal.pileupsamtools mpileup -q 30 -Q 20 -f $REF -l $HGDP/HGDP_938.bed $BAM/121101052.recal.bam &gt; 121101052.recal.pileupsamtools mpileup -q 30 -Q 20 -f $REF -l $HGDP/HGDP_938.bed $BAM/121101415.recal.bam &gt; 121101415.recal.pileupsamtools mpileup -q 30 -Q 20 -f $REF -l $HGDP/HGDP_938.bed $BAM/121101861.recal.bam &gt; 121101861.recal.pileup</code></pre><p>We use -q 30 and -Q 20 to exclude reads that have mapping quality score lower than 30 or base quality score lower than 20.</p><h3 id="5-3-pileup-–-gt-seq"><a href="#5-3-pileup-–-gt-seq" class="headerlink" title="5.3 : pileup –&gt; seq"></a>5.3 : pileup –&gt; seq</h3><p>这一步生成<code>hapmap_trios.seq</code>.</p><pre><code>python $LASER/pileup2seq/pileup2seq.py \-m $HGDP/HGDP_938.site \-b $BAM/AMD_roi_1-based.bed \-i $BAM/AMD_hapmap_trios_id.txt \-o hapmap_trios \$BAM/121101035.recal.pileup \$BAM/121101043.recal.pileup \$BAM/121101050.recal.pileup \$BAM/121101052.recal.pileup \$BAM/121101415.recal.pileup \$BAM/121101861.recal.pileup</code></pre><p>-b provides the targeted regions to exclude and -i specifies alternative IDs for the BAM files to be used in the .seq file (including popID and indivID). -b and -i are optional.</p><h3 id="6-Estimating-ancestry-coordinates"><a href="#6-Estimating-ancestry-coordinates" class="headerlink" title="6. Estimating ancestry coordinates"></a>6. Estimating ancestry coordinates</h3><h3 id="6-1-Generate-the-reference-ancestry-space"><a href="#6-1-Generate-the-reference-ancestry-space" class="headerlink" title="6.1 Generate the reference ancestry space"></a>6.1 Generate the reference ancestry space</h3><p>LASER can perform principal components analysis (PCA) on genotype data of the reference panel to generate a reference ancestry space.</p><pre><code># $LASER/laser -g $HGDP/HGDP_938.geno -pca 1 -k 30 -o HGDP_938</code></pre><p>The above command takes ~20 minutes to finish. We will skip this step, and use a set of reference ancestry coordinates that have been generated in the file <code>$HGDP/HGDP_938.RefPC</code>.coord.<br>View the reference coordinates:</p><pre><code>less -S $HGDP/HGDP_938.RefPC.coord</code></pre><h3 id="6-2-Estimate-ancestry-for-sequenced-samples"><a href="#6-2-Estimate-ancestry-for-sequenced-samples" class="headerlink" title="6.2 Estimate ancestry for sequenced samples"></a>6.2 Estimate ancestry for sequenced samples</h3><p>Submit two jobs to place sequenced samples into the reference ancestry space:</p><pre><code>$LASER/laser -g $HGDP/HGDP_938.geno -c $HGDP/HGDP_938.RefPC.coord -s hapmap_trios.seq -K 20 -k 4 -x 1 -y 3 -o hapmap_trios.1-3 &amp;$LASER/laser -g $HGDP/HGDP_938.geno -c $HGDP/HGDP_938.RefPC.coord -s hapmap_trios.seq -K 20 -k 4 -x 4 -y 6 -o hapmap_trios.4-6 &amp;</code></pre><p>The first job will process samples 1 to 3 and the second job will processed samples 4 to 6. Each sequenced sample will be projected from a 20-dimensional PCA space onto a 4-dimensional reference ancestry space. The running time is ~10 minutes for processing 3 samples in each job.</p><h3 id="6-3-Combine-results"><a href="#6-3-Combine-results" class="headerlink" title="6.3 Combine results"></a>6.3 Combine results</h3><p>Results from previous step will be output to two files <code>hapmap_trios.1-3.SeqPC.coord</code> and <code>hapmap_trios.4-6.SeqPC.coord</code>. Here we simply concatenate the two files while skipping the header line of the second file.</p><pre><code>cp hapmap_trios.1-3.SeqPC.coord hapmap_trios.SeqPC.coordmore +2 hapmap_trios.4-6.SeqPC.coord &gt;&gt; hapmap_trios.SeqPC.coord</code></pre><p><strong>View the results:</strong></p><pre><code>less -S hapmap_trios.SeqPC.coord</code></pre><p><strong>The results should look like below (results will vary slightly):</strong> </p><pre><code>popID  indivID  L1      Ci         K     t          PC1        PC2         PC3         PC4YRI    NA19238  78386   0.170864   20    0.999688   467.989    -210.294    -14.1729    -14.4204CEU    NA12892  85486   0.185973   20    0.999723   10.796     199.095     -9.90387    -21.4534CEU    NA12891  87588   0.190442   20    0.99973    2.04224    196.07      -19.5705    -12.8022CEU    NA12878  83213   0.181748   20    0.999711   4.34591    199.861     -12.4825    -22.6281YRI    NA19239  87564   0.193424   20    0.999734   474.464    -215.96     -9.02921    -19.7372YRI    NA19240  95866   0.213874   20    0.999748   469.914    -214.94     -14.9923    -13.6559</code></pre><h3 id="7-Visualizing-results"><a href="#7-Visualizing-results" class="headerlink" title="7. Visualizing results"></a>7. Visualizing results</h3><p>Example R codes are available in .&#x2F;LASER-2.01&#x2F;plot&#x2F;. Let’s copy the folder to current working directory:</p><pre><code>cp -r $LASER/plot/ ./</code></pre><p>Go to the plot folder and run the script to plot results:</p><pre><code>cd plotRscript plotHGDP.r $HGDP/HGDP_938.RefPC.coord ../hapmap_trios.SeqPC.coord</code></pre><p>A figure named <code>Results_on_HGDP.pdf</code> will be generated. Visualize the figure:</p><pre><code>evince Results_on_HGDP.pdf &amp;</code></pre><p>We expect to see the following figure, in which 3 CEU samples cluster with HGDP Europeans and 3 YRI samples cluster with HGDP Africans:</p><p><img src="/Ancestry%E7%A5%96%E6%BA%90%E5%88%86%E6%9E%90-LASER/Results_on_HGDP.png" alt="Human Genome Diversity Project"></p><h3 id="8-File-format"><a href="#8-File-format" class="headerlink" title="8. File format"></a>8. File format</h3><h3 id="8-1-Geno-file"><a href="#8-1-Geno-file" class="headerlink" title="8.1 Geno file"></a>8.1 Geno file</h3><p>Geno file are from reference samples. LASER use genotype of these samples as a reference panel. You can obtain geno file from VCF files using vcf2geno.</p><p>An example geno file for the HGDP data set (resource&#x2F;HGDP&#x2F;HGDP_938.geno):</p><pre><code>BrahuiHGDP0000112110202122211210BrahuiHGDP0000300200202022220220BrahuiHGDP0000502200102122221221BrahuiHGDP0000702200202022211221BrahuiHGDP0000901010202022220220BrahuiHGDP0001111211211122211220BrahuiHGDP0001312211212022220220BrahuiHGDP0001511200202022220220BrahuiHGDP0001711200100020112220BrahuiHGDP0001902200101021221220</code></pre><p>The first and second columns represent the population id and individual id. From the third column, each number represents a genotype. To be consistent with the sequence data, genotypes should be given on the forward strand. Genotypes are coded by 0, 1, or 2, representing copies of the reference allele at a locus in one individual.</p><p>In this geno file, we have 632,960 columns which contains 632,958 markers from column 3 to the last column.</p><h3 id="8-2-Seq-file"><a href="#8-2-Seq-file" class="headerlink" title="8.2 Seq file"></a>8.2 Seq file</h3><p>Seq file is generated from pileup files. It contains sequencing information and organize it in a LASER readable format. The first two columns represent population id and individual id. Subsequent columns are total read depths and reference base counts. For example, column 3 and 4 are 0, 0 in the following example. That means at first marker, the sequence read depth is 0 and thus none of the reads has reference base. We enforce tab delimiters between markers and space delimiters between each read depths and reference base counts. On line of seq file looks like below:</p><pre><code>NA12878.chrom22NA12878.chrom220 00 00 00 00 </code></pre><h3 id="8-3-Pileup-file"><a href="#8-3-Pileup-file" class="headerlink" title="8.3 Pileup file"></a>8.3 Pileup file</h3><p>Pileup file are generated using samtools. An example pileup file is shown below:</p><pre><code>2217094749A1cD2217202602T1.D2217411899A1.C2217450515G2.,9&lt;2217452966T1c52217470779C1,A2217492203G1,B2217504945C3,..BCA2217529814T3..,CCC</code></pre><p>The columns are chromosome, position (1-based), reference base, depth, bases and base qualities.</p><h3 id="8-4-BED-file"><a href="#8-4-BED-file" class="headerlink" title="8.4 BED file"></a>8.4 BED file</h3><p>BED file represents genomic regions and it follows UCSC conventions:</p><pre><code>1 752565 7525661 768447 7684481 1005805 10058061 1018703 10187041 1021414 1021415</code></pre><p>The columns are: chromosome, start position (0-based) and end position (1-based).</p><h3 id="8-5-Coord-file"><a href="#8-5-Coord-file" class="headerlink" title="8.5 Coord file"></a>8.5 Coord file</h3><p>Coord files represent the ancestries of both reference samples and sequence samples. An example coord file looks like below:</p><pre><code>popID  indivID  L1    Ci        t         PC1       PC2YRI    NA19238  1409  0.304122  0.98933   52.7634   -39.7924CEU    NA12892  1552  0.330037  0.989709  9.82674   25.2898CEU    NA12891  1609  0.362198  0.988082  0.439573  26.8872CEU    NA12878  1579  0.334825  0.988677  8.83775   28.1342YRI    NA19239  1558  0.34898   0.988302  53.9104   -39.1727YRI    NA19240  1735  0.404142  0.990264  59.8379   -45.2765</code></pre><p>The columns are: popID means “population ID”, indivID means “individual ID”, L1 means number of loci has been covered, Ci means “average coverage”, t means Procrustes similarity. PC1, PC2 means coordinates of first and second principal components. You may notice L1, Ci, and t are omitted in the coord files of reference samples. The reason is that reference samples use genotypes and do not have coverage information.</p><h3 id="8-6-Site-file"><a href="#8-6-Site-file" class="headerlink" title="8.6 Site file"></a>8.6 Site file</h3><p>Site file is equivalent to BED file and it is used here to represent marker positions. An example site file looks like below:</p><pre><code>CHR  POS      ID          REF  ALT1    752566   rs3094315   G    A1    768448   rs12562034  G    A1    1005806  rs3934834   C    T1    1018704  rs9442372   A    G1    1021415  rs3737728   A    G</code></pre><p>The site file has header line, and it contains chromosome, position(1-based), id (usually marker name), ref (reference allele) and alt (alternative allele).</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Ancestry祖源分析|peddy</title>
      <link href="/2020-06-23-ancestry-zu-yuan-fen-xi-peddy/"/>
      <url>/2020-06-23-ancestry-zu-yuan-fen-xi-peddy/</url>
      
        <content type="html"><![CDATA[<font face="times new roman" size=4><span id="more"></span><!-- toc --><hr>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>GWAS|Rvtests安装及使用教程</title>
      <link href="/2020-06-20-gwas-rvtests-an-zhuang-ji-shi-yong-jiao-cheng/"/>
      <url>/2020-06-20-gwas-rvtests-an-zhuang-ji-shi-yong-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<font face="times new roman" size=4><span id="more"></span><p>GWAS|Rvtests安装及使用教程</p><!-- toc --><hr><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1.介绍"></a>1.介绍</h3><p><strong><a href="http://zhanxw.github.io/rvtests/">Rvtests</a><strong>，全称（Rare Variant tests，稀有变异），rvtests已开发为支持遗传关联分析和Meta分析的综合工具。它可以分析unrelated individual和family-based individuals的quantitative 和binary结果。它包括各种关联分析（例如，</strong>single variant score test, burden test, variable threshold test, SKAT test, fast linear mixed model score test</strong>）。它采用 VCF&#x2F;BGEN&#x2F;PLINK作为基因型输入文件，并采用PLINK格式表型文件和协变量文件。</p><p>此软件包能够在计算机工作站上的线性混合模型中分析多达1,000,000个人的数据集。RVTESTS支持single variant and gene-level tests。它还允许以RAREMETAL格式在得分统计之间高效生成协方差矩阵，可用于支持下一波整合了大型生物库数据集的Meta分析。</p><p>可以使用线性回归或逻辑回归模型处理更大的样本量。</p><h3 id="2-引用"><a href="#2-引用" class="headerlink" title="2.引用"></a>2.引用</h3><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4848408/">RVTESTS</a>: An Efficient and Comprehensive Tool for Rare Variant Association Analysis Using Sequence Data. Bioinformatics, 2016, 32:1423-1426.</p><h3 id="3-下载和安装"><a href="#3-下载和安装" class="headerlink" title="3.下载和安装"></a>3.下载和安装</h3><p>源代码可以从github或github页面下载最新版本。</p><pre><code>git clone https://github.com/zhanxw/rvtestscd retestsmake</code></pre><p>编译成功后，可执行文件将位于executable文件夹下。只需键入executable&#x2F;rvtests即可开始。</p><p>或者，可以从<a href="https://github.com/zhanxw/rvtests/releases">此处</a>下载二进制可执行文件。</p><h3 id="4-快速教程"><a href="#4-快速教程" class="headerlink" title="4.快速教程"></a>4.快速教程</h3><h3 id="4-1-Single-variant-tests"><a href="#4-1-Single-variant-tests" class="headerlink" title="4.1 Single variant tests"></a>4.1 Single variant tests</h3><pre><code>rvtest --inVcf input.vcf --pheno phenotype.ped --out output --single wald,score</code></pre><p>phenotype.ped中推荐controls as 1, cases as 2, missing phenotypes as -9 or 0.</p><p>对于其他类型的关联分析，可以参考如下<strong>Models</strong>：</p><p><img src="/GWAS-Rvtests%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/single.jpg" alt="Single variant tests Models"></p><h3 id="4-2-Groupwise-tests"><a href="#4-2-Groupwise-tests" class="headerlink" title="4.2 Groupwise tests"></a>4.2 Groupwise tests</h3><p>Groupwise tests主要包括三种类型的tests：</p><ul><li><p><strong>Burden tests</strong>：用于group variants，通常少于1％或5％稀有变异关联分析，包括：CMC test, Zeggini test, Madsen-Browning test, CMAT test和rare-cover test<br><img src="/GWAS-Rvtests%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/burden.jpg" alt="Burden tests"></p></li><li><p><strong>Variable threshold tests</strong>：group variants under different frequency thresholds.<br><img src="/GWAS-Rvtests%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/variablethreshold.jpg" alt="Variable threshold tests"></p></li><li><p><strong>Kernel methods</strong>:包括SKAT test和KBAC test<br><img src="/GWAS-Rvtests%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/kernel.jpg" alt="Kernel methods"></p></li></ul><p>如果按基因进行稀有变异分析，需要使用<code>--geneFilerefFlat</code>格式指定参考基因。也可以<code>--gene</code>用来指定要测试的基因。例如，指定<code>--gene CFH,ARMS2</code>将对CFH和ARMS2基因执行关联分析。</p><pre><code>rvtest --inVcf input.vcf --pheno phenotype.ped --out output --geneFile refFlat_hg19.txt.gz --burden cmc --vt price --kernel skat,kbac</code></pre><h3 id="4-3-Related-individual-tests"><a href="#4-3-Related-individual-tests" class="headerlink" title="4.3 Related individual tests"></a>4.3 Related individual tests</h3><p>首先需要创建一个亲属关系矩阵：</p><pre><code>vcf2kinship --inVcf input.vcf --bn --out output</code></pre><p>该选项<code>--bn</code>意味着使用<code>Balding-Nicols</code>方法计算经验亲属关系。您可以指定<code>--ibs</code>获取IBS亲属关系或者<code>--pedigree input.ped</code>用于根据已知的家系信息计算血统。</p><p>然后，您可以使用基于线性混合模型的关联分析，例如<strong>Fast-LMM score test，Fast-LMM LRT test和Grammar-gamma tests</strong>：</p><pre><code>rvtest --inVcf input.vcf --pheno phenotype.ped --out output --kinship output.kinship --single famScore,famLRT,famGrammarGamma</code></pre><h3 id="4-4-Meta-analysis-tests"><a href="#4-4-Meta-analysis-tests" class="headerlink" title="4.4 Meta-analysis tests"></a>4.4 Meta-analysis tests</h3><p>The meta-analysis models outputs association test results and genotype covariance matrix. These calculated summary statistics can be used in rare variant association analysis (<a href="https://github.com/zhanxw/rvtests#meta-analysis-models">details</a>). We provide single variant score test and generate a genotype covariance matrix. You can use this command:</p><pre><code>rvtest --inVcf input.vcf --pheno phenotype.ped --meta score,cov --out output</code></pre><p>In a more realistic scenario, you may want to adjust for covariates and want to inverse normalized residuals obtained in null model (<a href="http://www.nature.com/ng/journal/vaop/ncurrent/full/ng.2852.html">link</a> to our methodology paper), then this command will work:</p><pre><code>rvtest --inVcf input.vcf --pheno phenotype.ped --covar example.covar --covar-name age,bmi --inverseNormal --useResidualAsPhenotype  --meta score,cov --out output</code></pre><p><code>--covar</code>指定协变量文件，<code>--covar-name</code>指定在分析中使用的协变量。协变量文件格式可以在<a href="http://zhanxw.github.io/rvtests/#Covariate%20file">这里</a>找到。<code>--inverseNormal --useResidualAsPhenotype</code>指定trait transformation method。这意味着首先在协变量上拟合表型的回归模型（自动添加截距），然后对残差进行逆归一化。<code>trait transformation</code>的详细信息可以在<a href="http://zhanxw.github.io/rvtests/#Trait%20transformation">这里</a>找到。</p><p>We support both unrelated individuals and related individuals (e.g. family data)。需要<code>--kinship input.kinship</code>：</p><pre><code>rvtest --inVcf input.vcf --pheno phenotype.ped --meta score,cov --out output --kinship input.kinship</code></pre><p>其中<code>input.kinship</code>是由<code>vcf2kinship</code>计算。</p><p><strong>注意</strong>：默认情况下，协方差矩阵是在一百万个基对的滑动窗口中计算的。您可以通过选项更改此设置<code>windowSize</code>。例如，<code>--meta cov[windowSize=500000]</code>指定一个500k-bp的滑动窗口。</p><p><img src="/GWAS-Rvtests%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/meta.jpg" alt="Meta-analysis models"></p><p>The above models are suitable to generate summary statistics which can be later meta-analyzed (see <a href="http://www.nature.com/ng/journal/v46/n2/abs/ng.2852.html">Dajiang Liu (2014) Nature Genetics</a>). Rvtests implemented the above methods and the results can be further analyzed by RareMetals (<a href="http://genome.sph.umich.edu/wiki/RareMETALS">link</a>) for quantitative trait and RareMetals2 (<a href="http://genome.sph.umich.edu/wiki/RareMETALS2">link</a>). It also worth to mention that our group offers another toolset for meta analysis (<a href="http://genome.sph.umich.edu/wiki/Rare-Metal">link</a>).</p><h3 id="4-4-1-Explanation-of-outputs"><a href="#4-4-1-Explanation-of-outputs" class="headerlink" title="4.4.1 Explanation of outputs"></a>4.4.1 Explanation of outputs</h3><p>The meta-analysis results come as two files: summary score statistics files (prefix.MetaScore.assoc.gz) and covariance files (prefix.MetaCov.assoc.gz).</p><p>In summary score statistics files, you will obtain these columns:</p><ul><li>N_INFORMATIVE: Number of samples that are analyzed for association.</li><li>AF: allele frequency. For related individuals, we use BLUE estimator. For case-control study, we list overall frequency (adjusted by relatedness if possible), case frequency and control frequency separated by a colon.</li><li>INFORMATIVE_ALT_AC: The number of alternative alleles in the analyzed samples.</li><li>CALL_RATE: The fraction of non-missing alleles. For case-control study, we calculate call rate for all samples, case samples and control samples separated by a colon.</li><li>HWE_PVALUE: Hardy-Weinberg equilibrium. For related individuals, this statistic can be inflated. For case-control study, we calculate HWE pvalues for all samples, case samples and controls samples separated by a colon.</li><li>N_REF&#x2F;N_HET&#x2F;N_ALT: Number of samples carrying homozygous reference&#x2F;heterozygous&#x2F;homozygous alternative alleles. For case-control study, we calculate these three statistics for all samples, case samples and controls samples separated by a colon.</li><li>U_STAT, SQRT_V_STAT: U and V statistics are score statistics and their covariance matrix. Details can be found in Dajiang Liu (2014) Nature Genetics.</li><li>ALT_EFFSIZE: for continuous outcome, this is the estimated effect size; for binary outcome, this is the estimated log odds-ratio. We apply a new correction method when binary trait associations for related individuals are analyzed in standard linear mixed models. The log odds ratio is approximately correct for related individual analysis as well.</li></ul><p>The covariance files stores covariances in sliding windows. You will obtain these columns:</p><ul><li>CHROM: the chromosome name</li><li>START_POS&#x2F;END_POS: within one sliding window, the first&#x2F;last variant chromosomal position.</li><li>NUM_MARKER: number of markers in one sliding window.</li><li>MARKER_POS: all chromosomal positions in the sliding window.</li><li>COV: covariances between markers. When the sliding window has markers G.1, G.2, …, G.N, this column will store “covariances” of (G.1, G.1), (G.1, G.2), …, (G.1, G.N); for binary outcomes, this column uses colons as separators and additionally stores covariances between N genotypes and K covariates (G.1, C.1), (G.1, C.2), …, (G.1, C.K), as well as covariances between K covariates (C.1, C.1), (C.1, C.2), … (C.1, C.K), (C.2, C.2), …, (C.2, C.K), …, (C.K, C.K).</li></ul><h3 id="4-4-2-Dominant-models-and-recessive-models"><a href="#4-4-2-Dominant-models-and-recessive-models" class="headerlink" title="4.4.2 Dominant models and recessive models"></a>4.4.2 Dominant models and recessive models</h3><p>通过在<code> –meta</code>选项之后附加<code>dominant</code>和&#x2F;或<code>recessive</code>，可以支持显性和隐性疾病模型。例如，使用<code>–meta dominant,recessive</code>将生成两组文件。对于dominant模型，分别是<code>prefix.MetaDominant.assoc</code>和<code>prefix.MetaDominantCov.assoc.gz</code>；对于recessive模型，分别是<code>prefix.MetaRecessive.assoc</code>和<code>prefix.MetaRecessiveCov.assoc.gz</code>。在dominant模型中，基因型0&#x2F;1&#x2F;2被编码为0&#x2F;1&#x2F;1；在recessive模型中，基因型0&#x2F;1&#x2F;2被编码为0&#x2F;0&#x2F;1。基因型缺失将被推算为均值。</p><h3 id="5-输入文件"><a href="#5-输入文件" class="headerlink" title="5.输入文件"></a>5.输入文件</h3><h3 id="5-1-Genotype-files（VCF，BCF，BGEN，KGG）"><a href="#5-1-Genotype-files（VCF，BCF，BGEN，KGG）" class="headerlink" title="5.1 Genotype files（VCF，BCF，BGEN，KGG）"></a>5.1 Genotype files（VCF，BCF，BGEN，KGG）</h3><p>Rvtests支持VCF（变体调用格式）文件。支持未压缩格式或压缩格式的vcf文件。To use group-based rare variant tests，需要使用<a href="http://samtools.sourceforge.net/tabix.shtml">tabix</a>为VCF文件建立索引。</p><p>以下是将未压缩VCF格式转换为bgzipped VCF格式的命令：</p><pre><code>(grep ^&quot;#&quot; $your_old_vcf; grep -v ^&quot;#&quot; $your_old_vcf | sed &#39;s:^chr::ig&#39; | sort -k1,1n -k2,2n) | bgzip -c &gt; $your_vcf_file tabix -f -p vcf $your_vcf_file</code></pre><p>上述命令将（1）chr从染色体名称中删除前缀；（2）首先按染色体，然后按染色体位置对VCF文件进行排序；（3）使用bgzip压缩；（4）创建tabix索引。</p><p>Rvtests支持<code>genotype dosages</code>。使用<code>--dosage DosageTag</code>指定dosage tag。例如，如果VCF格式字段为<code>GT：EC</code>，单个基因型字段为<code>0/0：0.02</code>，则可以使用<code>--dosage EC</code>，并且rvtests将在回归模型中使用剂量0.02。</p><p>Rvtests支持BGEN输入格式 v1.0到v1.3。使用<code>--inBgen</code>指定一个BGEN文件,<code>--inBgenSample</code>指定SAMPLE文件。</p><p>Rvtests支持KGGSeq输入格式。此格式是对二进制PLINK格式的扩展。使用–inKgg来代替–inVcf。</p><h3 id="5-2-Phenotype-files"><a href="#5-2-Phenotype-files" class="headerlink" title="5.2 Phenotype files"></a>5.2 Phenotype files</h3><p>可以使用<code>--mpheno $phenotypeColumnNumber</code>或<code>--pheno-name</code>指定特定表型。</p><p>表型文件示例（<code>example.pheno</code>）具有以下格式：</p><pre><code>fid iid fatid matid sex y1 y2 y3 y4P1 P1 0 0 0 1.7642934435605 -0.733862638327895 -0.980843608339726 2P2 P2 0 0 0 0.457111744989746 0.623297281416372 -2.24266162284447 1P3 P3 0 0 0 0.566689682543218 1.44136462889459 -1.6490100777089 1P4 P4 0 0 0 0.350528353203767 -1.79533911725537 -1.11916876241804 1P5 P5 0 0 1 2.72675074738545 -1.05487747371158 -0.33586430010589 2</code></pre><p>表型文件由<code>--pheno example.pheno</code> 指定。默认表型列标题为<code>y1</code>。如果要使用替代列作为关联分析的表型（例如标题为y2的列），则可以使用列或名称来指定表型</p><pre><code>–mpheno 2–pheno-name y2</code></pre><p>注意：要使用<code>--pheno-name</code>，标题行必须以<code>fid iid</code>开头。</p><p>在表型文件中，缺失值可以用<code>NA</code>或<code>任何非数字值</code>表示。缺少表型的个体将自动从后续关联分析中删除。对于每个缺失的表型值，将生成一条警告并将其记录在日志文件中。</p><p>当表型值分别为0、1和2时，rvtests会自动将其视为binary traits。但是，如果要将其视为连续性状，需使用<code>--qtl</code>选项。</p><h3 id="5-3-Covariate-files"><a href="#5-3-Covariate-files" class="headerlink" title="5.3 Covariate files"></a>5.3 Covariate files</h3><p>可以使用<code>--covar</code>和<code>--covar-name</code>指定将用于单变量关联分析的协变量。这是一个可选参数。如果数据中没有协变量，则可以忽略此选项。</p><p>协变量文件（例如<code>example.covar</code>）与表型文件具有相似的格式：</p><pre><code>fid iid fatid matid sex y1 y2 y3 y4P1 P1 0 0 0 1.911 -1.465 -0.817 1P2 P2 0 0 0 2.146 -2.451 -0.178 2P3 P3 0 0 0 1.086 -1.194 -0.899 1P4 P4 0 0 0 0.704 -1.052 -0.237 1P5 P5 0 0 1 2.512 -3.085 -2.579 1</code></pre><p>协变量文件由<code>--covar</code>选项指定（例如<code>--covar example.covar</code>）。要指定将在关联分析中使用的协变量，可以使用该选项<code>--covar-name</code>。例如，当使用<code>age，bmi</code>和3个PCAs进行关联分析时，可以为rvtests程序指定以下选项，即 <code>--covar example.covar --covar-name age,bmi,pc1,pc2,pc3</code>。</p><p>注意：协变量文件中缺少的数据可以用任何非数字值（例如NA）标记。它们将自动推算为数据文件中的平均值。</p><h3 id="5-4-Trait-transformation"><a href="#5-4-Trait-transformation" class="headerlink" title="5.4 Trait transformation"></a>5.4 Trait transformation</h3><p>In this meta-analysis, we use inverse normal transformed residuals in the association analysis, which is achieved by using a combination of <code>--inverseNormal</code> and <code>--useResidualAsPhenotype</code>. Specifically, we first fit the null model by regressing phenotype on covariates. The residuals are then inverse normal transformed (see <strong>Appendix A</strong> more detailed formula for transformation). Transformed residuals will be used to obtain score statistics.</p><pre><code>./rvtest --inVcf $vcf --pheno $example.pheno --covar example.covar --covar-name age,bmi --inverseNormal --useResidualAsPhenotype  --meta score,cov --out $output_prefix</code></pre><h3 id="6-Models"><a href="#6-Models" class="headerlink" title="6. Models"></a>6. Models</h3><h3 id="6-1-Utility-models"><a href="#6-1-Utility-models" class="headerlink" title="6.1 Utility models"></a>6.1 Utility models</h3><p>Rvtests has an convenient option –outputRaw. When specifying this, rvtests can output genotypes, phenotype, covariates (if any) and collapsed genotype to tabular files. These files can be imported into other software (e.g. R) for further analyses.</p><h3 id="7-Association-test-options"><a href="#7-Association-test-options" class="headerlink" title="7. Association test options"></a>7. Association test options</h3><h3 id="7-1-Sample-inclusion-x2F-exclusion"><a href="#7-1-Sample-inclusion-x2F-exclusion" class="headerlink" title="7.1 Sample inclusion&#x2F;exclusion"></a>7.1 Sample inclusion&#x2F;exclusion</h3><p>Rvtests可以灵活地指定要包括或排除的样本：</p><pre><code>--peopleIncludeID : give IDs of people that will be included in study--peopleIncludeFile : from given file, set IDs of people that will be included in study--peopleExcludeID : give IDs of people that will be included in study--peopleExcludeFile : from given file, set IDs of people that will be included in study</code></pre><h3 id="7-2-Variant-site-filters"><a href="#7-2-Variant-site-filters" class="headerlink" title="7.2 Variant site filters"></a>7.2 Variant site filters</h3><p>通常在稀有变异分析中使用不同的frequency cut-off。因此，rvtests指定frequency cut-offs。<br>Frequency Cut-off</p><pre><code>--freqUpper: Specify upper minor allele frequency bound to be included in analysis--freqLower: Specify lower minor allele frequency bound to be included in analysis</code></pre><p>如果指定<code>--freqLower 0.01 --freqUpper 0.05</code>，则仅分析次要等位基因频率在0.01到0.05（含边界）之间的变体。</p><p>与Sample inclusion&#x2F;exclusion类似，可以通过<code>--rangeList</code>选项来指定要包含的变异范围。例如·–rangeList 1:100-200·将1号染色体的位置包括100bp至200bp的区域。或者，使用单独的文件，<code>range.txt</code> <code>--rangeFile range.txt</code>指定关联分析范围。</p><pre><code>--rangeList: Specify some ranges to use, please use chr:begin-end format.--rangeFile: Specify the file containing ranges, please use chr:begin-end format.--siteFile: Specify the file containing sites to include, please use &quot;chr pos&quot; format.</code></pre><p>It is supported to filter variant site by site depth, minor allele count or annotation (annotated VCF file is needed).</p><pre><code>--siteDepthMin : Specify minimum depth(inclusive) to be included in analysis--siteDepthMax : Specify maximum depth(inclusive) to be included in analysis--siteMACMin : Specify minimum Minor Allele Count(inclusive) to be included in analysis--annoType : Specify annotation type that is followed by ANNO= in the VCF INFO field, regular expression is allowed</code></pre><p>注意：<code>--annoType</code>可以基于正则表达式过滤变异。例如，<code>--annoType Nonsynonymous</code>将仅分析ANNO&#x3D;Nonsynonymous在INFO字段中存在的非同义变异。要提取一种以上的注释类型，请使用<code>--annoType &#39;Start_Gain|Stop_Loss|Start_Loss|Essential_Splice_Site|Stop_Gain|Normal_Splice_Site|Synonymous|Nonsynonymous</code>提取LOF（功能丧失）突变。要生成带注释的VCF文件，请阅读下一节<code>Annotation</code>。</p><h3 id="7-2-1-Annotation"><a href="#7-2-1-Annotation" class="headerlink" title="7.2.1 Annotation"></a>7.2.1 Annotation</h3><p>在此，我们将带有注释信息的VCF文件定义为带注释的VCF。可以使用ANNO（一种快速准确的注释软件）来完成注释步骤。最少有两个步骤来注释VCF文件：</p><ul><li>安装ANNO及其资源文件</li></ul><pre><code>git clone https://github.com/zhanxw/anno.git; cd anno; 使; cd资源；./download.sh</code></pre><ul><li>运行以下脚本：</li></ul><pre><code>anno -i input.vcf -o output.vcf.gz -r anno / resources / hs37d5.fa -g anno / resources / refFlat_hg19.txt.gz -p anno / priority.txt -c anno / codon.txt –indexOutput</code></pre><p>然后，您将获得带注释的VCF文件output.vcf.gz及其tabix索引output.vcf.gz.tbi。</p><h3 id="7-3-Genotype-filters"><a href="#7-3-Genotype-filters" class="headerlink" title="7.3 Genotype filters"></a>7.3 Genotype filters</h3><p>可以通过以下选项过滤掉深度较浅或质量较差的基因型：</p><pre><code>-indvDepthMin : Specify minimum depth(inclusive) of a sample to be included in analysis--indvDepthMax : Specify maximum depth(inclusive) of a sample to be included in analysis--indvQualMin : Specify minimum depth(inclusive) of a sample to be included in analysis</code></pre><h3 id="7-4-处理缺失的基因型和表型"><a href="#7-4-处理缺失的基因型和表型" class="headerlink" title="7.4 处理缺失的基因型和表型"></a>7.4 处理缺失的基因型和表型</h3><p>When genotypes are missing (e.g. genotype &#x3D; “.&#x2F;.”) or genotypes are filtered out, there are three options to handle them: </p><ul><li><p>(1) impute to its mean(default option); </p></li><li><p>(2) impute by HWE equilibrium; </p></li><li><p>(3) remove from the model. </p><p>Use –impute [mean|hwe|drop] to specify which option to use.</p></li></ul><p>例如，当缺少定量表型时，某些样本具有基因型文件，但没有表型，rvtest可以将缺失表型推算为其平均值。</p><p>注意：请勿将<code>--imputePheno</code>用于binary trait。</p><p>总之，可以使用以下两个选项：</p><pre><code>--impute : Specify either of mean, hwe, and drop--imputePheno : Impute phenotype to mean by those have genotypes but no phenotypes</code></pre><h3 id="7-5-Specify-groups-e-g-burden-unit"><a href="#7-5-Specify-groups-e-g-burden-unit" class="headerlink" title="7.5 Specify groups (e.g burden unit)"></a>7.5 Specify groups (e.g burden unit)</h3><p>使用<code>--geneFile</code>选项指定基因文件名。例如，<code>--geneFile refFlat_hg19.txt.gz</code>将<code>refFlat_hg19.txt.gz</code>用作基因定义文件，然后对每个基因执行关联分析。使用<code>--gene</code>指定的基因的一个子集的测试。例如，<code>--gene CFH</code>将仅测试CFH基因。</p><p>Alternative grouping unit can be specified as set. These sets are treated similar to gene. You can thus use <code>--setFile </code>to define sets (similar to <code>--geneFile</code> option), and use <code>--set</code> to define a specific set (similar to<code> --gene option</code>). Additionally, use <code>--setList</code> can specify a set to test from command line.</p><p>The format of a set file is: (1) set names; (2) ranges (e.g. chrom:begin-end); For example, you have a set file, example.set, like this:</p><pre><code>set1 1:100-200,1:250-300set2 2:500-600</code></pre><p>您可以指定<code>--setFile example.set --set set2</code>将2号染色体内500至600bp的变体分组。如果要测试特定区域，例如2号染色体，位置500到550bp，但又不想制作另一个文件，则可以使用<code>--setList 2:500-600</code>。</p><p>概括来说，与分组单位有关的选项如下：</p><pre><code>--geneFile : specify a gene file (for burden tests)--gene : specify which genes to test--setList : specify a list to test (for burden tests)--setFile : specify a list file (for burden tests, first two columns:setName chr:beg-end)--set : specify which set to test (1st column)</code></pre><h3 id="8-Sex-chromosome-analysis"><a href="#8-Sex-chromosome-analysis" class="headerlink" title="8.Sex chromosome analysis"></a>8.Sex chromosome analysis</h3><p>Rvtests support X chromosome analysis. In human X chromosome, there is PAR (pseudoautosomal region) and non-PAR region. For males, there are two X allele in PAR region and one allele in non-PAR region. While the PAR region is treated in the same way as autosomes, rvtests treat non-PAR region differently. Below we will describe the details about how rvtests handles non-PAR region.</p><p>Prepare data. According to VCF standard, male genotype needs to coded as 0 or 1. For compatibility, rvtests also support 0&#x2F;0 or 1&#x2F;1 coding. In VCF files, male genotypes can be written as <code>“0”, “1”, “0|0”, “0/0”, “1|1”, “1/1”</code>. All other genotypes will be treated as missing.</p><p>Genotype in regression models. For consistence, male genotypes are converted to 0 or 2. When male dosages are provided, we expect the values in the VCF file are between 0.0 and 1.0, and then will model them as twice the value.</p><p>MetaScore results. If –meta score is specified, the output file prefix.MetaScore.assoc.gz includes both PAR-region and non-PAR region analysis. However, in the non-PAR region, the difference is that Hardy-Weinberg P-value and homozygous-reference&#x2F;heterzygous&#x2F;homozygous-alternative sample sizes are calculated using female samples only.</p><p>Related individuals. Just append –xHemi to the vcf2kinship (more details in Kinship generation) and rvtest command lines. Rvtests can recognize non-PAR region kinship file and use it in the analysis.</p><p>PAR region. PAR region is defined as two regions <code>X:60001-2699520 </code>and <code>X:154931044-155260560</code>. Use <code>--xLabel</code> can specify which chromosome has PAR region (default: 23 or X) and use <code>--xParRegion</code> to specify PAR region (default: hg19, meaning ‘60001-2699520,154931044-155260560’ in the UCSC build hg19, specify “hg18” will use PAR region definition in the UCSC build hg18, or specify “hg38” will use UCSC build 38).</p><h3 id="9-Kinship-generation"><a href="#9-Kinship-generation" class="headerlink" title="9.Kinship generation"></a>9.Kinship generation</h3><p>分析相关个人通常需要估计亲属关系。可以使用<code>vcf2kinship</code>。</p><p><code>vcf2kinship</code> can calculate pedigree kinship using a pedigree input file (PED format, see Phenotype file, use option <code>--ped</code>). The output file name is specified by <code>--prefix</code> option. If you use <code>--prefix</code> output then the output files will include <code>output.kinship</code>.</p><p>It can also calculate empirical kinship using genotype input file (VCF format, see Genotype file (VCF), use option <code>--inVcf</code>). For empirical kinship, you also need to specify the kinship model, either Balding-Nicols model (use option <code>--bn</code>) or Identity-by-state model (use option <code>--ibs</code>).</p><p>In sex chromosome analysis, it is often required to generate kinship on X chromosome regions, then you need to specify <code>--xHemi</code>. If your input VCF file has different X chromosome label (e.g. chromosome name is ‘23’ instead of ‘X’, you can use <code>--xLabel 23</code>.</p><p>If principal component decomposition (PCA) results are needed, you can use option <code>--pca</code>. Then output files with suffix ‘.pca’ include PCA results.</p><p>When dealing with large input files, it is often preferred to use multiple CPU to speed up calculation using the option <code>--thread N </code>in which N is the number of CPU.</p><p>For example, to generate pedigree-based kinship (<code>--ped</code>) on both autosomal region and X chromosome (<code>--xHemi</code>) region, the command line is:</p><pre><code>vcf2kinship --ped input.ped --xHemi --out output</code></pre><p>To generate empirical kinship (<code>--inVcf</code>) on both autosomal region and X chromosome (<code>--xHemi</code>) region using Balding-Nicols model, the command line is:</p><pre><code>vcf2kinship --inVcf input.vcf.gz --ped input.ped --bn --xHemi --out output</code></pre><p>NOTE: you need to provide a pedigree file (PED) in the above case, as vcf2kinship needs the sex information of samples to construct kinship for sex chromosome.</p><p>For modern genetic datasets, genotype data is often stored by chromosomes, with each chromosome stored in a separate VCF file. In this case, kinship matrix can be first calcualted separately for each chromosome, and then combined using the python script <a href="https://github.com/zhanxw/rvtests/tree/master/misc">combineKinship.py</a>. Specifically, if you generated two kinship matrices for chr1 chr2 (chr1.kinship, and chr2.kinship), you can run the python script to combine them, i.e.</p><pre><code>python combineKinship.py -o prefix chr1.kinship chr2.kinship</code></pre><p>所得的亲属关系矩阵等效于使用合并的vcf文件计算的亲属关系矩阵。</p><h3 id="10-Resources"><a href="#10-Resources" class="headerlink" title="10.Resources"></a>10.Resources</h3><h3 id="10-1-UCSC-RefFlat-Genes"><a href="#10-1-UCSC-RefFlat-Genes" class="headerlink" title="10.1 UCSC RefFlat Genes"></a>10.1 UCSC RefFlat Genes</h3><pre><code>refFlat_hg19.txt.gz</code></pre><p>UCSC基因组版本中refFlat格式的UCSC基因定义文件（<a href="http://genome.ucsc.edu/goldenpath/gbdDescriptionsOld.html#RefFlat">详细信息</a>）。</p><p><strong>File link</strong>：http : &#x2F;&#x2F;qbrc.swmed.edu&#x2F;zhanxw&#x2F;seqminer&#x2F;data&#x2F;refFlat_hg19.txt.gz</p><h3 id="10-2-Gencode-Genes"><a href="#10-2-Gencode-Genes" class="headerlink" title="10.2 Gencode Genes"></a>10.2 Gencode Genes</h3><pre><code>refFlat.gencode.v19.gz</code></pre><p>Gencode基因定义版本19，采用<code>refFlat</code>格式（<a href="http://www.gencodegenes.org/releases/19.html">详细信息</a>）。</p><p><strong>File link</strong>：http : &#x2F;&#x2F;qbrc.swmed.edu&#x2F;zhanxw&#x2F;seqminer&#x2F;data&#x2F;refFlat.gencode.v19.gz</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>GWAS|EPACTS安装及使用</title>
      <link href="/2020-06-15-gwas-epacts-an-zhuang-ji-shi-yong-jiao-cheng/"/>
      <url>/2020-06-15-gwas-epacts-an-zhuang-ji-shi-yong-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<font face="times new roman" size=4><span id="more"></span><p>GWAS|EPACTS安装及使用</p><!-- toc --><hr><h1 id="1-Installation-Details"><a href="#1-Installation-Details" class="headerlink" title="1. Installation Details"></a>1. Installation Details</h1><p>If you want to use EPACTS in an Ubuntu platform, following the step below</p><pre><code>git clone https://github.com/statgen/EPACTS.gitmv EPACTS/ epactscd epacts./configure --prefix=~/you/biosoft/epactsmakemake install</code></pre><p><strong>Important Note</strong>: make sure to specify –prefix&#x3D;&#x2F;path&#x2F;to&#x2F;install。安装过程中有太多的坑：</p><ul><li>因为本服务器gcc是7.2.0，所以安装过程中总是安装不成功。去<a href="http://groups.google.com/group/epacts">EPACTS Google group讨论区</a>说gcc需为gcc-5. gcc-5安装过程中也会有很多问题，具体可以关注公众号Gene2You，进行留言咨询。</li><li><strong>.&#x2F;configure</strong>过程中还会遇到其他问题，如需要安装”groff”，”gnuplot”，”No man pages found in package ‘epactsR’”，”make[2]: *** No rule to make target single.b.spa.R’, needed by all-am’. Stop.”等，可以查询<a href="http://groups.google.com/group/epacts">EPACTS Google group讨论区</a>，或者关注公众号Gene2You，进行留言咨询。</li></ul><p>安装成功后：</p><pre><code># Now $&#123;EPACTS_DIR&#125; represents the &#39;/path/to/install&#39; directoryEPACTS_DIR=/WORK/Project/youguoling/biosoft/epacts</code></pre><h1 id="2-Download-the-reference-FASTA-files"><a href="#2-Download-the-reference-FASTA-files" class="headerlink" title="2. Download the reference FASTA files"></a>2. Download the reference FASTA files</h1><ul><li><a href="https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz">UCSC reference</a></li><li><a href="https://www.ncbi.nlm.nih.gov/projects/r_gencoll/ftp_service/nph-gc-ftp-service.cgi/?HistoryId=NCID_1_43150472_130.14.22.33_5555_1592229715_618157301_0MetA0_S_HStore&QueryKey=2&ReleaseType=RefSeq&FileType=GENOME_FASTA&Flat=true">NCBI reference</a></li><li><a href="ftp://ftp.ensembl.org/pub/release-100/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz">Ensembl reference</a></li><li>如果Download the reference FASTA files from 1000 Genomes FTP automatically by running the following commands：</li></ul><pre><code> $&#123;EPACTS_DIR&#125;/bin/epacts download</code></pre><h1 id="3-Perform-a-test-run"><a href="#3-Perform-a-test-run" class="headerlink" title="3. Perform a test run"></a>3. Perform a test run</h1><p>by running the following command:</p><pre><code>$&#123;EPACTS_DIR&#125;/bin/test_run_epacts.sh</code></pre><h1 id="4-Getting-Started-With-Examples"><a href="#4-Getting-Started-With-Examples" class="headerlink" title="4. Getting Started With Examples"></a>4. Getting Started With Examples</h1><h2 id="4-1-All-in-one-example"><a href="#4-1-All-in-one-example" class="headerlink" title="4.1 All-in-one example"></a>4.1 All-in-one example</h2><p>To get started with EPACTS, run the following command will perform an example run</p><pre><code>$&#123;EPACTS_DIR&#125;/bin/test_run_epacts.sh</code></pre><p>You will find a series of lines in <code>test_run_epacts.sh</code> script commented out for each possible test.</p><p>The example <strong>phenotype</strong> (<em>PED format</em>) and <strong>genotype</strong> (<em>VCF format</em>) can be found at</p><pre><code>$&#123;EPACTS_DIR&#125;/share/EPACTS/</code></pre><h2 id="4-2-Single-Variant-Test"><a href="#4-2-Single-Variant-Test" class="headerlink" title="4.2 Single Variant Test"></a>4.2 Single Variant Test</h2><p>Or You can run EPACTS command yourself by running</p><pre><code>$&#123;EPACTS_DIR&#125;/epacts single \  --vcf  $&#123;EPACTS_DIR&#125;/data/1000G_exome_chr20_example_softFiltered.calls.vcf.gz \  --ped  $&#123;EPACTS_DIR&#125;/data/1000G_dummy_pheno.ped  \  --min-maf 0.001 --chr 20 --pheno DISEASE --cov AGE --cov SEX --test b.score --anno \   --out out/test --run 2</code></pre><p>The command above will perform single variant association test using a dummy case-control phenotype file and a subset of 1000 genomes exome VCF file (chr20) using score test statistic for all variants over 1% of higher MAF using 2 parallel runs.</p><p><strong>You will see the 4 output files as the main outcome of the analysis</strong></p><h4 id="4-2-1-Output-Text-of-All-Test-Statistics"><a href="#4-2-1-Output-Text-of-All-Test-Statistics" class="headerlink" title="4.2.1 Output Text of All Test Statistics"></a>4.2.1 Output Text of All Test Statistics</h4><p>The filename is <code>out/test.single.b.score.epacts.gz</code> and the contents will look like:</p><pre><code>$ zcat out/test.single.b.score.epacts.gz | head#CHROMBEGINENDMARKER_IDNSACCALLRATEMAFPVALUESCOREN.CASEN.CTRLAF.CASEAF.CTRL20683036830320:68303_A/G_Upstream:DEFB125266110.0018797NANANANANANA20683196831920:68319_C/A_Upstream:DEFB1252661.4467e-3610NANANANANANA20683966839620:68396_C/T_Nonsynonymous:DEFB125266110.0018797NANANANANANA20766357663520:76635_A/T_Intron:DEFB1252661.534e-3710NANANANANANA20766897668920:76689_T/C_Synonymous:DEFB125266010NANANANANANA20766907669020:76690_T/C_Nonsynonymous:DEFB125266110.0018797NANANANANANA20767007670020:76700_G/A_Nonsynonymous:DEFB125266010NANANANANANA20767267672620:76726_C/G_Nonsynonymous:DEFB125266010NANANANANANA20767717677120:76771_C/T_Nonsynonymous:DEFB125266310.00563910.684840.405871451210.0137930.0082645</code></pre><h4 id="4-2-2-Output-Text-of-Top-Associations"><a href="#4-2-2-Output-Text-of-Top-Associations" class="headerlink" title="4.2.2 Output Text of Top Associations"></a>4.2.2 Output Text of Top Associations</h4><p>Same type of file but containing top 5,000 association will be stored at <code>out/test.epacts.top5000</code></p><pre><code>$ head out/test.single.b.score.epacts.top5000 #CHROMBEGINENDMARKER_IDNSACCALLRATEMAFPVALUESCOREN.CASEN.CTRLAF.CASEAF.CTRL201610894161089420:1610894_G/A_Synonymous:SIRPG266138.6410.260616.9939e-053.97651451210.651770.36476204162411416241120:4162411_T/C_Intron:SMOX26620410.383460.00055583-3.45231451210.627590.9338820340619183406191820:34061918_T/C_Intron:CEP25026641.81510.07860.000954713.30351451210.225430.075436204155948415594820:4155948_G/A_Intron:SMOX26621510.404140.0020792-3.07871451210.682760.95868204680251468025120:4680251_A/G_Nonsynonymous:PRNP26618610.349620.00259623.01191451210.80690.5702520366688743666887420:36668874_G/A_Synonymous:RPRD1B2669610.180450.0030312.96461451210.448280.256220366418713664187120:36641871_G/A_Synonymous:TTI12661010.0187970.004308-2.85471451210.00689660.07438201616892161689220:1616892_A/G_Synonymous:SIRPG26614410.270680.00512392.79911451210.634490.4297520250383722503837220:25038372_G/A_Intron:ACSS1266103.310.194180.0057482.76181451210.472010.28813</code></pre><p>The key columns represents:</p><ul><li><strong>NS:</strong> Number of phenotyped samples with non-missing genotypes</li><li><strong>AC:</strong> Total Non-reference Allele Count</li><li><strong>CALLRATE:</strong> Fraction of non-missing genotypes.</li><li><strong>MAF:</strong> Minor allele frequencies</li><li><strong>PVALUE:</strong> P-value of single variant test</li><li><strong>AF.CASE:</strong> Non-reference allele frequencies for cases</li><li><strong>AF.CTRL:</strong> Non-reference allele frequencies for controls</li></ul><h4 id="4-2-3-Q-Q-plot-of-test-statistics-stratified-by-MAF"><a href="#4-2-3-Q-Q-plot-of-test-statistics-stratified-by-MAF" class="headerlink" title="4.2.3 Q-Q plot of test statistics (stratified by MAF)"></a>4.2.3 Q-Q plot of test statistics (stratified by MAF)</h4><p>The file out&#x2F;test.b.score.epacts.qq.pdf will be generated as shown below:<br><img src="/GWAS-EPACTS%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/qqplot.png" alt="Q-Q Plot"></p><h4 id="4-2-4-Manhattan-Plot-of-Test-Statistics"><a href="#4-2-4-Manhattan-Plot-of-Test-Statistics" class="headerlink" title="4.2.4 Manhattan Plot of Test Statistics"></a>4.2.4 Manhattan Plot of Test Statistics</h4><p>The file out&#x2F;test.b.score.epacts.mh.pdf will be generated for chr20 only.<br><img src="/GWAS-EPACTS%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/mh.png" alt="Manhattan Plot"></p><p>An example Genome-wide manhattan plot (from a genome-wide run) will look like below<br><img src="/GWAS-EPACTS%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/Manhattan.png" alt="Manhattan Plot"></p><h2 id="4-3-Gene-wise-or-group-wise-burden-test"><a href="#4-3-Gene-wise-or-group-wise-burden-test" class="headerlink" title="4.3 Gene-wise or group-wise burden test"></a>4.3 Gene-wise or group-wise burden test</h2><p>Gene-wise or group-wise burden test requires two steps. First, ‘group’ file containing the list of markers per group needs to be generated. Second, group-wise burden test needs to be run</p><h4 id="4-3-1-Creating-marker-group-file"><a href="#4-3-1-Creating-marker-group-file" class="headerlink" title="4.3.1 Creating marker group file"></a>4.3.1 Creating marker group file</h4><p>The marker group file has the following format</p><pre><code>[GROUP_ID]  [MARKER_ID_1]   [MARKER_ID_2]  .... [MARKER_ID_N]</code></pre><p>where</p><ul><li><strong>[GROUP_ID]</strong> is a string representing the group (e.g. gene name)</li><li><strong>[MARKER_ID_K]</strong> is a marker key as a format of [CHROM]:[POS]_[REF]&#x2F;[ALT] (NOTE THAT THIS IS DIFFERENT FROM TYPICAL VCF MARKER ID field)</li></ul><p>Note that <strong>[MARKER_ID_K]</strong> has to be sorted by increasing order of genomic coordinate</p><p>In order to create gene-level group file from typically formatted VCF file, one may use the following utility</p><pre><code>$&#123;EPACTS_DIR&#125;/epacts make-group --vcf [input-vcf] --out [output-group-file] --format [epacts, annovar, chaos or gatk] --nonsyn</code></pre><p>The above command create a file [output-group-file] containing a list of missense and nonsense variants per each gene. To incorporate different types of functional annotations, use –type option as follows</p><pre><code>$&#123;EPACTS_DIR&#125;/epacts make-group --vcf [input-vcf] --out [output-group-file] --format [epacts, annovar, chaos or gatk] --type [function_type_1] --type [function_type_2] ...</code></pre><p>Type <code>&#39;epacts makegroup -man&#39;</code> for the detailed documentation</p><h4 id="4-3-2-Annotating-VCF-file-using-EPACTS"><a href="#4-3-2-Annotating-VCF-file-using-EPACTS" class="headerlink" title="4.3.2 Annotating VCF file using EPACTS"></a>4.3.2 Annotating VCF file using EPACTS</h4><p>If the VCF is not annotated, ‘epacts makegroup’ cannot be used. In order to annotate VCF, one can use the example VCF using ANNOVAR as follows:</p><pre><code>$&#123;EPACTS_DIR&#125;/epacts anno \   --in $&#123;EPACTS_DIR&#125;/data/1000G_exome_chr20_example_softFiltered.calls.vcf.gz \   --out $&#123;EPACTS_DIR&#125;/data/1000G_exome_chr20_example_softFiltered.calls.anno.vcf.gz</code></pre><p>The epacts anno script will add “ANNO&#x3D;[function]:[genename]” entry into the INFO field based on gencodeV7 (default) or refGene database.</p><p>It is important to check whether the VCF file is already annotated or not in order to avoid no or redundant annotation.</p><h4 id="4-3-3-Running-Groupwise-Test"><a href="#4-3-3-Running-Groupwise-Test" class="headerlink" title="4.3.3 Running Groupwise Test"></a>4.3.3 Running Groupwise Test</h4><p>To perform a groupwise burden test on the example VCF (annotated as above), run the following command</p><pre><code>$&#123;EPACTS_DIR&#125;/epacts group --vcf $&#123;EPACTS_DIR&#125;/data/1000G_exome_chr20_example_softFiltered.calls.anno.vcf.gz \  --groupf $&#123;EPACTS_DIR&#125;/data/1000G_exome_chr20_example_softFiltered.calls.anno.grp --out out/test.gene.skat \  --ped $&#123;EPACTS_DIR&#125;/data/1000G_dummy_pheno.ped --maxAF 0.05 \  --chr 20 --pheno QT --cov AGE --cov SEX --test skat --skat-o --run 2</code></pre><h4 id="4-3-4-Example-Output"><a href="#4-3-4-Example-Output" class="headerlink" title="4.3.4 Example Output"></a>4.3.4 Example Output</h4><pre><code>$ head out/test.gene.skat.epacts.top5000#CHROM BEGIN   END     MARKER_ID       NS      FRAC_WITH_RARE     NUM_ALL_VARS    NUM_PASS_VARS   NUM_SING_VARS   PVALUE  STATRHO20     62607037        62608720        20:62607037-62608720_SAMD10     266     0.14662 9       5       1       0.0020064       120     2816211 2820493 20:2816211-2820493_FAM113A      266     0.011278        12      2       1       0.0032542       020     47245987        47361692        20:47245987-47361692_PREX1      266     0.1391  54      9       6       0.0054849       120     34761734        34810279        20:34761734-34810279_EPB41L1    266     0.071429        14      7       5       0.0068492       0.220     61340671        61391602        20:61340671-61391602_NTSR1      266     0.11278 24      9       3       0.011063        120     48561952        48568644        20:48561952-48568644_RNF114     266     0.011278        4       2       1       0.015175        0.220     60962895        60963559        20:60962895-60963559_RPS21      266     0.06015 6       3       2       0.016409        020     55904961        55917801        20:55904961-55917801_SPO11      266     0.011278        11      3       3       0.018031        0</code></pre><p>The key columns represents:</p><ul><li><strong>NS :</strong> Number of phenotyped samples with non-missing genotypes</li><li><strong>FRAC_WITH_RARE :</strong> Fraction of individual carrying rare variants below –max-maf (default : 0.05) threshold.</li><li><strong>NUM_ALL_VARS :</strong> Number of all variants defining the group.</li><li><strong>NUM_PASS_VARS :</strong> Number of variants passing the –min-maf, –min-mac, –max-maf, –min-callrate thresholds</li><li><strong>NUM_SING_VARS :</strong> Number of singletons among variants in NUM_PASS_VARS<br>PVALUE : P-value of burden tests</li><li>Other columns are test specific auxiliary columns. For example, in the VT test, the optimal MAF threshold is recorded as an auxiliary output column.</li></ul><h2 id="4-4-Specialized-Instruction-for-EMMAX-tests"><a href="#4-4-Specialized-Instruction-for-EMMAX-tests" class="headerlink" title="4.4 Specialized Instruction for EMMAX tests"></a>4.4 Specialized Instruction for EMMAX tests</h2><p>EMMAX (Efficient Mixed Model Association eXpedited - Kang et al (2010) Nat Genet 42:348-54) is an efficient implementation of mixed model association accounting for sample structure including population structure and hidden relatedness. Currently EPACTS supports EMMAX association mapping in single variant test and CMC-like burden tests.</p><p>Because EMMAX is based on linear model, the method fits better to quantiative traits than binary traits. However, p-values for binary traits are expected to be valid in the spirit of Armitage trend test, although the estimated effect size may not be precise.</p><p>In order to run EMMAX analysis from sequence-based genotypes. We recommend running EPACTS multiple times using the following procedure.</p><h4 id="4-4-1-Single-Variant-EMMAX-Association-Analysis"><a href="#4-4-1-Single-Variant-EMMAX-Association-Analysis" class="headerlink" title="4.4.1 Single Variant EMMAX Association Analysis"></a>4.4.1 Single Variant EMMAX Association Analysis</h4><ul><li><strong>Creating Kinship Matrix :</strong> From VCF, we recommend to set a MAF (e.g. 0.01) and call rate (e.g. 0.95) threshold to select high-quality markers to generate kinship matrix as follows:</li></ul><pre><code>$&#123;EPACTS_DIR&#125;/epacts make-kin \ --vcf [input.vcf.gz] --ped  [input.ped (Optional)] --min-maf 0.01 --minCallRate 0.95 \ --sepchr (if VCF is separated by chromosome) --out [outprefix.kinf] --run [# of parallel jobs]</code></pre><p>If you provide [input.ped] file, then it will calculate the subset the individuals contained in the PED file.</p><p>The procedure above will create a file [outprefix.kinf] after splitting and merging the genomes into multiple pieces. If only a certain subset of SNPs needs to be considered due to target regions, LD-pruning, or any other reasons, a VCF containing the subset of markers must be created beforehand and should be used as input VCF file.</p><ul><li><strong>Perform Single Variant Association :</strong> From VCF and PED, we recommend to use less stringent MAF threshold (e.g. 0.001) and call rate (e.g. 0.50) to perform single variant association</li></ul><pre><code>$&#123;EPACTS_DIR&#125;/epacts single \ --vcf [input.vcf.gz] --ped  [input.ped] --min-maf 0.001 --kin [outputprefix.kinf] \ --sepchr --pheno [PHENO_NAME] --cov [COV1] --cov [COV2] --test q.emmax \ --out [outprefix] --run [# of parallel jobs]</code></pre><p>The procedure above will perform single variant association analysis compatible to other types of single variant association analyses implemented in EPACTS</p><h4 id="4-4-2-Burden-style-EMMAX-Association-Analysis"><a href="#4-4-2-Burden-style-EMMAX-Association-Analysis" class="headerlink" title="4.4.2 Burden-style EMMAX Association Analysis"></a>4.4.2 Burden-style EMMAX Association Analysis</h4><p>In order to run EMMAX analysis from sequence-based genotypes. We recommend running EPACTS multiple times using the following procedure.</p><h5 id="Creating-Kinship-Matrix-See-‘Creating-Kinship-Matrix’-section-in-Single-Variant-EMMAX-Association-Analysis"><a href="#Creating-Kinship-Matrix-See-‘Creating-Kinship-Matrix’-section-in-Single-Variant-EMMAX-Association-Analysis" class="headerlink" title="Creating Kinship Matrix : See ‘Creating Kinship Matrix’ section in #Single Variant EMMAX Association Analysis"></a>Creating Kinship Matrix : See ‘Creating Kinship Matrix’ section in #Single Variant EMMAX Association Analysis</h5><h5 id="Create-Marker-Group"><a href="#Create-Marker-Group" class="headerlink" title="Create Marker Group**"></a>Create Marker Group**</h5><ul><li>By annotating the VCF and extracting missense and nonsense variants:<br> #Annotating VCF file using ANNOVAR - This step will be required to create marker group file<br> #Creating marker group file - Assume that [group.grp] file is produced</li><li>Or, by creating your own marker group information<br> See #Creating marker group file for details</li></ul><h5 id="Run-CMC-style-burden-test-by"><a href="#Run-CMC-style-burden-test-by" class="headerlink" title="Run CMC-style burden test by"></a>Run CMC-style burden test by</h5><pre><code>$&#123;EPACTS_DIR&#125;/epacts group --groupf [group.grp] \ --vcf [input.vcf.gz] --ped  [input.ped] --max-maf [max-MAF-for-rare-variants] \ --kin [outputprefix.kinf] --sepchr --pheno [PHENO_NAME] --cov [COV1] --cov [COV2] \ --test emmaxCMC --out [outprefix]</code></pre><h5 id="Run-Variable-Threshold-burden-test-by"><a href="#Run-Variable-Threshold-burden-test-by" class="headerlink" title="Run Variable Threshold burden test by"></a>Run Variable Threshold burden test by</h5><pre><code>$&#123;EPACTS_DIR&#125;/epacts group --groupf [group.grp] \ --vcf [input.vcf.gz] --ped  [input.ped] --max-maf [max-MAF-for-rare-variants] \ --kin [outputprefix.kinf] --sepchr --pheno [PHENO_NAME] --cov [COV1] --cov [COV2] \ --test emmaxVT --out [outprefix]</code></pre><h4 id="4-5-Preparing-Your-Own-Input-Data"><a href="#4-5-Preparing-Your-Own-Input-Data" class="headerlink" title="4.5 Preparing Your Own Input Data"></a>4.5 Preparing Your Own Input Data</h4><h5 id="4-5-1-VCF-file-for-Genotypes"><a href="#4-5-1-VCF-file-for-Genotypes" class="headerlink" title="4.5.1 VCF file for Genotypes"></a>4.5.1 VCF file for Genotypes</h5><p>EPACTS support VCF files as input for association with the following requirement</p><p>Input VCF file must be bgzipped and tabixed before running association to allow efficient random access of the file. Below is an example command to conver plain VCF into bgzipped and tabixed VCF</p><pre><code>bgzip input.vcf     ## this command will produce input.vcf.gztabix -pvcf -f input.vcf.gz  ## this command will produce input.vcf.gz.tbi</code></pre><ul><li>If the VCF file is separated by chromosome, the VCF file specified in the input argument must contain the string “chr1” in the chromosome 1 file, and corresponding chromosome name for other chromosomes. Thus, the files names should be like [prefix]chr1[suffix].vcf.gz, [prefix]chr2[suffix].vcf.gz, …, [prefix]chr22[suffix].vcf.gz, [prefix]chrX[suffix].vcf.gz.</li><li>Sample IDs in the VCF file must be consistent to those from PED file</li><li>Currently EPACTS only support bi-allelic variants, but it handles SNPs, INDELs, snd SVs.</li><li>Currently, EPACTS only support VCF aligned with NCBI build 37 coordinates</li><li>An example VCF file from 1000 genome project is below.<br>$ zcat example&#x2F;1000G_integrated_phase1_chr20.vcf.gz | cut -f 1-10 | head -50</li></ul><pre><code>##fileformat=VCFv4.1##INFO=&lt;ID=LCSNP,Number=0,Type=Flag,Description=&quot;Genotype likelihood in Low coverage VCF in data integration&quot;&gt;##INFO=&lt;ID=EXSNP,Number=0,Type=Flag,Description=&quot;Genotype likelihood in Exome VCF in data integration&quot;&gt;##INFO=&lt;ID=INDEL,Number=0,Type=Flag,Description=&quot;Genotype likelihood in INDEL VCF in data integration&quot;&gt;##INFO=&lt;ID=SV,Number=0,Type=Flag,Description=&quot;Genotype likelihood in SV VCF in data integration&quot;&gt;##INFO=&lt;ID=BAVGPOST,Number=1,Type=Float,Description=&quot;Average posterior probability from beagle&quot;&gt;##INFO=&lt;ID=BRSQ,Number=1,Type=Float,Description=&quot;Genotype imputation quality estimate from beagle&quot;&gt;##INFO=&lt;ID=LDAF,Number=1,Type=Float,Description=&quot;MLE Allele Frequency Accounting for LD&quot;&gt;##INFO=&lt;ID=AVGPOST,Number=1,Type=Float,Description=&quot;Average posterior probability from MaCH/Thunder&quot;&gt;##INFO=&lt;ID=RSQ,Number=1,Type=Float,Description=&quot;Genotype imputation quality from MaCH/Thunder&quot;&gt;##INFO=&lt;ID=ERATE,Number=1,Type=Float,Description=&quot;Per-marker Mutation rate from MaCH/Thunder&quot;&gt;##INFO=&lt;ID=THETA,Number=1,Type=Float,Description=&quot;Per-marker Transition rate from MaCH/Thunder&quot;&gt;##INFO=&lt;ID=CIEND,Number=2,Type=Integer,Description=&quot;Confidence interval around END for imprecise variants&quot;&gt;##INFO=&lt;ID=CIPOS,Number=2,Type=Integer,Description=&quot;Confidence interval around POS for imprecise variants&quot;&gt;##INFO=&lt;ID=END,Number=1,Type=Integer,Description=&quot;End position of the variant described in this record&quot;&gt;##INFO=&lt;ID=HOMLEN,Number=.,Type=Integer,Description=&quot;Length of base pair identical micro-homology at event breakpoints&quot;&gt;##INFO=&lt;ID=HOMSEQ,Number=.,Type=String,Description=&quot;Sequence of base pair identical micro-homology at event breakpoints&quot;&gt;##INFO=&lt;ID=SOURCE,Number=.,Type=String,Description=&quot;Source of deletion call&quot;&gt;##INFO=&lt;ID=SVLEN,Number=1,Type=Integer,Description=&quot;Difference in length between REF and ALT alleles&quot;&gt;##INFO=&lt;ID=SVTYPE,Number=1,Type=String,Description=&quot;Type of structural variant&quot;&gt;##INFO=&lt;ID=AC,Number=.,Type=Integer,Description=&quot;Alternate Allele Count&quot;&gt;##INFO=&lt;ID=AN,Number=1,Type=Integer,Description=&quot;Total Allele Count&quot;&gt;##ALT=&lt;ID=DEL,Description=&quot;Deletion&quot;&gt;##FORMAT=&lt;ID=GT,Number=1,Type=String,Description=&quot;Genotype&quot;&gt;##FORMAT=&lt;ID=DS,Number=1,Type=Float,Description=&quot;Genotype dosage from MaCH/Thunder&quot;&gt;##FORMAT=&lt;ID=GL,Number=.,Type=Float,Description=&quot;Genotype Likelihoods&quot;&gt;##FORMAT=&lt;ID=BD,Number=1,Type=Float,Description=&quot;Genotype dosage from beagle&quot;&gt;#CHROM POS ID  REF ALT QUAL    FILTER  INFO    FORMAT  HG0009620 60479   .   C   T   100 PASS    LCSNP;EXSNP;BAVGPOST=1.000;BRSQ=0.894;LDAF=0.0020;AVGPOST=0.9995;RSQ=0.8779;ERATE=0.0005;THETA=0.0008;AC=4;AN=2184  GT:DS:GL:BD 0|0:0.000:-0.19,-0.46,-2.68:0.002220 60522   .   T   TC  1588    PASS    INDEL;BAVGPOST=1.000;BRSQ=0.994;LDAF=0.0116;AVGPOST=0.9980;RSQ=0.9327;ERATE=0.0004;THETA=0.0167;AC=24;AN=2184   GT:DS:GL:BD 0|0:0.000:0.00,-0.90,-9.20:020 60571   .   C   A   100 PASS    LCSNP;EXSNP;BAVGPOST=0.999;BRSQ=0.813;LDAF=0.0029;AVGPOST=0.9986;RSQ=0.8085;ERATE=0.0014;THETA=0.0014;AC=5;AN=2184  GT:DS:GL:BD 0|0:0.000:-0.05,-0.96,-5.00:0.000820 60795   .   G   C   100 PASS    LCSNP;EXSNP;BAVGPOST=1.000;BRSQ=0.930;LDAF=0.0006;AVGPOST=0.9996;RSQ=0.7205;ERATE=0.0003;THETA=0.0041;AC=1;AN=2184  GT:DS:GL:BD 0|0:0.000:-0.03,-1.21,-5.00:0.000120 60810   .   G   GA  127 PASS    INDEL;BAVGPOST=1.000;BRSQ=0.862;LDAF=0.0013;AVGPOST=0.9987;RSQ=0.5684;ERATE=0.0004;THETA=0.0061;AC=2;AN=2184    GT:DS:GL:BD 0|0:0.000:0.00,-1.80,-18.80:0</code></pre><h5 id="4-5-2-PED-file-for-Phenotypes-and-Covariates"><a href="#4-5-2-PED-file-for-Phenotypes-and-Covariates" class="headerlink" title="4.5.2 PED file for Phenotypes and Covariates"></a>4.5.2 PED file for Phenotypes and Covariates</h5><p>EPACTS accepts a PED format supported by MERLIN or PLINK software to represent phenotypes. For example, the example.ped file and example.dat file can represent the phenotypes and corresponding column name (from 6th column and after).</p><pre><code>$ head example.ped13281  NA12344 NA12347 NA12348 1   1   94.17   66.113281  NA12347 0   0   1   1   109.54  44.013281  NA12348 0   0   2   2   119.40  46.61328   NA06984 0   0   1   2   87.72   39.31328   NA06989 0   0   2   1   100.60  41.71328   NA12329 NA06984 NA06989 2   1   100.85  46.413291  NA06986 0   0   1   2   91.94   61.913291  NA06995 NA07435 NA07037 1   2   104.36  57.413291  NA06997 NA06986 NA07045 2   2   107.53  53.1</code></pre><pre><code>$ cat example.datA DISEASET QTT AGE</code></pre><p>EPACTS also accept a PED format with header information. The above file can be combined into one file as follows</p><pre><code>$ head data/1000G_dummy_pheno.ped#FAM_ID    IND_ID  FAT_ID  MOT_ID  SEX DISEASE QT  AGE13281  NA12344 NA12347 NA12348 1   1   94.17   66.113281  NA12347 0   0   1   1   109.54  44.013281  NA12348 0   0   2   2   119.40  46.61328   NA06984 0   0   1   2   87.72   39.31328   NA06989 0   0   2   1   100.60  41.71328   NA12329 NA06984 NA06989 2   1   100.85  46.413291  NA06986 0   0   1   2   91.94   61.913291  NA06995 NA07435 NA07037 1   2   104.36  57.413291  NA06997 NA06986 NA07045 2   2   107.53  53.1The column names can be used to identify the names of phenotypes and covariates in the analysis.</code></pre><h1 id="5-Detailed-Options"><a href="#5-Detailed-Options" class="headerlink" title="5. Detailed Options"></a>5. Detailed Options</h1><p>The detailed options can viewed by running the following commands</p><pre><code>$&#123;EPACTS_DIR&#125;/bin/epacts -man           (for overall structure) $&#123;EPACTS_DIR&#125;/bin/epacts single -man    (for single variant test)$&#123;EPACTS_DIR&#125;/bin/epacts group -man     (for groupwise test)$&#123;EPACTS_DIR&#125;/bin/epacts anno -man      (for annotation)$&#123;EPACTS_DIR&#125;/bin/epacts plot -man      (for QQ and Manhattan plot)$&#123;EPACTS_DIR&#125;/bin/epacts zoom -man      (for zoom plot)$&#123;EPACTS_DIR&#125;/bin/epacts meta -man      (for meta-analysis)$&#123;EPACTS_DIR&#125;/bin/epacts make-group -man (for creating gene group)</code></pre><h1 id="6-Implementing-Additional-Statistical-Tests"><a href="#6-Implementing-Additional-Statistical-Tests" class="headerlink" title="6. Implementing Additional Statistical Tests"></a>6. Implementing Additional Statistical Tests</h1><p>In order to add additional statistical test to EPACTS, the following procedure are recommended</p><ol><li>Create a file named ‘single.[testname].R’ for single variant test or ‘gene.[testname].R’ for gene-level test under ${EPACTS_DIR}&#x2F;share&#x2F;EPACTS&#x2F;</li><li>Test your implementation using –test [testname] option to perform sanity check and debugging</li><li>If you want to add your test in the official in-house version, please send your code to Hyun</li></ol><p>Below is an example of a single variant test implementation ( single.q.lm.R )</p><pre><code>## Core functions of EPACTS to perform association#################################################################### SINGLE VARIANT TEST## INPUT VARIABLES:##   n        : total # of individuals##   NS       : number of called samples##   AC       : allele count##   MAF      : minor allele frequency##   vids     : indices from 1:nrow(NS) after AF/AC threshold##   genos    : genotype matrix (after AF/AC threshold)## EXPECTED OUTPUT : list(p, addcols, addnames) for each genos row##   p        : p-value##   add      : additional columns to add##   cname    : column names for additional columns##################################################################  ## single.lm() : Use built-in lm() function to perform association## KEY FEATURES : SIMPLE, BUT MAY BE SLOW##                GOOD SNIPPLET TO START A NEW FUNCTION## TRAITS  : QUANTITATIVE## RETURNS : PVALUE, BETA, SEBETA, TSTAT## MISSING VALUES : IGNOREDsingle.q.lm &lt;- function() &#123;  cname &lt;- c(&quot;BETA&quot;,&quot;SEBETA&quot;,&quot;TSTAT&quot;) # column names for additional variables in the EPACTS output  m &lt;- nrow(genos)  p &lt;- rep(NA,m)  add &lt;- matrix(NA,m,3) ## BETA, SEBETA, TSTAT  if ( m &gt; 0 ) &#123;   for(i in 1:m) &#123;     r &lt;- summary(lm(pheno~genos[i,]+cov-1))$coefficients[1,]  # run simple linear regression     p[i] &lt;- r[4]   # store p-value to p[i]     add[i,] &lt;- r[1:3] # store additional variables to add[i,]   &#125; &#125; return(list(p=p,add=add,cname=cname))&#125;</code></pre><p>As described in the comment, you may assume that the following variables are available for use for testing association across m markers</p><ul><li>n (scalar) : total number of individuals</li><li>NS (M * 1 vector) : Number of called samples for each marker</li><li>AC (M * 1 vector) : Non-reference allele count for each marker</li><li>MAF (M * 1 vector) : Minor allele frequency</li><li>vids (m * 1 vector) : indices of markers passing the inclusion criteria (e.g. MAF threshold) among 1:M</li><li>genos (m * n matrix) : genotype matrix as a input for association test</li></ul><p>The output variables to generate is as follows</p><ul><li>p (m * 1 vector) : p-value matrix as output</li><li>add (m * c matrix) : additional columns as output of test (such as SCORE, BETA, etc)</li><li>cname (c * 1 vector) : column names of add</li></ul><p>In the output files, the following columns will be displayed</p><ol><li>MARKER : Marker ID</li><li>NS : Number of called samples</li><li>AC : Non-ref allele count</li><li>CALLRATE : Call rate &#x3D; NS&#x2F;n</li><li>MAF : Minor allele frequency</li><li>PVALUE : P-values</li><li>Additional columns specified by return values ‘add’</li></ol><p>Below is an example of a gene-lvel variant test implementation ( single.q.lm.R )</p><pre><code>#################################################################### GENE-LEVEL BURDEN TEST## INPUT VARIABLES: ##   n        : total # of individuals##   genos    : genotype matrix for each gene##   NS       : number of called samples for each marker##   AC       : allele count for each marker##   MAC      : minor allele count for each marker##   MAF      : minor allele frequency##   vids     : indices from 1:n after AF/AC threshold## EXPECTED OUTPUT : list(p, addcols, addnames) for each genos row##   p        : p-value##   add      : additional column values##   cname    : additional column names##################################################################      ## gene.q.reverse() : Reverse logistic regression## KEY FEATURES : 0/1 collapsing variable ~ rare variants## TRAITS  : QUANTITATIVE (GAUSSIAN)## RETURNS : PVALUE, BETA, SEBETA, ZSTAT## MISSING VALUE : IMPUTED AS MAJOR ALLELESgene.q.reverse &lt;- function() &#123;  cname &lt;- c(&quot;BETA&quot;,&quot;SEBETA&quot;,&quot;ZSTAT&quot;)  m &lt;- nrow(genos)  if ( m &gt; 0 ) &#123;    g &lt;- as.double(colSums(genos,na.rm=T) &gt; 0)    sg &lt;- sum(g)    if ( ( sg &gt; 0 ) &amp;&amp; ( sg &lt; n ) ) &#123;      r &lt;- glm(g~pheno+cov-1,family=binomial)       if ( ( r$converged ) &amp;&amp; ( ! r$boundary ) ) &#123;        return(list(p=summary(r)$coefficients[1,4],                    add=summary(r)$coefficients[1,1:3],                    cname=cname))      &#125;    &#125;  &#125;  return(list(p=NA,add=rep(NA,3),cname=cname))&#125;</code></pre><p>Similar to gene-level test, you may assume the following variables exist for testing A SINGLE GENE. Note that M is the number of markers spanning the gene region</p><ul><li>n (scalar) : total number of individuals</li><li>NS (M * 1 vector) : Number of called samples for each marker</li><li>AC (M * 1 vector) : Non-reference allele count for each marker</li><li>MAC (M * 1 vector) : Minor allele count</li><li>MAF (M * 1 vector) : Minor allele frequency</li><li>vids (m * 1 vector) : indices of markers passing the inclusion criteria (e.g. MAF threshold) among 1:M</li><li>genos (m * n matrix) : genotype matrix as a input for association test</li></ul><p>The output variables to generate is as follows</p><ul><li>p (scalar) : p-value matrix as output</li><li>add (c * 1 vector) : additional columns as output of test (such as SCORE, BETA, etc)</li><li>cname (c * 1 vector) : column names of add</li><li>In the output files, the following columns will be displayed</li></ul><ol><li>MARKER : Marker ID</li><li>NS : Number of called samples</li><li>MAF_BURDEN : MAF of 0&#x2F;1 collapsing variables (existence of rare variants)</li><li>NUM_ALL_VARS : Number of all variants within the gene</li><li>NUM_RARE_VARS : Number of rare variants below the max-MAF threshold</li><li>NUM_SING_VARS : Number of singleton variants</li><li>PVALUE : P-value from the test</li><li>Additional columns specified by return values ‘add’</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>GWAS|GMMAT安装及使用指南</title>
      <link href="/2020-06-13-gwas-gmmat-an-zhuang-ji-shi-yong-jiao-cheng/"/>
      <url>/2020-06-13-gwas-gmmat-an-zhuang-ji-shi-yong-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<font face="times new roman" size=4><span id="more"></span><p>GWAS|GMMAT安装及使用指南</p><!-- toc --><hr><h1 id="1Introduction"><a href="#1Introduction" class="headerlink" title="1Introduction"></a>1Introduction</h1><p>GMMAT is an R package for performing association tests using generalized linear mixed models (GLMMs)1 in genome-wide association studies (GWAS) and sequencing associa- tion studies. GLMMs provide a broad range of models for correlated data analysis. In  the GWAS and sequencing association study context, examples of correlated data include those from family studies, samples with cryptic relatedness and&#x2F;or shared environmental effects, as well as samples generated from complex sampling designs.</p><p>GMMAT first fits a GLMM with covariate adjustment and random effects to account for population structure and family or cryptic relatedness. </p><ul><li><strong>For GWAS</strong>, GMMAT performs score tests for each genetic variant. </li><li><strong>For candidate gene studies</strong>, GMMAT can also perform Wald tests to get the effect size estimate for each genetic variant. </li><li><strong>For rare variant analysis</strong> from sequencing association studies, GMMAT performs the <code>burden test</code>, <code>the sequence kernel association test (SKAT)</code>, <code>SKAT-O</code> and <code>the efficient hybrid test of the burden test and SKAT</code>, in the variant <strong>Set Mixed Model Association Tests (SMMAT)</strong> framework, based on user-defined variant sets.</li></ul><h1 id="2The-model"><a href="#2The-model" class="headerlink" title="2The model"></a>2The model</h1><p>In the context of single variant test, GMMAT works with the following GLMM</p><p><em>ηi &#x3D; g(µi) &#x3D; Xiα + Giβ + bi</em></p><h1 id="3Getting-started"><a href="#3Getting-started" class="headerlink" title="3Getting started"></a>3Getting started</h1><h2 id="3-1Installing-GMMAT"><a href="#3-1Installing-GMMAT" class="headerlink" title="3.1Installing GMMAT"></a>3.1Installing GMMAT</h2><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">install.packages("GMMAT")<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">install.packages(c("devtools",  "RcppArmadillo",  "CompQuadForm",  "doMC", "foreach", "Matrix",  "BiocManager",  "testthat"))<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">if (!requireNamespace("BiocManager", quietly = TRUE))    install.packages("BiocManager")BiocManager::install(c("SeqArray","SeqVarTools"))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h1 id="4Input"><a href="#4Input" class="headerlink" title="4Input"></a>4Input</h1><p>GMMAT requires the phenotype and covariates in an R data frame, known positive semi- definite matrices Vk as an R matrix (in the case of a single matrix) or an R list (in the case of multiple matrices), and genotypes saved in a plain text file (or in a compressed plain text file .gz or .bz2), a PLINK binary PED file, or in a GDS format file. We describe how to prepare these data below.</p><h2 id="4-1Phenotype-and-covariates"><a href="#4-1Phenotype-and-covariates" class="headerlink" title="4.1Phenotype and covariates"></a>4.1Phenotype and covariates</h2><p>For example, here we show the header and first 6 rows of the example text file pheno.txt:</p><pre><code>iddiseasetraitagesex115.45610215.61501303.1540416.22481515.42490606.22501...</code></pre><p>In this example, there are an ID column (id), one binary phenotype (disease), one quantitative phenotype (trait) and two covariates (age and sex). There can be additional columns for unused variables, and the order of columns does not matter. To read it into  R as a data frame, you can use</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">pheno.file  <-  system.file("extdata",  "pheno.txt",  package  =  "GMMAT")pheno  <-  read.table(pheno.file,  header  =  TRUE)# Missing values in the data frame should be recognizable by  R as NA. For  example, if  you use . (period) to denote missing values in the text file, you can usepheno  <-  read.table(pheno.file,  header  =  TRUE,  na.strings  =  ".")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="4-2Matrices-of-covariance-structure"><a href="#4-2Matrices-of-covariance-structure" class="headerlink" title="4.2Matrices of covariance structure"></a>4.2Matrices of covariance structure</h2><p>GMMAT requires at least one positive semi-definite matrix Vk to model the covariance structure of the random effects (for cross-sectional data). In the simplest case, this is usually a GRM estimated from the genotype data. <strong>Currently GMMAT does not provide  a function to calculate the GRM</strong>, but there are many software packages that can do this job. For example, <strong>GEMMA</strong> can be used to estimate either the centered GRM or the standardized GRM. GRM saved in an external file must be read into R as a matrix. For example</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">GRM.file  <-  system.file("extdata",  "GRM.txt.bz2",  package  =  "GMMAT")GRM  <-  as.matrix(read.table(GRM.file,  check.names  =  FALSE))# This matrix can include more than n individuals in practice, but the rownames and colnames must include all individuals’ id in the phenotype and covariates data frame. Multiple matrices can be used to allow multiple components of random effects. In such cases, the matrices should be constructed as a list of matrices, and each matrix should comply with the rownames and colnames requirements described above (although they don’t have to be in the same order). For example, if you have 3 R matrices Mat1, Mat2 and Mat3, you can construct the R listMats  <-  list(Mat1,  Mat2,  Mat3)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>All matrices must be positive semi-definite. Sparse matrices from the Matrix package are also allowed.</p><h2 id="4-3Genotypes"><a href="#4-3Genotypes" class="headerlink" title="4.3Genotypes"></a>4.3Genotypes</h2><p>GMMAT can take genotype files either in plain text format (or the compressed version<br>.gz or .bz2), PLINK binary PED format, or in the GDS format. Non-integer imputed genotypes (dosages) should be saved  in plain text files (or the compressed version .gz   or .bz2). The plain text file can be space-, tab-, comma-, or even special character- delimited, and there can be additional rows (e.g., comments) and&#x2F;or columns before the genotype data matrix. Here is an example of part of a tab-delimited plain text genotype file geno.txt:</p><pre><code>#  This  is  an  example  genotype  file  for  demonstrating  GMMAT# Each row represents one SNP for all individuals in the study#  First  column  is  SNP  name,  second  and  third  columns  are  alleles  (Allele1 and  Allele2):  it  is  recommended  to  use  Allele1  for  the  reference  allele and  Allele2  for  the  effect  allele,  but  reversed  coding  is  also  allowed and does not affect association test results (users should be cautious with  allele  coding  when  interpreting  results)#  Starting  from  fourth  column,  each  column  represents  one  individual #  In  this  example,  there  are  400  individuals  and  100  SNPsSNP1AT00NANA...SNP2AC1010...SNP3AC0001...SNP4AG1011...SNP5AG1021...```Genotypes in Variant Call Format (VCF) and PLINK binary PED format can be converted to the GDS format using seqVCF2GDS and seqBED2GDS functions from the SeqArray package:```&#123;r&#125;SeqArray::seqVCF2GDS(&quot;VCF_file_name&quot;,  &quot;GDS_file_name&quot;)SeqArray::seqBED2GDS(&quot;BED_file_name&quot;,  &quot;FAM_file_name&quot;,  &quot;BIM_file_name&quot;, &quot;GDS_file_name&quot;)</code></pre><h2 id="5Running-GMMAT"><a href="#5Running-GMMAT" class="headerlink" title="5Running GMMAT"></a>5Running GMMAT</h2><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">#If GMMAT has been successfully installed, you can load it in an R session usinglibrary(GMMAT)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>We provide 6 functions in GMMAT : </p><ul><li><p>glmmkin for fitting the GLMM with known Vk</p></li><li><p>glmm.score for running single variant score tests</p></li><li><p>glmm.wald for single variant Wald tests</p></li><li><p>glmm.score.meta for performing meta-analysis on score test results</p></li><li><p>SM-MAT for running variant set tests SMMAT (also known as gene-based tests or aggregate variant tests)</p></li><li><p>SMMAT.meta for performing variant set tests meta-analysis using intermediate files (single variant scores and their covariance matrices in each variant set, from the SMMAT function). </p><p>Details about how to use these functions, their arguments and returned values can be found in the R help document of GMMAT.</p></li></ul><h4 id="5-1Fitting-GLMM"><a href="#5-1Fitting-GLMM" class="headerlink" title="5.1Fitting GLMM"></a>5.1Fitting GLMM</h4><p>Here we provide a simple example of fitting GLMM using glmmkin. We have the binary phenotype disease, the quantitative phenotype trait, and two covariates age and sex,  saved in a plain text file pheno.txt. We also have computed the GRM externally and  saved it in a compressed file GRM.txt.bz2. In this example we fit a GLMM assuming Bernoulli distribution of the disease and logit link function (also known as a logistic mixed model). We adjust for age and sex, and use one <em>n</em> x <em>n</em> matrix as Vk (the GRM) to model the covariance structure of the random effects.</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">model0  <-  glmmkin(disease  ~  age  +  sex,  data  =  pheno,  kins  =  GRM, id  =  "id",  family  =  binomial(link  =  "logit"))model0$thetamodel0$coefficientsmodel0$cov<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>Note that pheno and GRM must be read into R as a data frame and a matrix, respectively. When using the function glmmkin, the data frame of phenotype and covariates (in our example, pheno) should be passed to the argument ”data”, and the matrix or the list of matrices for random effects (in our example, the matrix GRM) should be passed  to the argument ”kins”. The first argument of the function glmmkin is ”fixed”, which requires a formula for fixed effects. The syntax of the formula is the same as the formula used in a linear model lm and a generalized linear model glm. The example model above is equivalent to</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">model0  <-  glmmkin(fixed  =  disease  ~  age  +  sex,  data  =  pheno,  kins  =  GRM, id  =  "id",  family  =  binomial(link  =  "logit"))<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>The argument ”id” specifies the ID column name in the data frame pheno. The argument ”family” takes the same syntax as used in a generalized linear model glm. For example, if you would like to fit a LMM for a quantitative trait, you can use</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">model1  <-  glmmkin(fixed  =  trait  ~  age  +  sex,  data  =  pheno,  kins  =  GRM,id  =  "id",  family  =  gaussian(link  =  "identity"))<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>Please avoid using LMMs for binary traits.</strong></p><p>To fit a heteroscedastic LMM for a quantitative trait (allowing heterogeneous residual variances among different groups), you can use</p><pre><code>model2  &lt;-  glmmkin(fixed  =  trait  ~  age  +  sex,  data  =  pheno,  kins  =  GRM,id  =  &quot;id&quot;,  groups  =  &quot;disease&quot;, family  =  gaussian(link  =  &quot;identity&quot;))model2$theta</code></pre><p>In this example, groups are defined by disease status. Therefore, disease cases and controls are assumed to have different residual variances on the quantitative trait, after adjusting for age and sex.</p><p>In the following example, we have the same binary phenotype disease, covariates age and sex, and the same GRM as in the previous example. In addition to the GRM, we  have another n n matrix to model the covariance structure of the random effects.</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">M10  <-  matrix(0,  400,  400)for(i  in  1:40)  M10[(i-1)*10+(1:10),  (i-1)*10+(1:10)]  <-  1rownames(M10)  <-  colnames(M10)  <-  1:400Mats  <-  list(GRM,  M10)model3  <-  glmmkin(fixed  =  disease  ~  age  +  sex,  data  =  pheno,  id  =  "id", kins  =  Mats,  family  =  binomial(link  =  "logit"))model3$theta<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>For longitudinal data, the following example illustrates a random intercept only model, which is appropriate for analyzing repeated measures with no time trends. We have 5 exchangeable observations of the continuous phenotype y.repeated for each individual, adjusting for sex as a fixed effects covariate.</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">pheno2.file  <-  system.file("extdata",  "pheno2.txt",  package  =  "GMMAT")pheno2  <-  read.table(pheno2.file,  header  =  TRUE)model4  <-  glmmkin(y.repeated  ~  sex,  data  =  pheno2,  kins  =  GRM,  id  =  "id",family  =  gaussian(link  =  "identity"))model4$theta<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>The last example of this section illustrates a random intercept and random slope model, which is appropriate for analyzing longitudinal data with individual-specific time trends. We have observations of the continuous phenotype y.trend at 5 time points for each individual, adjusting for sex and time as fixed effects covariates. </p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">model5  <-  glmmkin(y.trend  ~  sex  +  time,  data  =  pheno2,  kins  =  GRM,  id  =  "id", random.slope  =  "time",  family  =  gaussian(link  =  "identity"))model5$theta<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="5-2Single-variant-tests"><a href="#5-2Single-variant-tests" class="headerlink" title="5.2Single variant tests"></a>5.2Single variant tests</h4><h5 id="5-2-1Score-tests"><a href="#5-2-1Score-tests" class="headerlink" title="5.2.1Score tests"></a>5.2.1Score tests</h5><p>When performing score tests in GWAS, we need a fitted GLMM under the null hypothesis H0 : β &#x3D; 0 and a genotype file. We can construct score tests using the glmmkin class object returned from the function glmmkin for the null GLMM. Note that score tests require only vector&#x2F;matrix multiplications and are much faster than Wald tests, which require fitting a new GLMM for each SNP. Score tests give the direction of effects but not effect size estimates. However, we can simply add score statistics and their variances from different studies to perform a meta-analysis. Here we provide a simple example of score tests using the plain text genotype file ”geno.txt”:</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">geno.file  <-  system.file("extdata",  "geno.txt",  package  =  "GMMAT")glmm.score(model0,  infile  =  geno.file,  outfile  ="glmm.score.text.testoutfile.txt",  infile.nrow.skip  =  5,infile.ncol.skip  =  3,  infile.ncol.print  =  1:3,infile.header.print  =  c("SNP",  "Allele1",  "Allele2"))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>The first argument in glmm.score is the returned glmmkin class object from the null GLMM. The argument ”infile” is the name (and path if not in the current working di- rectory) of the plain text genotype file (or compressed files .gz and .bz2), and the ar- gument ”outfile” is the name of the output file.  In this example genotype file, we  have    5 comment lines to skip using ”infile.nrow.skip”. The first 3 columns contain informa- tion on SNP name and alleles, which we skip from the analysis using ”infile.ncol.skip” but subsequently keep in the output file using ”infile.ncol.print” to select the 1st,  2nd   and 3rd columns. Corresponding column names in the output file can be assigned using ”infile.header.print”.<br>If your genotype information is saved in a PLINK binary PED file ”geno.bed”, you can use:</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">geno.file  <-  strsplit(system.file("extdata",  "geno.bed",package  =  "GMMAT"),  ".bed",  fixed  =  TRUE)[[1]]glmm.score(model0,  infile  =  geno.file,  outfile  ="glmm.score.bed.testoutfile.txt")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>Here ”infile” is the prefix (and path if not in the current working directory) of the PLINK files (.bed, .bim and .fam). SNP information in the .bim file (in our example, ”geno.bim”) is carried over to the output file.</p><p>Alternatively, if your genotype information is saved in a GDS file ”geno.gds”, you can use:</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">geno.file  <-  system.file("extdata",  "geno.gds",  package  =  "GMMAT")glmm.score(model0,  infile  =  geno.file,  outfile  ="glmm.score.gds.testoutfile.txt")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>The function glmm.score returns the actual computation time in seconds from its function call for plain text genotype files (or compressed files .gz and .bz2) and PLINK binary PED files. For GDS genotype files, no value is returned.</p><h5 id="5-2-2Wald-tests"><a href="#5-2-2Wald-tests" class="headerlink" title="5.2.2Wald tests"></a>5.2.2Wald tests</h5><p>When performing Wald tests for candidate SNPs to get effect size estimates, we need the phenotype (and covariates) data frame,  the matrices modeling the covariance  structure  of the random effects, and the genotype file. To perform Wald tests, we do not need fitting the null GLMM required in score tests using glmmkin. In the example below, we perform Wald tests for 4 candidate SNPs of interest and get their effect estimates:</p><pre><code>geno.file  &lt;-  system.file(&quot;extdata&quot;,  &quot;geno.txt&quot;,  package  =  &quot;GMMAT&quot;)snps  &lt;-  c(&quot;SNP10&quot;,  &quot;SNP25&quot;,  &quot;SNP1&quot;,  &quot;SNP0&quot;)glmm.wald(fixed  =  disease  ~  age  +  sex,  data  =  pheno,  kins  =  GRM,  id  =  &quot;id&quot;,family  =  binomial(link  =  &quot;logit&quot;),  infile  =  geno.file,  snps  =  snps,infile.nrow.skip  =  5,  infile.ncol.skip  =  3,  infile.ncol.print  =  1:3,infile.header.print  =  c(&quot;SNP&quot;,  &quot;Allele1&quot;,  &quot;Allele2&quot;))</code></pre><p>The syntax is a hybrid of glmmkin and glmm.score. Note that the argument ”fixed” is a formula including the covariates  but NOT the test SNPs.  The argument ”snps” is      a character vector of the names of the test SNPs. If ”infile” is a plain text genotype file  (or compressed files .gz and .bz2), the function glmm.wald returns a data frame with first columns copied from the genotype file using ”infile.ncol.print” and names specified using ”infile.header.print”, followed by the sample size N, the allele frequency (AF) of the effect allele (Allele2 in this example, but you can also define Allele1 as the effect allele in your coded genotype file), effect size estimate BETA of the effect allele, standard error SE, Wald test P value PVAL, and an indicator for whether the  GLMM  is converged. Note that in the example above, SNP0 is not actually included in the genotype file, so all results are missing.</p><p>If your genotype information is saved in a PLINK binary PED file ”geno.bed”, you can use:</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">geno.file  <-  strsplit(system.file("extdata",  "geno.bed",package  =  "GMMAT"),  ".bed",  fixed  =  TRUE)[[1]]glmm.wald(fixed  =  disease  ~  age  +  sex,  data  =  pheno,  kins  =  GRM,  id  =  "id",family  =  binomial(link  =  "logit"),  infile  =  geno.file,  snps  =  snps)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>It returns a data frame with first 6 columns copied from the .bim file (in our example, ”geno.bim”), followed by the sample size N, the allele frequency (AF) of A2 allele (the effect allele, note that A1 allele in .bim is coded 0 and A2 allele is coded 1), effect size estimate BETA of A2 allele, standard error SE, Wald test P value PVAL, and an indicator for whether the GLMM is converged.<br>Alternatively, if your genotype information is saved in a GDS file ”geno.gds”, you can use:</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">geno.file  <-  system.file("extdata",  "geno.gds",  package  =  "GMMAT")glmm.wald(fixed  =  disease  ~  age  +  sex,  data  =  pheno,  kins  =  GRM,  id  =  "id",    family  =  binomial(link  =  "logit"),  infile  =  geno.file,  snps  =  snps)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>It returns a data frame with first 5 columns information extracted from the GDS file, followed by the sample size N, the allele frequency (AF) of ALT allele, effect size estimate BETA of ALT allele, standard error SE, Wald test P value PVAL, and an indicator for whether the GLMM is converged.</p><h5 id="5-2-3Meta-analysis"><a href="#5-2-3Meta-analysis" class="headerlink" title="5.2.3Meta-analysis"></a>5.2.3Meta-analysis</h5><p>Score test results from multiple studies can be combined in meta-analysis. We provide the function glmm.score.meta to perform meta-analysis on score test results. Generally, if each study performs score tests using genotypes in PLINK binary PED format or    GDS format, the score test output from glmm.score can be directly used as input files. Otherwise the meta-analysis function needs a tab or space delimited plain text file (or compressed files that can be recognized by the R function read.table) with at least 8 columns: SNP name, effect allele, reference allele, N, AF, SCORE, VAR and PVAL. Note that the SNP name, effect allele, reference allele can have customized column names in different input files, but the column names of N, AF, SCORE, VAR and PVAL should match exactly. Customized SNP and alleles column names can be specified using ”SNP”, ”A1” and ”A2”.   Note that we  do not define whether ”A1” or ”A2” is the effect allele:      it is your choice.  However,  your choice should be consistent across different studies:   for example, if you have two studies with the same allele column names ”Allele1” and ”Allele2”, and you want to define ”A1” as the effect allele, but the effect allele is ”Allele1” in the first study and ”Allele2” in the second study, you need A2 &#x3D; c(”Allele2”, ”Allele1”) for the reference allele column in each study, and A1 &#x3D; c(”Allele1”, ”Allele2”) for the effect allele column in each study. Note that in glmm.score output from analyzing PLINK binary PED format genotypes, the effect allele has column name ”A2”, and in glmm.score output from analyzing GDS format genotypes, the effect allele has column name ”ALT”. Thus if you have a result file from analyzing PLINK binary PED format genotypes in the third study, and another result file from analyzing GDS format genotypes in the fourth study, in addition to the aforementioned two studies, and you still want to define ”A1” as the effect allele, you need A2 &#x3D; c(”Allele2”, ”Allele1”, ”A1”, ”REF”) for the reference allele column in each study, and A1 &#x3D; c(”Allele1”, ”Allele2”, ”A2”, ”ALT”) for the effect allele column in each study.<br>Here is an example of meta-analyzing 3 score test result files:</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">meta1.file  <-  system.file("extdata",  "meta1.txt",  package  =  "GMMAT")meta2.file  <-  system.file("extdata",  "meta2.txt",  package  =  "GMMAT")meta3.file  <-  system.file("extdata",  "meta3.txt",  package  =  "GMMAT")glmm.score.meta(files  =  c(meta1.file,  meta2.file,  meta3.file), outfile  =  "glmm.score.meta.testoutfile.txt", SNP  =  rep("SNP",  3),  A1  =  rep("A1",  3),  A2  =  rep("A2",  3))#### 5.3Variant set tests##### 5.3.1Pooled analysisVariant set tests (also known as gene-based tests or aggregate variant tests) in a single study (or a pooled analysis of multiple studies) can be performed using the function SMMAT. Currently only the GDS genotype format is supported. In addition to a glmmkin class object returned from the function glmmkin for the null GLMM and the GDS format genotype file, a group definition file with no header and 6 columns (variant set id, variant chromosome, variant position, variant reference allele, variant alternate Note that each variant in the group definition file is matched by chromosome, position, reference allele and alternate allele with variants  from the GDS file.  One genetic variant   can be included in different groups with possibly different weights.  If no external weights  are needed in the analysis, simply replace the 6th column by all 1’s.Four variant set tests are supported in the SMMAT framework: ”B” for the burden  test, ”S” for SKAT, ”O” for SKAT-O and ”E” for the efficient hybrid test of the burden test and SKAT. You can include one or more tests in a single analysis. If ”O” is selected, the burden test and SKAT results will be automatically included; if ”E” is selected, the burden test results will be automatically included. Therefore, the following example gives all four test results:```&#123;r&#125;group.file  <-  system.file("extdata",  "SetID.withweights.txt", package  =  "GMMAT")geno.file  <-  system.file("extdata",  "geno.gds",  package  =  "GMMAT")SMMAT(model0,  group.file  =  group.file,  geno.file  =  geno.file,MAF.range  =  c(1e-7,  0.5),  miss.cutoff  =  1,  method  =  "davies",tests  =  c("O",  "E"))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>It returns a data frame with first 8 columns showing the group (variant set) name, num- ber of variants in each group, minimum, mean, maximum missing rate of variants  in  each group, minimum, mean, maximum effect allele frequency of variants in each group, followed by variant set test results. For Burden, 3 columns will be included to show the burden test score, variance of the score, and its P value. For SKAT, the P value column will be included. For SKAT-O, 3 columns will be included to show SKAT-O P value, minimum P value in the search grid, and the value of the mixing parameter ρ at which the minimum P value is observed. For the efficient hybrid test, the P  value column will be included.</p><p>For a single study, intermediate files containing single variant scores and their covari- ance matrices for each variant set (based on the group definition file) can be saved for future use in re-analysis and&#x2F;or meta-analysis. For example, here we perform the burden test and save intermediate files:</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">SMMAT(model0,  group.file  =  group.file,  geno.file  =  geno.file,MAF.range  =  c(1e-7,  0.5),  miss.cutoff  =  1,  method  =  "davies",tests  =  "B",  meta.file.prefix  =  "SMMAT.meta")<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>In the example above, a space-delimited file ”SMMAT.meta.score.1” will be generated to save the single variant scores, and a binary file ”SMMAT.meta.var.1” will be generated to</p><p>save the covariance matrices for the variant sets. Note that the binary file is not human- readable, but can be used by SMMAT.meta in re-analysis and&#x2F;or meta-analysis.</p><h5 id="5-3-2Meta-analysis"><a href="#5-3-2Meta-analysis" class="headerlink" title="5.3.2Meta-analysis"></a>5.3.2Meta-analysis</h5><p>With intermediate files generated by SMMAT, the function SMMAT.meta can be used in re-analysis of single study results, and&#x2F;or meta-analysis to combine multiple studies. Here we show an example of rerunning SKAT using intermediate files generated above in the burden test:</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">SMMAT.meta(meta.files.prefix  =  "SMMAT.meta",  n.files  =  1,group.file  =  group.file,  MAF.range  =  c(1e-7,  0.5),miss.cutoff  =  1,  method  =  "davies",  tests  =  "S")<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>The first argument, ”meta.files.prefix”, is a vector of intermediate files’ prefix with length equal to the number of studies, and the second argument, ”n.files”, is a vector of integers showing how many sets of intermediate files each study has (also with length equal to the number of studies). In our above example of re-analysis, we have one set of intermedi- ate files (”SMMAT.meta.score.1” and ”SMMAT.meta.var.1”) with prefix ”SMMAT.meta”. The group definition file (passed to ”group.file”) should be the same as the one used to generate intermediate files by SMMAT (with possibly different weights allowed). In the above example, only SKAT is performed, but four variant set tests are supported in the SMMAT framework: ”B” for the burden test, ”S” for SKAT, ”O” for SKAT-O and ”E” for the efficient hybrid test of the burden test and SKAT. You can include one or more tests by passing a vector to the argument ”tests”. If ”O” is selected, the burden test and SKAT results will be automatically included; if ”E” is selected, the burden test results will be automatically included.</p><h2 id="6Output"><a href="#6Output" class="headerlink" title="6Output"></a>6Output</h2><p>The single variant score test function glmm.score generates a tab-delimited plain text output file. Here we show the header and the first five rows of the example output ”glmm.score.text.testoutfile.txt” from using a plain text genotype file ”geno.txt” in the function glmm.score:</p><pre><code>SNPAllele1Allele2NAFSCOREVARPVALSNP1AT3930.02544531.9854.556350.352406SNP2AC4000.53.5103246.33280.60606 SNP3AC4000.2075-0.533430.60230.923185SNP4AG4000.29875-3.1149440.51280.624567SNP5AG4000.59375-4.0013542.27570.538287...</code></pre><p>The first 3 columns are copied from the genotype file using ”infile.ncol.print” with names specified using ”infile.header.print”. Results are included in 5 columns: the sample size N, the allele frequency (AF) of the effect allele (Allele2 in this example, but it is the user’s choice: you can also define Allele1 as the effect allele in your coded genotype file), the score statistic SCORE of the effect allele, the variance of the score VAR, and score test  P value PVAL.</p><p>If you use a PLINK binary PED file ”geno.bed” as the genotype file, here are the header and the first 5 rows of the example output ”glmm.score.bed.testoutfile.txt” from glmm.score:</p><pre><code>CHRSNPcMPOSA1A2NAF1SNP101TA3930.9745551SNP202AC4000.51SNP303CA4000.79251SNP404GA4000.701251SNP505AG4000.59375...SCOREVARPVAL-1.9854.556350.3524063.5103246.33280.606060.533430.60230.9231853.1149440.51280.624567-4.0013542.27570.538287...</code></pre><p>The first 6 columns are copied from the .bim file (in our example, ”geno.bim”): the chromosome CHR, SNP name, genetic location cM, physical position POS, and alleles A1 and A2. Results are included in 5 columns: the sample size N, the allele frequency (AF) of A2 allele, the score statistic SCORE of A2 allele, the variance of the score VAR, and score test P value PVAL.</p><p>If you use a GDS genotype file ”geno.gds”, here are the header and the first 5 rows of the example output ”glmm.score.gds.testoutfile.txt” from glmm.score:</p><pre><code>SNPCHRPOSREFALTNMISSRATEAFSNP111TA3930.01750.974554707379135SNP212AC40000.5SNP313CA40000.7925SNP414GA40000.70125SNP515AG40000.59375...SCOREVARPVAL-1.984997739641174.556354198331280.3524061988416593.5103164202288246.33277042795540.6060598076216430.53340037613844630.60228467716080.9231853747865533.1149410113999240.51276100679120.624566559783622 -4.0013505007948542.27572106505490.538287231263494...</code></pre><p>The first 5 columns are extracted from the GDS file: SNP (”annotation&#x2F;id”), CHR (”chro- mosome”), POS (”position”), reference and alternate alleles (”allele”). Results are included in 6 columns: the sample size N (with non-missing genotypes), the genotype missing rate MISSRATE, the allele frequency (AF) of ALT allele, the score statistic SCORE of ALT allele, the variance of the score VAR, and score test P value PVAL.</p><p>The meta-analysis function glmm.score.meta generates a tab-delimited plain text output file. Here are the header and the first 5 rows of the example output from the meta-analysis ”glmm.score.meta.testoutfile.txt”:</p><pre><code>SNPA1A2NAFSCOREVARPVALL14AC100000.6589521.5371445.720.30766609304268L25AC100000.7842514.3376387.0910.466163476535903L7AC200000.5043533.11361019.1220.299608382095623L9AC300000.39875-33.0641904.8420.271687891048334L35AC100000.7842514.3376387.0910.466163476535903...</code></pre><p>The first 3 columns are set by the function glmm.score.meta to denote SNP name and alleles (your choice of either A1 or A2 as the effect allele). N is the total sample size, AF is the effect allele frequency, SCORE is the summary score statistic of the effect allele, VAR is the variance of the summary score statistic, and PVAL is the meta-analysis P value.<br>In variant set tests SMMAT, if ”meta.file.prefix” is specified, space-delimited inter- mediate files for single variant scores and binary intermediate files for covariance matrices will be generated. Here are the header and the first 5 rows of the example intermediate file ”SMMAT.meta.score.1”:</p><pre><code>group  chr  pos  ref  alt  N  missrate  altfreq Set1 1 1 T A 393 0.0175 0.974554707379135Set112AC40000.5Set113CA40000.7925Set114GA40000.70125Set115AG40000.59375...                    SCORE VAR PVAL-1.98499773963038 4.55635419833203 0.3524061988443163.51031642023436 46.3327704279556 0.6060598076210760.533400376147224 30.6022846771614 0.9231853747852943.11494101140768 40.5127610067916 0.62456655978276-4.00135050078827 42.2757210650552 0.538287231264163...</code></pre><p>The first 5 columns are copied from the group definition file, indicating the variant set (group) id, variant chromosome, variant position, variant reference allele, variant alternate allele, respectively. Results are included in 6 columns: the sample size N (with non- missing genotypes), the genotype missing rate missrate, the alt allele frequency altfreq, the score statistic SCORE of alt allele, the variance of the score VAR, and single variant score test P value PVAL.</p><h2 id="7Advanced-options"><a href="#7Advanced-options" class="headerlink" title="7Advanced options"></a>7Advanced options</h2><h4 id="7-1Alternative-model-fitting-algorithms"><a href="#7-1Alternative-model-fitting-algorithms" class="headerlink" title="7.1Alternative model fitting algorithms"></a>7.1Alternative model fitting algorithms</h4><p>By default we use the Average Information REML algorithm13,14 to fit the GLMM in glmmkin, which is computationally efficient and recommended in most cases. However, there are also alternative model fitting algorithms:</p><pre><code>method  =  &quot;REML&quot;,  method.optim  =  &quot;Brent&quot;</code></pre><p>It maximizes the restricted likelihood using the derivative-free Brent method,15 but only works when there is one matrix for the covariance structure of the random effects.</p><pre><code>method  =  &quot;ML&quot;,  method.optim  =  &quot;Brent&quot;</code></pre><p>It maximizes the likelihood using the Brent method.</p><pre><code>method  =  &quot;REML&quot;,  method.optim  =  &quot;Nelder-Mead&quot;</code></pre><p>It maximizes the restricted likelihood using the Nelder-Mead method,16 however it is usually very slow in large samples.</p><pre><code>method  =  &quot;ML&quot;,  method.optim  =  &quot;Nelder-Mead&quot;</code></pre><p>It maximizes the likelihood using the Nelder-Mead method.<br>Note that the default algorithm is</p><pre><code>method  =  &quot;REML&quot;,  method.optim  =  &quot;AI&quot;</code></pre><p>A maximum likelihood version of Average Information algorithm is not available in<br>glmmkin.</p><h4 id="7-2Changing-model-fitting-parameters"><a href="#7-2Changing-model-fitting-parameters" class="headerlink" title="7.2Changing model fitting parameters"></a>7.2Changing model fitting parameters</h4><p>By default we set the maximum number of iteration to 500 and tolerance to declare convergence to 1e-5:</p><pre><code>maxiter  =  500,  tol  =  1e-5</code></pre><p>These parameters can be changed. When using the Brent method for maximizing the likelihood (or restricted likelihood), we specify the search range of the ratio of the variance component parameter τ1 over the dispersion parameter  φ  to  be  between  1e-5  and  1e5, and we divide the search region evenly into 10 regions on the log scale:</p><pre><code>taumin  =  1e-5,  taumax  =  1e5,  tauregion  =  10</code></pre><p>These parameters can also be changed, but they are only effective when using the Brent method.</p><h4 id="7-3Missing-genotypes"><a href="#7-3Missing-genotypes" class="headerlink" title="7.3Missing genotypes"></a>7.3Missing genotypes</h4><p>It is recommended to perform genotype quality control prior to analysis to impute missing genotypes or filter out SNPs with high missing rates. However, GMMAT does allow miss- ing genotypes, and imputes to the mean value by default. Alternatively, in glmm.score and glmm.wald, missing genotypes can be omitted from the analysis using</p><pre><code>missing.method  =  &quot;omit&quot;</code></pre><p>In variant set tests using SMMAT, instead of imputing missing genotypes to the mean value, you can impute missing genotypes to 0 (homozygous reference allele) using</p><pre><code>missing.method  =  &quot;impute2zero&quot;</code></pre><p>If using a plain text (or compressed .gz and .bz2) genotype file, missing genotypes should be coded as ”NA”. If you have missing genotypes coded in a different way, you can specify this in the argument ”infile.na”.</p><h4 id="7-4Reordered-genotypes"><a href="#7-4Reordered-genotypes" class="headerlink" title="7.4Reordered genotypes"></a>7.4Reordered genotypes</h4><p>The genotype file (either a plain text file, a PLINK binary PED file, or a GDS file) can include more individuals than in the phenotype and covariates data frame, and they can be in different orders. GMMAT handles this issue using an argument ”select” in both glmm.score and glmm.wald. For example, if the order of individuals in your genotype file is A, B, C, D, but you only have 3 unique individuals (with order C, A, B) in the fitted ”obj” (for glmm.score) or in the data frame ”data” (for glmm.wald), then you can specify</p><pre><code>select = c(2, 3, 1, 0)</code></pre><p>to reflect the order of individuals. Note that since individual D is not included, its order is assigned to 0. The length of the vector must match the number of individuals in your genotype file. Also note that if there are observations with missing phenotype&#x2F;covariates in ”data”, ”select” for glmm.wald should match to ”data” before removing any missing values, while ”select” for glmm.score should match to ”obj” (in which missing values have been excluded).</p><p>In variant set tests, SMMAT will extract ID from ”null.obj” using ”id include” re- turned in the glmmkin fitted null model object. The ID will be matched to ”sample.id” in the GDS genotype file.</p><h4 id="7-5Parallel-computing"><a href="#7-5Parallel-computing" class="headerlink" title="7.5Parallel computing"></a>7.5Parallel computing</h4><p>Parallel computing can be enabled in glmm.score and SMMAT using the argument ”ncores” to specify how many cores you would like to use on a computing node. By default ”ncores” is 1, meaning that these functions will run in a single thread. Currently parallel computing is only implemented for GDS format genotype files.</p><p>If you  enable parallel computing and save  intermediate files,  you  will get multi-   ple sets of intermediate files. For example, if your ”ncores” is 12 and you specified ”meta.file.prefix” to ”study1”, then you will get 12 sets of (totaling 24) intermediate files ”study1.score.1”, ”study1.var.1”, ”study1.score.2”, ”study1.var.2”, …, ”study1.score.12”, ”study1.var.12”. Later in the meta-analysis to combine with 2 sets of intermediate files ”study2.score.1”, ”study2.var.1”, ”study2.score.2”, ”study2.var.2”, you will need to use</p><pre><code>meta.files.prefix  =  c(&quot;study1&quot;,  &quot;study2&quot;),  n.files  =  c(12,  2)</code></pre><p>If your R is configured with Intel MKL and you would like to enable parallel comput- ing, it is recommended that you set the environmental variable ”MKL NUM THREADS” to 1 before running R to avoid hanging. Alternatively,  you  can do this at the beginning  of your R script by using</p><pre><code>Sys.setenv(MKL_NUM_THREADS  =  1)</code></pre><h4 id="7-6Variant-filters"><a href="#7-6Variant-filters" class="headerlink" title="7.6Variant filters"></a>7.6Variant filters</h4><p>Variants can be filtered in glmm.score and SMMAT based on minor allele frequency (MAF) and missing rate filters. The argument ”MAF.range” specifies the minimum and maximum MAFs for a variant to be included in the analysis. By default the minimum MAF is 1 10−7 and the maximum MAF is 0.5, meaning that only monomorphic markers in the sample will be excluded (if your sample size is no more than 5 million). The argument ”miss.cutoff” specifies the maximum missing rate for a variant to be included  in the analysis.  By default it is set to 1, meaning that no variants  will be removed due to high genotype missing rates.</p><h4 id="7-7Internal-minor-allele-frequency-weights"><a href="#7-7Internal-minor-allele-frequency-weights" class="headerlink" title="7.7Internal minor allele frequency weights"></a>7.7Internal minor allele frequency weights</h4><p>Internal weights are calculated based on the minor allele frequency (NOT the effect allele frequency, therefore, variants with effect allele frequencies 0.01 and 0.99 have the same weights) as a beta probability density function. Internal weights are multiplied by the external weights given in the last column of the group definition file. To turn off internal weights, use</p><pre><code>MAF.weights.beta  =  c(1,  1)</code></pre><p>to assign flat weights, as a beta distribution with parameters 1 and 1 is a uniform distri- bution on the interval between 0 and 1.</p><h4 id="7-8Allele-flipping"><a href="#7-8Allele-flipping" class="headerlink" title="7.8Allele flipping"></a>7.8Allele flipping</h4><p>In variant set tests SMMAT, by default the alt allele is used as the coding allele and variants in each variant set are matched strictly on chromosome, position, reference and alternate alleles.</p><p>The argument ”auto.flip” allows automatic allele flipping if a specified variant is not found in the genotype file, but a variant at the same chromosome and position with reference allele matching the alternate allele in the group definition file ”group.file”, and alternate allele matching the reference allele in the group definition file ”group.file”, to  be included in the analysis. Please use with caution for whole genome sequence data, as both ref&#x2F;alt and alt&#x2F;ref variants at the same position are not uncommon, and they are  likely two different variants, rather than allele flipping.</p><p>The argument ”use.minor.allele” allows using the minor allele instead of the alt allele as the coding allele in variant set tests. Note that this choice does not change ”S” for SKAT results, but ”B” for the burden test, ”O” for SKAT-O and ”E” for efficient hybrid test of the burden test and SKAT results will be affected. Generally the alt allele can either be the minor or the major allele. If in a variant set, different variants with alt allele</p><p>frequencies 0.001 and 0.998 are combined together in a burden test, the results would be difficult to interpret. We generally recommend turning on the ”use.minor.allele” option, unless you know the ancestry alleles explicitly and the specific scientific hypothesis clearly that you would like to test. Along with the MAF filter, this option is useful for combining rare mutations, assuming rare allele effects are in the same direction.</p><h4 id="7-9P-values-of-weighted-sum-of-chi-squares"><a href="#7-9P-values-of-weighted-sum-of-chi-squares" class="headerlink" title="7.9P values of weighted sum of chi-squares"></a>7.9P values of weighted sum of chi-squares</h4><p>In variant set tests SMMAT, you can use 3 methods in the ”method” argument to compute P values of weighted sum of chi-square distributions: ”davies”,17 ”kuonen”18 and ”liu”.19  By default ”davies” is used, if it returns an error message in the calculation, or a  P value greater than 1, or less than 1 10−5, ”kuonen” method will be used. If ”kuonen” method fails to compute the P value, ”liu” method will be used.</p><h4 id="7-10Heterogeneous-genetic-effects-in-variant-set-meta-analysis"><a href="#7-10Heterogeneous-genetic-effects-in-variant-set-meta-analysis" class="headerlink" title="7.10Heterogeneous genetic effects in variant set meta-analysis"></a>7.10Heterogeneous genetic effects in variant set meta-analysis</h4><p>Heterogeneous genetic effects20 are allowed in variant set tests meta-analysis function SMMAT.meta, by specifying groups using the ”cohort.group.idx” argument. By default all studies are assumed to share the same genetic effects in the meta-analysis, and this can be changed by assigning different group indices to studies. For example,</p><pre><code>cohort.group.idx = c(&quot;a&quot;,&quot;b&quot;,&quot;a&quot;,&quot;a&quot;,&quot;b&quot;)</code></pre><p>means cohorts 1, 3, 4 are assumed to have homogeneous genetic effects, and cohorts 2, 5 are in another group with homogeneous genetic effects (but possibly heterogeneous with group ”a”).</p><h4 id="7-11Other-options"><a href="#7-11Other-options" class="headerlink" title="7.11Other options"></a>7.11Other options</h4><p>By default, genotypes are centered to the mean before the analysis in single variant tests.<br>You can turn this feature off by specifying</p><pre><code>center = FALSE</code></pre><p>in both glmm.score and glmm.wald functions to use raw genotypes.</p><p>If your genotype file is a plain text (or a compressed .gz and .bz2 file), and you want to read in fewer lines than all lines included in the file, you can use the ”infile.nrow” argument to specify how many lines (including lines to be skipped using ”infile.nrow.skip”) you want to read in. By default the delimiter is assumed to be a tab, but you can change it using the ”infile.sep” argument. These options are implemented in glmm.score and glmm.wald. In the score test function glmm.score, by default 100 SNPs are tested in a batch. You can change it using the ”nperbatch” argument, but the computational time can increase substantially if it is either too small or too large, depending on the performance of your<br>computing system.</p><p>If you perform Wald tests glmm.wald and use a plain text (or a compressed .gz  and .bz2) file, and your SNPs are not in your first column, you can change ”snp.col” in glmm.wald to indicate which column is your SNP name.</p><p>In the variant set tests SMMAT, by default the group definition file ”group.file” should be tab delimited, but you can change it using the ”group.file.sep” argument. Also there is a ”Garbage.Collection” argument (default FALSE), if turned on, SMMAT will call the function gc for each variant set tested. It helps save memory footprint, but the computation speed might be slower.</p>]]></content>
      
      
      <categories>
          
          <category> GWAS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GWAS </tag>
            
            <tag> GMMAT </tag>
            
            <tag> SMMAT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>miRNA数据库|miRNA靶基因预测</title>
      <link href="/2020-06-12-mirna-shu-ju-ku-mirna-ba-ji-yin-yu-ce/"/>
      <url>/2020-06-12-mirna-shu-ju-ku-mirna-ba-ji-yin-yu-ce/</url>
      
        <content type="html"><![CDATA[<font face="times new roman" size=4><span id="more"></span><p>miRNA数据库|miRNA靶基因预测</p><!-- toc --><hr><h1 id="常见的miRNA靶基因预测数据库"><a href="#常见的miRNA靶基因预测数据库" class="headerlink" title="常见的miRNA靶基因预测数据库"></a>常见的miRNA靶基因预测数据库</h1>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>GWAS|SAIGE-GENE安装及使用指南</title>
      <link href="/2020-06-11-gwas-saige-gene-an-zhuang-ji-shi-yong-jiao-cheng/"/>
      <url>/2020-06-11-gwas-saige-gene-an-zhuang-ji-shi-yong-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<font face="times new roman" size=4><span id="more"></span><p>GWAS|SAIGE-GENE安装及使用指南</p><!-- toc --><hr><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1.Overview"></a>1.Overview</h1><p>The most current version of SAIGE is version 0.38</p><p>This tutorial will walk you through</p><p>1.Installing SAIGE</p><p>2.Running SAIGE for：</p><ul><li>Single-variant association tests</li><li>Gene-based tests</li><li>Conditional analysis</li></ul><h1 id="2-Installing-SAIGE"><a href="#2-Installing-SAIGE" class="headerlink" title="2.Installing SAIGE"></a>2.Installing SAIGE</h1><h2 id="2-1-Install-SAIGE-using-the-conda-environment"><a href="#2-1-Install-SAIGE-using-the-conda-environment" class="headerlink" title="2.1 Install SAIGE using the conda environment"></a>2.1 Install SAIGE using the conda environment</h2><h3 id="2-1-1-Create-a-conda-environment-using-conda-environment-file-Here-is-a-link-to-download-the-conda-environment-file-environment-RSAIGE-yml"><a href="#2-1-1-Create-a-conda-environment-using-conda-environment-file-Here-is-a-link-to-download-the-conda-environment-file-environment-RSAIGE-yml" class="headerlink" title="2.1.1 Create a conda environment using (conda environment file) Here is a link to download the conda environment file-environment-RSAIGE.yml"></a>2.1.1 Create a conda environment using (conda environment file) Here is a link to download the conda environment file-<strong><a href="https://raw.githubusercontent.com/weizhouUMICH/SAIGE/master/conda_env/environment-RSAIGE.yml">environment-RSAIGE.yml</a></strong></h3><p>After downloading <code>environment-RSAIGE.yml</code>, run following command</p><pre><code>conda env create -f environment-RSAIGE.yml</code></pre><h3 id="2-1-2-Activate-the-conda-environment-RSAIGE"><a href="#2-1-2-Activate-the-conda-environment-RSAIGE" class="headerlink" title="2.1.2 Activate the conda environment RSAIGE"></a>2.1.2 Activate the conda environment RSAIGE</h3><pre><code>conda activate RSAIGEFLAGPATH=`which python | sed &#39;s|/bin/python$||&#39;`export LDFLAGS=&quot;-L$&#123;FLAGPATH&#125;/lib&quot;export CPPFLAGS=&quot;-I$&#123;FLAGPATH&#125;/include&quot;</code></pre><p>Please make sure to set up the <code>LDFLAGS</code> and <code>CPPFLAGS</code> using export (the last two command lines), so libraries can be linked correctly when the SAIGE source code is compiled. Note: <strong>Here are the steps to <a href="https://github.com/weizhouUMICH/SAIGE/blob/master/conda_env/createCondaEnvSAIGE_steps.txt">create the conda environment file</a></strong></p><h3 id="2-1-3-Open-R-run-following-script-to-install-the-MetaSKAT-R-library"><a href="#2-1-3-Open-R-run-following-script-to-install-the-MetaSKAT-R-library" class="headerlink" title="2.1.3 Open R, run following script to install the MetaSKAT R library."></a>2.1.3 Open <strong>R</strong>, run following script to install the <strong>MetaSKAT</strong> R library.</h3><pre><code>install.packages(&#39;MetaSKAT&#39;)</code></pre><h3 id="2-1-4-Install-SAIGE-from-the-source-code"><a href="#2-1-4-Install-SAIGE-from-the-source-code" class="headerlink" title="2.1.4 Install SAIGE from the source code."></a>2.1.4 Install SAIGE from the source code.</h3><h4 id="Method-1"><a href="#Method-1" class="headerlink" title="Method 1:"></a>Method 1:</h4><pre><code>src_branch=masterrepo_src_url=https://github.com/weizhouUMICH/SAIGEgit clone --depth 1 -b $src_branch $repo_src_urlR CMD INSTALL --library=path_to_final_SAIGE_library SAIGE</code></pre><p>When call SAIGE in R, set lib.loc&#x3D;path_to_final_SAIGE_library</p><p>  library(SAIGE, lib.loc&#x3D;path_to_final_SAIGE_library)</p><h4 id="Method-2"><a href="#Method-2" class="headerlink" title="Method 2:"></a>Method 2:</h4><p>Open R. Run</p><pre><code>devtools::install_github(&quot;weizhouUMICH/SAIGE&quot;)</code></pre><h2 id="2-2-Run-SAIGE-using-a-docker-image"><a href="#2-2-Run-SAIGE-using-a-docker-image" class="headerlink" title="2.2 Run SAIGE using a docker image"></a>2.2 Run SAIGE using a docker image</h2><p>The docker image can be pulled</p><pre><code>docker pull wzhou88/saige:0.38</code></pre><p><a href="https://github.com/weizhouUMICH/Docker/tree/master/SAIGE">Dockerfile for creating your own docker image for SAIGE</a></p><p>Functions can be called</p><pre><code>step1_fitNULLGLMM.R --helpstep2_SPAtests.R --helpcreateSparseGRM.R --help</code></pre><p>Previous versions of SAIGE installation files are here: <a href="https://www.dropbox.com/sh/zmlu1llpxd66pjl/AADFqdssvOBjbWZch6Q9zYNaa?dl=0">https://www.dropbox.com/sh/zmlu1llpxd66pjl/AADFqdssvOBjbWZch6Q9zYNaa?dl=0</a></p><h1 id="3-Flowchart"><a href="#3-Flowchart" class="headerlink" title="3 Flowchart"></a>3 Flowchart</h1><p>SAIGE and SAIGE-GENE can work for both binary and quantitative traits.</p><h2 id="3-1-SAIGE-Flowchart"><a href="#3-1-SAIGE-Flowchart" class="headerlink" title="3.1 SAIGE Flowchart"></a>3.1 SAIGE Flowchart</h2><p><img src="/GWAS-SAIGE-GENE%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/SAIGE2step.png" alt="SAIGE Flowchart"></p><h2 id="3-2-SAIGE-GENE-Flowchart"><a href="#3-2-SAIGE-GENE-Flowchart" class="headerlink" title="3.2 SAIGE-GENE Flowchart"></a>3.2 SAIGE-GENE Flowchart</h2><p><img src="/GWAS-SAIGE-GENE%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/saigegene2steps.png" alt="SAIGE-GENE Flowchart"></p><h1 id="4-Running-SAIGE-and-SAIGE-GENE"><a href="#4-Running-SAIGE-and-SAIGE-GENE" class="headerlink" title="4 Running SAIGE and SAIGE-GENE"></a>4 Running SAIGE and SAIGE-GENE</h1><p>Scripts are in the folder extdata&#x2F; and command lines are in the file cmd.sh</p><pre><code>cd /extdata/less -S cmd.sh</code></pre><p>Input files are in the folder <strong>extdata&#x2F;input</strong></p><p>Output files are in the folder <strong>extdata&#x2F;output</strong> </p><p>To obtain help information of the scripts that call functions in the SAIGE library</p><pre><code>Rscript createSparseGRM.R --helpRscript step1_fitNULLGLMM.R --helpRscript step2_SPAtests.R --help</code></pre><p>To obtain help information of functions in the SAIGE library</p><pre><code>#open RRlibrary(SAIGE)?createSparseGRM?fitNULLGLMM?SPAGMMATtest</code></pre><h2 id="4-1-Single-variant-association-tests"><a href="#4-1-Single-variant-association-tests" class="headerlink" title="4.1 Single variant association tests"></a>4.1 Single variant association tests</h2><p>For single-variant association tests, sparse GRM and categorical variance ratios are <strong>NOT</strong> needed. </p><p>Randomly selected markers with <strong>MAC &gt;&#x3D; 20</strong> are used to estimate the variance ratio </p><h3 id="Step-1-fitting-the-null-logistic-x2F-linear-mixed-model"><a href="#Step-1-fitting-the-null-logistic-x2F-linear-mixed-model" class="headerlink" title="Step 1: fitting the null logistic&#x2F;linear mixed model"></a>Step 1: fitting the null logistic&#x2F;linear mixed model</h3><ul><li>For <strong>binary traits</strong>, a null logistic mixed model will be fitted (<em><strong>–traitType&#x3D;binary</strong></em>). </li><li>For <strong>quantitative traits</strong>, a null linear mixed model will be fitted (<em><strong>–traitType&#x3D;quantitative</strong></em>) and needs to be inverse normalized (<em><strong>–invNormalize&#x3D;TRUE</strong></em>)</li></ul><pre><code>#check the help info for step 1Rscript step1_fitNULLGLMM.R --help</code></pre><pre><code>#For Binary traits:Rscript step1_fitNULLGLMM.R     \        --plinkFile=./input/nfam_100_nindep_0_step1_includeMoreRareVariants_poly \        --phenoFile=./input/pheno_1000samples.txt_withdosages_withBothTraitTypes.txt \        --phenoCol=y_binary \        --covarColList=x1,x2 \        --sampleIDColinphenoFile=IID \        --traitType=binary        \        --outputPrefix=./output/example_binary \        --nThreads=4 \        --LOCO=FALSE \        --IsOverwriteVarianceRatioFile ## v0.38. Whether to overwrite the variance ratio file if the file already exists#For Quantitative traits, if not normally distributed, inverse normalization needs to be specified to be TRUE --invNormalize=TRUERscript step1_fitNULLGLMM.R     \        --plinkFile=./input/nfam_100_nindep_0_step1_includeMoreRareVariants_poly \        --phenoFile=./input/pheno_1000samples.txt_withdosages_withBothTraitTypes.txt \        --phenoCol=y_quantitative \        --covarColList=x1,x2 \        --sampleIDColinphenoFile=IID \        --traitType=quantitative       \    --invNormalize=TRUE\        --outputPrefix=./output/example_quantitative \        --nThreads=4 \        --LOCO=FALSE\    --tauInit=1,0</code></pre><h4 id="Input-files"><a href="#Input-files" class="headerlink" title="Input files"></a>Input files</h4><p><strong>1. Genotype file for constructing the <code>genetic relationship matrix (GRM)</code></strong></p><p>SAIGE takes the PLINK binary file for the genotypes and assumes the file prefix is the same one for <strong>.bed, .bim. and .fam</strong></p><pre><code>./input/nfam_100_nindep_0_step1_includeMoreRareVariants_poly.bed./input/nfam_100_nindep_0_step1_includeMoreRareVariants_poly.bim./input/nfam_100_nindep_0_step1_includeMoreRareVariants_poly.fam</code></pre><p><strong>2.Phenotype file (contains non-genetic covariates if any, such as gender and age)</strong></p><p>The file can be either space or tab-delimited with a header. It is required that the file contains one column for sample IDs and one column for the phenotype. It may contain columns for non-genetic covariates.</p><p><strong>Note:</strong> Current version of SAIGE does not support categorical covariates that have more than two categories</p><pre><code>less -S ./input/pheno_1000samples.txt_withdosages_withBothTraitTypes.txt</code></pre><h4 id="Output-files"><a href="#Output-files" class="headerlink" title="Output files"></a>Output files</h4><p><strong>1. model file</strong></p><pre><code>./output/example_quantitative.rda</code></pre><pre><code>#open RR#load the model file in Rload(&quot;./output/example_quantitative.rda&quot;)names(modglmm)modglmm$theta#theta: a vector of length 2. The first element is the dispersion parameter estimate and the second one is the variance component parameter estimate#coefficients: fixed effect parameter estimates#linear.predictors: a vector of length N (N is the sample size) containing linear predictors#fitted.values: a vector of length N (N is the sample size) containing fitted mean values on the original scale#Y: a vector of length N (N is the sample size) containing final working vector#residuals: a vector of length N (N is the sample size) containing residuals on the original scale#sampleID: a vector of length N (N is the sample size) containing sample IDs used to fit the null model</code></pre><p><strong>2. association result file for the subset of randomly selected markers</strong></p><pre><code>less -S ./output/example_quantitative_30markers.SAIGE.results.txt</code></pre><p><strong>3. variance ratio file</strong></p><pre><code>less -S ./output/example_quantitative.varianceRatio.txt</code></pre><h3 id="Step-2-performing-single-variant-association-tests"><a href="#Step-2-performing-single-variant-association-tests" class="headerlink" title="Step 2: performing single-variant association tests"></a>Step 2: performing single-variant association tests</h3><ul><li>For <strong>binary traits</strong>, saddle point approximation is used to account for case-control imbalance.</li><li>File formats for dosages&#x2F;genotypes of genetic variants to be tested can be used: VCF, BGEN, SAV</li><li>Conditional analysis based summary stats can be performed (<em><strong>–condition</strong></em>) can be performed in Step 2 with dosage&#x2F;genotype input file formats <strong>VCF, BGEN and SAV</strong>.</li><li>To query and test a subset of markers</li><li><ul><li>both variant IDs and range of chromosome positions can be specified for BGEN input (<em>–idstoExcludeFile, –idstoIncludeFile, –rangestoExcludeFile, –rangestoIncludeFile</em>)</li></ul></li><li><ul><li>range chromosome positions can be specified for VCF&#x2F;SAV input (<em>–chrom, –start, –end</em>).</li></ul></li><li>For VCF&#x2F;SAV input, <em>–chrom</em> MUST be specified and the string needs to be exactly the same as in the VCF&#x2F;SAV, such as <strong>“01” or “chr1”</strong>.</li><li>For VCF&#x2F;SAV input, <em>–vcfField&#x3D;DS</em> to test dosages and <em>–vcfField&#x3D;GT</em> to test genotypes</li><li>To drop samples with <strong>missing genotypes&#x2F;dosages</strong>,<em>–IsDropMissingDosages&#x3D;TRUE</em>, if FALSE, missing genotypes&#x2F;dosages will be mean imputed.</li></ul><p><strong>NOTE</strong>: this option has not been extensively tested yet. **</p><ul><li>sampleFile is used specify a file with sample IDs for bgen file. Please DO NOT include a header in the file. SAIGE versions &gt;&#x3D; 0.38 do not need sampleFile if VCF files are used</li></ul><pre><code>#check the help info for step 2Rscript step2_SPAtests.R --help</code></pre><pre><code>#Perform single-variant association tests#for binary traits, * --IsOutputAFinCaseCtrl=TRUE can be specified to output allele frequencies in cases and controls* --IsOutputNinCaseCtrl=TRUE can be specified to output sample sizes of cases and controls for each marker* --IsOutputHetHomCountsinCaseCtrl can be specified to output heterozygous and homozygous counts in cases and controlsRscript step2_SPAtests.R\        --vcfFile=./input/genotype_10markers.missingness.vcf.gz \        --vcfFileIndex=./input/genotype_10markers.missingness.vcf.gz.tbi \        --vcfField=GT \        --chrom=1 \        --minMAF=0.0001 \        --minMAC=1 \        --sampleFile=./input/sampleIDindosage.txt \        --GMMATmodelFile=./output/example_binary.rda \        --varianceRatioFile=./output/example_binary.varianceRatio.txt \        --SAIGEOutputFile=./output/example_binary.SAIGE.vcf.genotype.txt \        --numLinesOutput=2 \        --IsOutputAFinCaseCtrl=TRUE##drop samples with missing genotypes/dosages##--IsDropMissingDosages=TRUERscript step2_SPAtests.R        \        --vcfFile=./input/genotype_10markers.missingness.vcf.gz \        --vcfFileIndex=./input/genotype_10markers.missingness.vcf.gz.tbi \        --vcfField=GT \        --chrom=1 \        --minMAF=0.0001 \        --minMAC=1 \        --sampleFile=./input/sampleIDindosage.txt \        --GMMATmodelFile=./output/example_binary.rda \        --varianceRatioFile=./output/example_binary.varianceRatio.txt \        --SAIGEOutputFile=./output/example_binary.SAIGE.vcf.genotype.dropmissing.txt \        --numLinesOutput=2 \        --IsOutputAFinCaseCtrl=TRUE\    --IsDropMissingDosages=TRUE    #conditional analysis## --condition = Genetic marker ids (**chr:pos_ref/alt for vcf/sav or marker id for bgen**) separated by comma. e.g.chr3:101651171_C/T,chr3:101651186_G/ARscript step2_SPAtests.R        \        --vcfFile=./input/genotype_10markers.missingness.vcf.gz \        --vcfFileIndex=./input/genotype_10markers.missingness.vcf.gz.tbi \        --vcfField=GT \        --chrom=1 \        --minMAF=0.0001 \        --minMAC=1 \        --sampleFile=./input/sampleIDindosage.txt \        --GMMATmodelFile=./output/example_binary.rda \        --varianceRatioFile=./output/example_binary.varianceRatio.txt \        --SAIGEOutputFile=./output/example_binary.SAIGE.vcf.genotype.dropmissing.txt \        --numLinesOutput=2 \        --IsOutputAFinCaseCtrl=TRUE     \    --IsDropMissingDosages=TRUE\    --condition=1:4_A/C#plain text input for dosages (plain text input for dosages is not inputed since 0.36.1)Rscript step2_SPAtests.R \        --dosageFile=./input/dosage_10markers.txt \        --dosageFileNrowSkip=1 \        --dosageFileNcolSkip=6 \        --dosageFilecolnamesSkip=CHR,SNP,CM,POS,EFFECT_ALLELE,ALT_ALLELE \        --minMAF=0.0001 \        --sampleFile=./input/sampleIDindosage.txt \        --GMMATmodelFile=./output/example.rda \        --varianceRatioFile=./output/example.varianceRatio.txt \        --SAIGEOutputFile=./output/example.plainDosage.SAIGE.txt \        --numLinesOutput=2 \        --IsOutputAFinCaseCtrl=TRUE#bgen for dosagesRscript step2_SPAtests.R \        --bgenFile=./input/genotype_100markers.bgen \        --bgenFileIndex=./input/genotype_100markers.bgen.bgi \        --minMAF=0.0001 \        --minMAC=1 \        --sampleFile=./input/samplefileforbgen_10000samples.txt \        --GMMATmodelFile=./output/example.rda \        --varianceRatioFile=./output/example.varianceRatio.txt \        --SAIGEOutputFile=./output/example.SAIGE.bgen.txt \        --numLinesOutput=2 \        --IsOutputAFinCaseCtrl=TRUE#VCF containing genotypes (--vcfField=GT)Rscript step2_SPAtests.R \        --vcfFile=./input/genotype_10markers.vcf.gz \        --vcfFileIndex=./input/genotype_10markers.vcf.gz.tbi \        --vcfField=GT \        --chrom=1 \        --minMAF=0.0001 \        --minMAC=1 \        --sampleFile=./input/sampleIDindosage.txt \        --GMMATmodelFile=./output/example.rda \        --varianceRatioFile=./output/example.varianceRatio.txt \        --SAIGEOutputFile=./output/example.SAIGE.vcf.genotype.txt \        --numLinesOutput=2 \        --IsOutputAFinCaseCtrl=TRUE#VCF containing dosages (--vcfField=DS)Rscript step2_SPAtests.R \        --vcfFile=./input/dosage_10markers.vcf.gz \        --vcfFileIndex=./input/dosage_10markers.vcf.gz.tbi \        --vcfField=DS \        --chrom=1 \        --minMAF=0.0001 \        --minMAC=1 \        --sampleFile=./input/sampleIDindosage.txt \        --GMMATmodelFile=./output/example.rda \        --varianceRatioFile=./output/example.varianceRatio.txt \        --SAIGEOutputFile=./output/example.SAIGE.vcf.dosage.txt \        --numLinesOutput=2 \        --IsOutputAFinCaseCtrl=TRUE# SAV for dosagesRscript step2_SPAtests.R        \        --savFile=./input/dosage_10markers.sav  \        --savFileIndex=./input/dosage_10markers.sav.s1r \        --vcfField=DS \        --minMAF=0.0001 \        --minMAC=1 \        --chrom=1 \        --sampleFile=./input/samplefileforbgen_10000samples.txt \        --GMMATmodelFile=./output/example.rda \        --varianceRatioFile=./output/example.varianceRatio.txt \        --SAIGEOutputFile=./output/example.SAIGE.sav.txt \        --numLinesOutput=2 \        --IsOutputAFinCaseCtrl=TRUE</code></pre><h4 id="Input-files-1"><a href="#Input-files-1" class="headerlink" title="Input files"></a>Input files</h4><p>1.Dosage file SAIGE supports different formats for dosages: <strong>VCF, BCF, BGEN and SAV</strong>.</p><ul><li>BGEN</li></ul><pre><code>genotype_100markers.bgengenotype_100markers.bgen.bgi</code></pre><ul><li>VCF containing genotypes</li></ul><pre><code>zcat genotype_10markers.vcf.gz | less -Sgenotype_10markers.vcf.gz.tbi</code></pre><ul><li>VCF containing dosages</li></ul><pre><code>zcat dosage_10markers.vcf.gz | less -Sdosage_10markers.vcf.gz.tbi</code></pre><p>-SAV</p><pre><code>dosage_10markers.savdosage_10markers.sav.s1r</code></pre><p>2.Sample file</p><p>This file contains one column for sample IDs corresponding to the sample order in the dosage file. <strong>No header is included</strong>. The option was originally for BGEN file that does not contain sample information.</p><pre><code>less -S sampleIDindosage.txt</code></pre><p>3.Model file from step 1</p><pre><code>./output/example.rda</code></pre><p>4.Variance ratio file from step 1</p><pre><code>./output/example.varianceRatio.txt</code></pre><h4 id="Output-file"><a href="#Output-file" class="headerlink" title="Output file"></a>Output file</h4><p>A file with association test results</p><pre><code>less -S ./output/example.SAIGE.vcf.dosage.txt</code></pre><p><strong>NOTE:</strong></p><ul><li>Association results are with regard to Allele2.</li><li>For binary traits, the header of the output file: <code>CHR POS SNPID Allele1 Allele2 AC_Allele2 AF_Allele2 imputationInfo N BETA SE Tstat p.value p.value.NA Is.SPA.converge varT varTstar AF.Cases AF.Controls</code></li><li>For quantitative traits, the header of the output file: <code>CHR POS SNPID Allele1 Allele2 AC_Allele2 AF_Allele2 imputationInfo N BETA SE Tstat p.value varT varTstar</code></li></ul><pre><code>CHR: chromosomePOS: genome position SNPID: variant IDAllele1: allele 1Allele2: allele 2AC_Allele2: allele count of allele 2AF_Allele2: allele frequency of allele 2imputationInfo: imputation info. If not in dosage/genotype input file, will output 1N: sample sizeBETA: effect size of allele 2SE: standard error of BETATstat: score statistic of allele 2p.value: p value (with SPA applied for binary traits)p.value.NA: p value when SPA is not applied (only for binary traits)Is.SPA.converge: whether SPA is converged or not (only for binary traits)varT: estimated variance of score statistic with sample relatedness incorporatedvarTstar: variance of score statistic without sample relatedness incorporatedAF.Cases: allele frequency of allele 2 in cases (only for binary traits and if --IsOutputAFinCaseCtrl=TRUE)AF.Controls: allele frequency of allele 2 in controls (only for binary traits and if --IsOutputAFinCaseCtrl=TRUE)Tstat_cond, p.value_cond, varT_cond, BETA_cond, SE_cond: summary stats for conditional analysis</code></pre><h4 id="An-example-with-a-signal"><a href="#An-example-with-a-signal" class="headerlink" title="An example with a signal"></a>An example with a signal</h4><ul><li>p.value in Step 2 for the marker is ~4.16 x 10^-7</li></ul><pre><code>Rscript step1_fitNULLGLMM.R     \        --plinkFile=./input/nfam_100_nindep_0_step1_includeMoreRareVariants_poly \        --phenoFile=./input/Prev_0.1_nfam_1000.pheno_positive_pheno.txt \        --phenoCol=y \        --covarColList=x1,x2 \        --sampleIDColinphenoFile=IID \        --traitType=binary        \        --outputPrefix=./output/example_binary_positive_signal \        --nThreads=4    \        --LOCO=FALSE    \        --minMAFforGRM=0.01Rscript step2_SPAtests.R        \        --vcfFile=./input/nfam_1000_MAF0.2_nMarker1_nseed200.vcf.gz \        --vcfFileIndex=./input/nfam_1000_MAF0.2_nMarker1_nseed200.vcf.gz.tbi \        --vcfField=GT \        --chrom=1 \        --minMAF=0.0001 \        --minMAC=1 \        --GMMATmodelFile=./output/example_binary_positive_signal.rda \        --varianceRatioFile=./output/example_binary_positive_signal.varianceRatio.txt \        --SAIGEOutputFile=./output/example_binary_positive_signal.assoc.step2.txt \        --numLinesOutput=2 \        --IsOutputAFinCaseCtrl=TRUE</code></pre><h2 id="4-2-Region-or-gene-based-association-tests-SAIGE-GENE"><a href="#4-2-Region-or-gene-based-association-tests-SAIGE-GENE" class="headerlink" title="4.2 Region- or gene-based association tests (SAIGE-GENE)"></a>4.2 Region- or gene-based association tests (SAIGE-GENE)</h2><h3 id="Step-0-creating-a-sparse-GRM"><a href="#Step-0-creating-a-sparse-GRM" class="headerlink" title="Step 0: creating a sparse GRM"></a>Step 0: creating a sparse GRM</h3><p><strong>Note</strong>: This step is only needed for region- and gene-based tests (SAIGE-GENE)</p><p>The sparse GRM only needs to be created once for each data set, e.g. a biobank, and can be used for all different phenotypes as long as all tested samples are included in it.</p><pre><code>Rscript createSparseGRM.R\    --plinkFile=./input/nfam_100_nindep_0_step1_includeMoreRareVariants_poly \    --nThreads=4  \    --outputPrefix=./output/sparseGRM\    --numRandomMarkerforSparseKin=2000\    --relatednessCutoff=0.125</code></pre><h4 id="Input-file"><a href="#Input-file" class="headerlink" title="Input file"></a>Input file</h4><p><strong>Genotype file</strong> for constructing the genetic relationship matrix </p><p>SAIGE takes the PLINK binary file for the genotypes and assumes the file prefix is the same one for <strong>.bed, .bim. and .fam</strong></p><pre><code>nfam_100_nindep_0_step1_includeMoreRareVariants_poly.bednfam_100_nindep_0_step1_includeMoreRareVariants_poly.bimnfam_100_nindep_0_step1_includeMoreRareVariants_poly.fam</code></pre><h4 id="Output-files-1"><a href="#Output-files-1" class="headerlink" title="Output files"></a>Output files</h4><p>1.a file storing the sparse GRM</p><pre><code>sparseGRM_relatednessCutoff_0.125_1000_randomMarkersUsed.sparseGRM.mtx</code></pre><p>The sparse GRM file can be opened using the readMM function in the R library Matrix</p><p>2.a file storing IDs of the samples in the sparse GRM</p><pre><code>sparseGRM_relatednessCutoff_0.125_1000_randomMarkersUsed.sparseGRM.mtx.sampleIDs.txt</code></pre><h3 id="Step-1-fitting-the-null-logistic-x2F-linear-mixed-model-1"><a href="#Step-1-fitting-the-null-logistic-x2F-linear-mixed-model-1" class="headerlink" title="Step 1: fitting the null logistic&#x2F;linear mixed model"></a>Step 1: fitting the null logistic&#x2F;linear mixed model</h3><ul><li><em><strong>IsSparseKin&#x3D;TRUE</strong></em> must be specified for SAIGE-GENE</li><li>step 1 model result from the single-variant assoc test can be re-used, except that for gene-based tests, variance ratios for multiple MAC categories and a sparse GRM need to be used (<em>IsSparseKin&#x3D;TRUE</em>).</li><li>with <em><strong>IsSparseKin&#x3D;TRUE</strong></em>, no sparseGRMFile and sparseGRMSampleIDFile are specified (step 0 has not been done beforehand), a sparse GRM will be created based on the relatednessCutoff in this step.</li><li>with <em><strong>IsSparseKin&#x3D;TRUE</strong></em>, sparseGRMFile and sparseGRMSampleIDFile can be used to specify a pre-calcuated sparse GRM and the sample ids for the sparse GRM (output from step 0). Tested samples would be a subset of samples in the pre-calcuated GRM.</li><li>To activate the variance ratio estimation based multiple MAC categories, <em><strong>–isCateVarianceRatio&#x3D;TRUE</strong></em></li><li><em><strong>cateVarRatioMinMACVecExclude</strong></em> and <em><strong>cateVarRatioMaxMACVecInclude</strong></em> are used to specify the MAC categories</li></ul><pre><code>#by default  --cateVarRatioMinMACVecExclude=0.5,1.5,2.5,3.5,4.5,5.5,10.5,20.5 --cateVarRatioMaxMACVecInclude=1.5,2.5,3.5,4.5,5.5,10.5,20.5corresponding to0.5 &lt; MAC &lt;=  1.51.5 &lt; MAC &lt;=  2.52.5 &lt; MAC &lt;=  3.53.5 &lt; MAC &lt;=  4.54.5 &lt; MAC &lt;=  5.55.5 &lt; MAC &lt;=  10.510.5 &lt; MAC &lt;=  20.520.5 &lt; MAC</code></pre><pre><code>Rscript step1_fitNULLGLMM.R     \    --plinkFile=./input/nfam_100_nindep_0_step1_includeMoreRareVariants_poly \        --phenoFile=./input/pheno_1000samples.txt_withdosages_withBothTraitTypes.txt \        --phenoCol=y_quantitative \        --covarColList=x1,x2 \        --sampleIDColinphenoFile=IID \        --traitType=quantitative       \        --invNormalize=TRUE     \        --outputPrefix=./output/example_quantitative \    --outputPrefix_varRatio=./output/example_quantitative_cate\    --sparseGRMFile=./output/example_binary_cate.varianceRatio.txt.sparseGRM.mtx    \        --sparseGRMSampleIDFile=./output/example_binary.varianceRatio.txt.sparseGRM.mtx.sample  \        --nThreads=4 \        --LOCO=FALSE\    --skipModelFitting=FALSE \        --IsSparseKin=TRUE      \        --isCateVarianceRatio=TRUE</code></pre><h4 id="Input-files-2"><a href="#Input-files-2" class="headerlink" title="Input files"></a>Input files</h4><p>1.(same as step 1 for single-variant assoc tests and step 0)</p><p>Genotype file for constructing the genetic relationship matrix in the plink format </p><p>2.a file storing the sparse GRM (optional, output by step 0)</p><pre><code>sparseGRM_relatednessCutoff_0.125_1000_randomMarkersUsed.sparseGRM.mtx</code></pre><p>The sparse GRM file can be opened using the readMM function in the R library Matrix</p><p>3.a file storing IDs of the samples in the sparse GRM (optional, output by step 0)</p><pre><code>sparseGRM_relatednessCutoff_0.125_1000_randomMarkersUsed.sparseGRM.mtx.sampleIDs.txt</code></pre><h4 id="Output-files-2"><a href="#Output-files-2" class="headerlink" title="Output files"></a>Output files</h4><ul><li>same as the step 1 output by SAIGE for single-variant association tests</li></ul><ol><li>model file </li><li>association result file for the subset of randomly selected markers </li><li>variance ratio file</li></ol><ul><li>specific to SAIGE-GENE</li></ul><ol start="4"><li>sparse Sigma file</li></ol><pre><code>sparseGRM_relatednessCutoff_0.125_1000_randomMarkersUsed.sparseSigma.mtx</code></pre><p><strong>NOTE</strong>: the file contains the sparse Sigma matrix, which is ** NOT ** the sparse GRM. The sparse Sigma matrix is computed based on the sparse GRM and the results of step 1.</p><h3 id="Step-2-performing-the-region-or-gene-based-association-tests"><a href="#Step-2-performing-the-region-or-gene-based-association-tests" class="headerlink" title="Step 2: performing the region- or gene-based association tests"></a>Step 2: performing the region- or gene-based association tests</h3><ul><li>The command line is the same as the step 2 for single-variant assoc tests, except that a group file is specified (–groupFile)</li><li>Each line is for one gene&#x2F;set of variants. The first element is for gene&#x2F;set name.</li><li>The rest of the line is for variant ids included in this gene&#x2F;set. For vcf&#x2F;sav, the genetic marker ids are in the format chr:pos_ref&#x2F;alt. For bgen, the genetic marker ids should match the ids in the bgen file. Each element in the line is separated by tab.</li><li>IsSingleVarinGroupTest&#x3D;TRUE is to perform single-variant association tests as well for markers included in the gene-based tests</li><li>–IsOutputBETASEinBurdenTest is to output effect sizes for burden tests (this option is still under development)</li><li>Same as the single-variant association tests, conditional analysis based summary stats can be performed (–condition) can be performed in step 2 with dosage&#x2F;genotype input file formats VCF, BGEN and SAV.</li></ul><pre><code>Rscript step2_SPAtests.R \        --vcfFile=./input/genotype_10markers.vcf.gz \        --vcfFileIndex=./input/genotype_10markers.vcf.gz.tbi \        --vcfField=GT \        --chrom=1 \    --minMAF=0 \        --minMAC=0.5 \        --maxMAFforGroupTest=0.01       \        --sampleFile=./input/samplelist.txt \        --GMMATmodelFile=./output/example_quantitative.rda \        --varianceRatioFile=./output/example_quantitative_cate.varianceRatio.txt \        --SAIGEOutputFile=./output/example_quantitative.SAIGE.gene.txt \        --numLinesOutput=1 \        --groupFile=./input/groupFile_geneBasedtest_simulation.txt    \        --sparseSigmaFile=./output/example_quantitative_cate.varianceRatio.txt_relatednessCutoff_0.125.sparseSigma.mtx       \        --IsSingleVarinGroupTest=TRUE##another example, conditional analysis for gene-based testsRscript step2_SPAtests.R \        --vcfFile=./input/seedNumLow_126001_seedNumHigh_127000_nfam_1000_nindep_0.sav \        --vcfFileIndex=./input/seedNumLow_126001_seedNumHigh_127000_nfam_1000_nindep_0.sav.s1r \        --vcfField=DS \        --chrom=chr1 \        --minMAF=0 \        --minMAC=0.5 \        --maxMAFforGroupTest=0.01       \        --sampleFile=./input/samplelist.txt \        --GMMATmodelFile=./output/example_quantitative.rda \        --varianceRatioFile=./output/example_quantitative_cate.varianceRatio.txt \    --SAIGEOutputFile=./output/example_quantitative.SAIGE.gene_conditional.txt \        --numLinesOutput=1 \        --groupFile=./input/groupFile_geneBasedtest.txt    \        --sparseSigmaFile=./output/example_quantitative_cate.varianceRatio.txt_relatednessCutoff_0.125.sparseSigma.mtx       \        --IsOutputAFinCaseCtrl=TRUE     \        --IsSingleVarinGroupTest=TRUE   \    --condition=chr1:32302_A/C ##Specify customized weights for markers in the gene- or region-based tests* weightsIncludeinGroupFile logical. Whether to specify customized weight for makers in gene- or region-based tests. If TRUE, weights are included in the group file. For vcf/sav, the genetic marker ids and weights are in the format chr:pos_ref/alt;weight. For bgen, the genetic marker ids should match the ids in the bgen filE, e.g. SNPID;weight. Each element in the line is seperated by tab. By default, FALSE* weights_for_G2_cond vector of float. weights for conditioning markers for gene- or region-based tests. The length equals to the number of conditioning markers, delimited by comma.Rscript step2_SPAtests.R \        --vcfFile=./input/seedNumLow_126001_seedNumHigh_127000_nfam_1000_nindep_0.sav \        --vcfFileIndex=./input/seedNumLow_126001_seedNumHigh_127000_nfam_1000_nindep_0.sav.s1r \        --vcfField=DS \        --chrom=chr1 \        --minMAF=0 \        --minMAC=0.5 \        --maxMAFforGroupTest=0.01       \        --sampleFile=./input/samplelist.txt \        --GMMATmodelFile=./output/example_binary.rda \        --varianceRatioFile=./output/example_binary_cate_v2.varianceRatio.txt \        --SAIGEOutputFile=./output/example_binary.SAIGE.gene_conditional_withspecifiedWeights.txt \        --numLinesOutput=1 \        --groupFile=./input/groupFile_geneBasedtest_withWeights.txt    \        --sparseSigmaFile=./output/example_binary_cate_v2.varianceRatio.txt_relatednessCutoff_0.125.sparseSigma.mtx       \        --IsOutputAFinCaseCtrl=TRUE     \        --IsSingleVarinGroupTest=TRUE   \        --IsOutputPvalueNAinGroupTestforBinary=TRUE     \        --IsAccountforCasecontrolImbalanceinGroupTest=TRUE      \        --weightsIncludeinGroupFile=TRUE        \        --weights_for_G2_cond=3,1       \        --condition=chr1:32302_A/C,chr1:32304_A/C</code></pre><h4 id="Input-files-3"><a href="#Input-files-3" class="headerlink" title="Input files"></a>Input files</h4><ul><li>same as step 1 input by SAIGE for single-variant association tests</li></ul><ol><li><p>Dosage file </p><p>SAIGE-GENE can take in VCF, BCF, BGEN, and SAV.</p></li><li><p>Sample file </p><p>This file contains one column for sample IDs corresponding to the sample order in the dosage file. <strong>No header is included</strong>.</p></li></ol><pre><code>less -S sampleIDindosage.txt</code></pre><ol start="3"><li>Model file from step 1</li></ol><pre><code>./output/example.rda</code></pre><ol start="4"><li>Variance ratio file from step 1</li></ol><pre><code>./output/example.varianceRatio.txt</code></pre><ul><li>specific to SAIGE-GENE</li></ul><ol start="5"><li><p>Group file </p><p>Each line is for one gene&#x2F;set of variants. The first element is for gene&#x2F;set name.</p></li></ol><p>The rest of the line is for variant ids included in this gene&#x2F;set. For vcf&#x2F;sav, the genetic marker ids are in the format chr:pos_ref&#x2F;alt. For bgen, the genetic marker ids should match the ids in the bgen file. Each element in the line is separated by tab.<br>** Note that the order of variants in the group file needs to be consistent to variants’ order in the dosage file ** To specify customized weights for variants, set weightsIncludeinGroupFile&#x3D;TRUE and in the group file, for vcf&#x2F;sav, the genetic marker ids and weights are in the format chr:pos_ref&#x2F;alt;weight. For bgen, the genetic marker ids should match the ids in the bgen filE, e.g. SNPID;weight. Each element in the line is seperated by tab.**<br>** If weightsIncludeinGroupFile&#x3D;TRUE, in conditional analysis, weights for conditioning markers need to be specified using the argument weights_for_G2_cond, e.g. weights_for_G2_cond&#x3D;1,3,4. The weights in –weights_for_G2_cond are for markers in –condition, respectively.**</p><pre><code>less -S ./input/groupFile_geneBasedtest.txt</code></pre><ol start="6"><li>sparse Sigma file</li></ol><pre><code>sparseGRM_relatednessCutoff_0.125_1000_randomMarkersUsed.sparseSigma.mtx</code></pre><h4 id="Output-files-3"><a href="#Output-files-3" class="headerlink" title="Output files"></a>Output files</h4><ol><li>A file with region- or gene-based association test results</li></ol><pre><code>less -S ./output/example_quantitative.SAIGE.gene_conditional.txt</code></pre><p><strong>NOTE:</strong></p><p>  The header of the output file: <code>Gene Pvalue Pvalue_cond Nmarker_MACCate_1 Nmarker_MACCate_2 Nmarker_MACCate_3 Nmarker_MACCate_4 Nmarker_MACCate_5 Nmarker_MACCate_6 Nmarker_MACCate_7 Nmarker_MACCate_8 markerIDs markerAFs Pvalue_Burden Pvalue_SKAT Pvalue_Burden_cond Pvalue_SKAT_cond</code></p><pre><code>Gene : Gene name (as provided in the group file)Pvalue: p-value of SKAT-O testPvalue_cond: conditional p-value of SKAT-O test (if --condition= is specified)Nmarker_MACCate_n: number of markers in the gene falling in the nth MAC category (The MAC category is corresponding to the one used for the variance ratio estimation). For example, by default, Nmarker_MACCate_1 is the number of singletonsmarkerIDs: IDs for variants included in the testmarkerAFs: allele frequencies for variants included in the testPvalue_Burden: p-value of Burden testPvalue_SKAT: p-value of SKAT testPvalue_Burden_cond: conditional p-value of Burden test (if --condition= is specified)Pvalue_SKAT_cond: conditional p-value of SKAT test (if --condition= is specified)Pvalue_SKAT.NA: p-values of SKAT test without accounting for unbalanced case-control ratios for binary traitsPvalue.NA: p-values of SKAT-O test without accounting for unbalanced case-control ratios for binary traitsPvalue_Burden.NA: p-values of Burden test without accounting for unbalanced case-control ratios for binary traits</code></pre><ol start="2"><li>A file with single-variant association test results for genetic variants included in the gene-based tests (if –IsSingleVarinGroupTest&#x3D;TRUE)</li></ol><pre><code>less -S ./output/example_quantitative.SAIGE.gene_conditional.txt_single</code></pre><p>Same as the output by SAIGE for single-variant association tests</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>linux基础|Anaconda安装及Conda使用教程</title>
      <link href="/2020-06-10-linux-ji-chu-anaconda-an-zhuang-ji-conda-shi-yong-jiao-cheng/"/>
      <url>/2020-06-10-linux-ji-chu-anaconda-an-zhuang-ji-conda-shi-yong-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<font face="times new roman" size=4><span id="more"></span><p>linux基础|Anaconda安装及Conda使用教程</p><!-- toc --><hr><h1 id="1-Anaconda下载"><a href="#1-Anaconda下载" class="headerlink" title="1.Anaconda下载"></a>1.Anaconda下载</h1><p>Anaconda Linux版本下载地址<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.3.1-Linux-x86_64.sh">清华镜像源</a></p><h1 id="2-Anaconda安装"><a href="#2-Anaconda安装" class="headerlink" title="2.Anaconda安装"></a>2.Anaconda安装</h1><h2 id="安装代码"><a href="#安装代码" class="headerlink" title="安装代码"></a>安装代码</h2><pre><code>bash Anaconda3-5.3.1-Linux-x86_64.sh</code></pre><h2 id="安装过程注意事项："><a href="#安装过程注意事项：" class="headerlink" title="安装过程注意事项："></a>安装过程注意事项：</h2><ul><li><p>首词bash也需要输入，无论是否用的Bash shell。</p></li><li><p>安装过程中，看到提示“In order to continue the installation process, please review the license agreement.”（“请浏览许可证协议以便继续安装。”），点击“Enter”查看“许可证协议”。</p></li><li><p>在“许可证协议”界面将屏幕滚动至底，输入“yes”表示同意许可证协议内容。然后进行下一步。</p></li><li><p>安装过程中，提示“Press Enter to accept the default install location, CTRL-C to cancel the installation or specify an alternate installation directory.”（“按回车键确认安装路径，按’CTRL-C’取消安装或者指定安装目录。”）如果接受默认安装路径，则会显示“PREFIX&#x3D;&#x2F;home&#x2F;<user>&#x2F;anaconda&lt;2 or 3&gt;”并且继续安装。安装过程大约需要几分钟的时间。</p></li><li><p>安装器若提示“Do you wish the installer to prepend the Anaconda&lt;2 or 3&gt; install location to PATH in your &#x2F;home&#x2F;<user>&#x2F;.bashrc ?”（“你希望安装器添加Anaconda安装路径在&#x2F;home&#x2F;<user>&#x2F;.bashrc文件中吗？”），建议输入“yes”。<strong>注意：</strong>路径&#x2F;home&#x2F;<user>&#x2F;.bash_rc中“<user>”即进入到家目录后你的目录名。如果输入“no”，则需要手动添加路径，否则conda将无法正常运行。</p></li><li><p>当看到“Thank you for installing Anaconda&lt;2 or 3&gt;!”则说明已经成功完成安装。</p></li></ul><h2 id="验证安装结果。"><a href="#验证安装结果。" class="headerlink" title="验证安装结果。"></a>验证安装结果。</h2><p><strong>可选用以下任意一种方法：</strong></p><ul><li><p>在终端中输入命令condal list，如果Anaconda被成功安装，则会显示已经安装的包名和版本号。</p></li><li><p>在终端中输入python。这条命令将会启动Python交互界面，如果Anaconda被成功安装并且可以运行，则将会在Python版本号的右边显示“Anaconda custom (64-bit)”。退出Python交互界面则输入exit()或quit()即可。</p></li><li><p>在终端中输入anaconda-navigator。如果Anaconda被成功安装，则Anaconda Navigator将会被启动。</p></li></ul><h1 id="3-conda管理"><a href="#3-conda管理" class="headerlink" title="3.conda管理"></a>3.conda管理</h1><h2 id="3-1-验证conda已被安装"><a href="#3-1-验证conda已被安装" class="headerlink" title="3.1 验证conda已被安装"></a>3.1 验证conda已被安装</h2><pre><code>conda list</code></pre><p>终端上将会以conda 版本号的形式显示当前安装conda的版本号。如：conda 4.5.11</p><h2 id="3-2-卸载conda"><a href="#3-2-卸载conda" class="headerlink" title="3.2 卸载conda"></a>3.2 卸载conda</h2><pre><code>rm -rf ~/anaconda2</code></pre><h2 id="3-3-管理环境"><a href="#3-3-管理环境" class="headerlink" title="3.3 管理环境"></a>3.3 管理环境</h2><h3 id="创建新环境"><a href="#创建新环境" class="headerlink" title="创建新环境"></a>创建新环境</h3><pre><code>conda create --name wgsor #安装python3环境conda create --name wgs python=3.7or #安装python2环境conda create --name wgs python=2.7</code></pre><h3 id="切换环境"><a href="#切换环境" class="headerlink" title="切换环境"></a>切换环境</h3><pre><code>source activate wgs</code></pre><h3 id="退出环境至root"><a href="#退出环境至root" class="headerlink" title="退出环境至root"></a>退出环境至root</h3><pre><code>source deactivate</code></pre><h3 id="显示已创建环境"><a href="#显示已创建环境" class="headerlink" title="显示已创建环境"></a>显示已创建环境</h3><pre><code>conda info --envs</code></pre><h3 id="删除环境"><a href="#删除环境" class="headerlink" title="删除环境"></a>删除环境</h3><pre><code>conda remove --name wgs --all</code></pre><h3 id="导入导出环境"><a href="#导入导出环境" class="headerlink" title="导入导出环境"></a>导入导出环境</h3><p>如果想要导出当前环境的包信息可以用</p><pre><code>#将包信息存入yaml文件中:conda env export &gt; environment.yaml</code></pre><p>当需要重新创建一个相同的虚拟环境时可以用</p><pre><code>conda env create -f environment.yaml</code></pre><h2 id="3-4-管理conda包"><a href="#3-4-管理conda包" class="headerlink" title="3.4 管理conda包"></a>3.4 管理conda包</h2><h3 id="查找可供安装的包版本"><a href="#查找可供安装的包版本" class="headerlink" title="查找可供安装的包版本"></a>查找可供安装的包版本</h3><pre><code>conda search vcftools</code></pre><h3 id="获取当前环境中已安装的包信息"><a href="#获取当前环境中已安装的包信息" class="headerlink" title="获取当前环境中已安装的包信息"></a>获取当前环境中已安装的包信息</h3><pre><code>conda list</code></pre><h3 id="安装包"><a href="#安装包" class="headerlink" title="安装包"></a>安装包</h3><pre><code>conda install vcftools</code></pre><p>conda config –add channels <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</a><br>conda config –add channels <a href="http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/">http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/</a><br>conda config –add channels <a href="http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free">http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free</a><br>conda config –add channels <a href="http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main">http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</a><br>conda config –add channels <a href="http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2">http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</a><br>conda config –add channels <a href="http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro">http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro</a><br>conda config –add channels <a href="http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r">http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</a><br>conda config –set show_channel_urls yes</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>WGCNA最佳实战</title>
      <link href="/2020-06-06-wgcna-zui-jia-shi-zhan/"/>
      <url>/2020-06-06-wgcna-zui-jia-shi-zhan/</url>
      
        <content type="html"><![CDATA[<font face="宋体" size=4><span id="more"></span><p>WGCNA最佳实战</p><!-- toc --><hr><h1 id="什么是WGCNA"><a href="#什么是WGCNA" class="headerlink" title="什么是WGCNA?"></a>什么是WGCNA?</h1><p><img src="/WGCNA%E6%9C%80%E4%BD%B3%E5%AE%9E%E6%88%98/tutorial.png" alt="tutorials"></p><p><strong>WGCNA</strong>：全称 Weighted correlation network analysis，加权基因共表达网络分析，是用来描述不同样品之间基因关联模式的系统生物学方法，可以用来鉴定高度协同变化的基因集, 并根据基因集的内连性和基因集与表型之间的关联鉴定候补生物标记基因或治疗靶点。</p><p>相比于只关注差异表达的基因，WGCNA利用数千或近万个变化最大的基因或全部基因的信息识别感兴趣的基因集，并与表型进行显著性关联分析。一是充分利用了信息，二是把数千个基因与表型的关联转换为数个基因集与表型的关联，免去了多重假设检验校正的问题。</p><p>理解WGCNA，需要先理解下面<strong>几个术语</strong>和它们在WGCNA中的定义:</p><p><strong>1.共表达网络</strong>：定义为加权基因网络。</p><ul><li><strong>点</strong>代表基因</li><li><strong>边</strong>代表基因表达相关性。</li><li><strong>加权</strong>是指对相关性值进行冥次运算(冥次的值也就是软阈值 (power, pickSoftThreshold这个函数所做的就是确定合适的power))。</li><li><strong>无向网络的边属性计算方式</strong>为abs(cor(genex, geney)) ^ power；</li><li><strong>有向网络的边属性计算方式</strong>为(1+cor(genex, geney)&#x2F;2) ^ power;</li><li><strong>sign hybrid</strong>的边属性计算方式为cor(genex, geney)^power if cor&gt;0 else 0。这种处理方式强化了强相关，弱化了弱相关或负相关，使得相关性数值更符合无标度网络特征，更具有生物意义。如果没有合适的power，一般是由于部分样品与其它样品因为某种原因差别太大导致的，可根据具体问题移除部分样品或查看后面的经验值。</li></ul><p>**2.Module(模块)**：高度內连的基因集，表达模式相似的基因分为一类，这样的一类基因成为模块。</p><ul><li>在无向网络中，模块内是高度相关的基因。在有向网络中，模块内是高度正相关的基因。</li><li>把基因聚类成模块后，可以对<strong>每个模块进行三个层次的分析</strong>：(1)功能富集分析查看其功能特征是否与研究目的相符；(2)模块与性状进行关联分析，找出与关注性状相关度最高的模块；(3)模块与样本进行关联分析，找到样品特异高表达的模块。</li></ul><p>**3.Connectivity (连接度)**：类似于网络中”<strong>度(degree)</strong>“的概念。每个基因的连接度是与其相连的基因的边属性之和。</p><p><strong>4.Module eigengene E</strong>: 给定模型的第一主成分，代表整个模型的基因表达谱。<strong>PCA分析</strong>的降维作用，之前主要是拿来做可视化，现在用到这个地方，很好的用一个向量代替了一个矩阵，方便后期计算。(降维除了<strong>PCA</strong>，还可以看看<strong>tSNE</strong>)</p><p><strong>5.Intramodular connectivity</strong>: 给定基因与给定模型内其他基因的关联度，判断基因所属关系。</p><p><strong>6.Module membership</strong>: 给定基因表达谱与给定模型的eigengene的相关性。</p><p><strong>7.Hub gene</strong>: 关键基因 (连接度最多或连接多个模块的基因)。</p><p>**8.Adjacency matrix (邻接矩阵)**：基因和基因之间的加权相关性值构成的矩阵。</p><p>**9.TOM (Topological overlap matrix)**：把邻接矩阵转换为拓扑重叠矩阵，以降低噪音和假相关，获得的新距离矩阵，这个信息可拿来构建网络或绘制TOM图。</p><h1 id="WGCNA基本分析流程"><a href="#WGCNA基本分析流程" class="headerlink" title="WGCNA基本分析流程"></a>WGCNA基本分析流程</h1><p><img src="/WGCNA%E6%9C%80%E4%BD%B3%E5%AE%9E%E6%88%98/%E5%9F%BA%E6%9C%AC%E5%88%86%E6%9E%90%E6%B5%81%E7%A8%8B.png" alt="基本分析流程"></p><ul><li><p>构建基因共表达网络：使用加权的表达相关性。</p></li><li><p>识别基因集：基于加权相关性，进行层级聚类分析，并根据设定标准切分聚类结果，获得不同的基因模块，用聚类树的分枝和不同颜色表示。</p></li><li><p>如果有表型信息，计算基因模块与表型的相关性，鉴定性状相关的模块。</p></li><li><p>研究模型之间的关系，从系统层面查看不同模型的互作网络。</p></li><li><p>从关键模型中选择感兴趣的驱动基因，或根据模型中已知基因的功能推测未知基因的功能。</p></li><li><p>导出TOM矩阵，绘制相关性图。</p></li></ul><h1 id="WGCNA分析实战"><a href="#WGCNA分析实战" class="headerlink" title="WGCNA分析实战"></a>WGCNA分析实战</h1><p>WGCNA本质是基于相关系数的网络分析方法，适用于多样品数据模式，一般要求样本数多于15个。样本数多于20时效果更好，样本越多，结果越稳定。一般可应用的研究方向有：不同器官或组织类型发育调控、同一组织不同发育调控、非生物胁迫不同时间点应答、病原菌侵染后不同时间点应答。</p><p><strong>从方法上来讲</strong>，WGCNA分为<strong>表达量聚类分析</strong>和<strong>表型关联</strong>两部分，主要包括基因之间相关系数计算、基因模块的确定、共表达网络、模块与性状关联四个步骤。</p><ul><li><strong>基因表达矩阵</strong>: 芯片数据的归一化矩阵。常规表达矩阵即可，即基因在行，样品在列，一般以RPKM为单位,RPKM、FPKM或其它标准化方法影响不大。进入分析前做一个转置：推荐使用<code>Deseq2</code>的<code>varianceStabilizingTransformation</code>或<code>log2(x+1)</code>对标准化后的数据做个转换；如果数据来自不同的批次，需要先移除批次效应；如果数据存在系统偏移，需要做下<code>quantile normalization</code>。<br>需要两样东西：表达矩阵datExpr、表型矩阵datTraits</li><li><strong>性状矩阵或表型矩阵</strong>：用于关联分析的性状或表型必须是数值型矩阵 (如下面示例中的Height, Weight,Diameter)。本身就是数值型：如长度、重量等，直接使用；如果是区域或分类变量，需要转换为0-1矩阵的形式：如患病与否这样的分类变量，需要用0-1表示（0表示没有该属性：患病，1表示有该属性），构建0-1矩阵后再分析。</li></ul><pre><code>ID    Sick Height Weight sam1   1     1   2   sam2   1     2   7 sam3   0     10  22 sam4   0     NA  31  sam5   0     14  19 </code></pre><h2 id="第一步-数据输入与初步处理"><a href="#第一步-数据输入与初步处理" class="headerlink" title="第一步 数据输入与初步处理"></a>第一步 数据输入与初步处理</h2><pre><code>wkdir &lt;- &quot;F:/biosoft/WCGNA/测试数据&quot;setwd(wkdir)library(WGCNA)options(stringsAsFactors = FALSE)femData = read.csv(&quot;LiverFemale3600.csv&quot;)#dim(femData)names(femData) #看一下列名</code></pre><h3 id="进行转置：设置初步的表达矩阵：样本为行，观测为列"><a href="#进行转置：设置初步的表达矩阵：样本为行，观测为列" class="headerlink" title="进行转置：设置初步的表达矩阵：样本为行，观测为列"></a>进行转置：设置初步的表达矩阵：样本为行，观测为列</h3><pre><code>datExpr0 = as.data.frame(t(femData[, -c(1:8)]))names(datExpr0) = femData$substanceBXHrownames(datExpr0) = names(femData)[-c(1:8)]</code></pre><h3 id="检查基因和样本是否有太多的缺失值【太多就去掉】"><a href="#检查基因和样本是否有太多的缺失值【太多就去掉】" class="headerlink" title="检查基因和样本是否有太多的缺失值【太多就去掉】"></a>检查基因和样本是否有太多的缺失值【太多就去掉】</h3><pre><code>gsg = goodSamplesGenes(datExpr0, verbose = 3)gsg$allOK # 返回TRUE则继续# （可选）如果存在太多的缺失值if (!gsg$allOK)&#123;  # 把含有缺失值的基因或样本打印出来  if (sum(!gsg$goodGenes)&gt;0)    printFlush(paste(&quot;Removing genes:&quot;, paste(names(datExpr0)[!gsg$goodGenes], collapse = &quot;, &quot;)));  if (sum(!gsg$goodSamples)&gt;0)    printFlush(paste(&quot;Removing samples:&quot;, paste(rownames(datExpr0)[!gsg$goodSamples], collapse = &quot;, &quot;)));  # 去掉那些缺失值  datExpr0 = datExpr0[gsg$goodSamples, gsg$goodGenes]&#125;</code></pre><h3 id="对样本进行聚类-检测异常值"><a href="#对样本进行聚类-检测异常值" class="headerlink" title="对样本进行聚类,检测异常值"></a>对样本进行聚类,检测异常值</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">if(T)&#123;  sampleTree = hclust(dist(datExpr0), method = "average")  par(cex = 0.6)  par(mar = c(0,4,2,0))  plot(sampleTree, main = "Sample clustering to detect outliers", sub="", xlab="", cex.lab = 1.5,       cex.axis = 1.5, cex.main = 2)  # 结果可以看到，F2_221是一个异常值  abline(h = 15, col = "red") #先画一条辅助线&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="去除异常值，得到过滤后的表达矩阵"><a href="#去除异常值，得到过滤后的表达矩阵" class="headerlink" title="去除异常值，得到过滤后的表达矩阵"></a>去除异常值，得到过滤后的表达矩阵</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;"># 把高于15的切除clust = cutreeStatic(sampleTree, cutHeight = 15, minSize = 10)table(clust) # 0代表切除的，1代表保留的keepSamples = (clust==1)datExpr = datExpr0[keepSamples, ]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="开始设置表型矩阵-x3D-》加载表型信息"><a href="#开始设置表型矩阵-x3D-》加载表型信息" class="headerlink" title="开始设置表型矩阵&#x3D;》加载表型信息"></a>开始设置表型矩阵&#x3D;》加载表型信息</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">traitData = read.csv("ClinicalTraits.csv")#dim(traitData)names(traitData)# 去掉不需要的信息，得到全部样本的表型矩阵allTraits = traitData[, -c(31, 16)] #去掉'note'、'comments'allTraits = allTraits[, c(2, 11:36) ] # 去掉中间的日期之类的dim(allTraits)names(allTraits)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="得到部分表型矩阵-x3D-》表达矩阵有哪些样本，表型矩阵就有哪些样本"><a href="#得到部分表型矩阵-x3D-》表达矩阵有哪些样本，表型矩阵就有哪些样本" class="headerlink" title="得到部分表型矩阵&#x3D;》表达矩阵有哪些样本，表型矩阵就有哪些样本"></a>得到部分表型矩阵&#x3D;》表达矩阵有哪些样本，表型矩阵就有哪些样本</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">femaleSamples = rownames(datExpr)traitRows = match(femaleSamples, allTraits$Mice)# 把原来的第一列Mice变成行名datTraits = allTraits[traitRows, -1]rownames(datTraits) = allTraits[traitRows, 1]collectGarbage() #释放内存空间<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>到这里为止，得到了所有样本的表达矩阵和表型矩阵，在进一步构建网络、检测模块之前，先看下表型和样本的相关性</p></blockquote><h3 id="针对去除异常值的表达矩阵进行聚类分析"><a href="#针对去除异常值的表达矩阵进行聚类分析" class="headerlink" title="针对去除异常值的表达矩阵进行聚类分析"></a>针对去除异常值的表达矩阵进行聚类分析</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">sampleTree2 = hclust(dist(datExpr), method = "average")# 用颜色表示表型在各个样本的表现: 白色表示低，红色为高，灰色为缺失traitColors = numbers2colors(datTraits, signed = FALSE)# 把样本聚类和表型热图绘制在一起if(T)&#123;  plotDendroAndColors(sampleTree2, traitColors,                      groupLabels = names(datTraits),                      main = "Sample dendrogram and trait heatmap")&#125;save(datExpr, datTraits, file = "FemaleLiver-01-dataInput.RData")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="第二步-网络分析"><a href="#第二步-网络分析" class="headerlink" title="第二步 网络分析"></a>第二步 网络分析</h2><h3 id="构建网络、检测协同表达的基因模块（非常重要的一步！）"><a href="#构建网络、检测协同表达的基因模块（非常重要的一步！）" class="headerlink" title="构建网络、检测协同表达的基因模块（非常重要的一步！）"></a>构建网络、检测协同表达的基因模块（非常重要的一步！）</h3><blockquote><p>实现构建网络有3种方法：(3选1即可)<br>1.One-step；<br>2.Step-by-step 支持自定义一些参数；<br>3.Block-wise network construction 针对大型数据<br><strong>这里采用一步分析法</strong></p></blockquote><h3 id="加载之前保存的RData"><a href="#加载之前保存的RData" class="headerlink" title="加载之前保存的RData"></a>加载之前保存的RData</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">lnames = load(file = "FemaleLiver-01-dataInput.RData")<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="筛选软阈值（soft-thresholding-power）"><a href="#筛选软阈值（soft-thresholding-power）" class="headerlink" title="筛选软阈值（soft thresholding power）"></a>筛选软阈值（soft thresholding power）</h3><blockquote><p>原则是使构建的网络更符合无标度网络特征</p></blockquote><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">#设置一系列软阈值（默认1到30）powers = c(c(1:10), seq(from = 12, to=20, by=2))#帮助用户选择合适的软阈值，进行拓扑网络分析#需要输入表达矩阵、设置的阈值范围、运行显示的信息程度(verbose=0不显示任何信息)sft = pickSoftThreshold(datExpr, powerVector = powers, verbose = 5)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>sft结果有两列，其中powerEstimate返回最佳的软阈值beta值。这里的结果是6，表示从6达到高阈值以后，图形曲线开始变平，就是说：到达阈值6时网络拓扑结构连通的就差不多了，够本了！具体见下面做出的图(左一)来理解。实际使用并不需要知道具体值</p><p>画出结果 &#x3D;》横轴是Soft threshold (power)<br>(左图)纵轴是无标度网络的评估参数（相关系数的平方),数值越高，网络越符合无标度特征 (non-scale)<br>(右图)纵轴是基因模块中所有基因邻接函数的均值</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">if(T)&#123;  par(mfrow = c(1,2))  cex1 = 0.9  plot(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2],       xlab="Soft Threshold (power)",       ylab="Scale Free Topology Model Fit,signed R^2",type="n",       main = paste("Scale independence"))  #注意这里的-sign(sft$fitIndices[,3])中sign函数，它把正数、负数分别转为1、-1  text(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2],       labels=powers,cex=cex1,col="red")  # 设置筛选标准h=r^2^=0.9。这里的0.9是个大概的数，就是看左图软阈值6大概对应的位置  abline(h=0.90,col="red")  #看一下Soft threshold与平均连通性  plot(sft$fitIndices[,1], sft$fitIndices[,5],       xlab="Soft Threshold (power)",ylab="Mean Connectivity", type="n",       main = paste("Mean connectivity"))  text(sft$fitIndices[,1], sft$fitIndices[,5], labels=powers, cex=cex1,col="red")&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="一步构建网络-关键一步！"><a href="#一步构建网络-关键一步！" class="headerlink" title="一步构建网络[关键一步！]"></a>一步构建网络[关键一步！]</h3><blockquote><p>几千个基因组归类成了几十个模块<br>计算基因间的邻接性，根据邻接性计算基因间的相似性，然后算出基因间的相异性系数，并因此得到基因间的系统聚类树<br>按照混合动态剪切树的标准，设置每个基因模块最少的基因数目为30<br>确定基因模块后，再次分析，依次计算每个模块的特征向量值<br>对模块进行聚类分析，将距离较近的模块合并为新的模块<br>power就是上面计算得到的软阈值</p></blockquote><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">net = blockwiseModules(datExpr, power = 6,                       TOMType = "unsigned", minModuleSize = 30,                       reassignThreshold = 0, mergeCutHeight = 0.25,                       numericLabels = TRUE, pamRespectsDendro = FALSE,                       saveTOMs = TRUE,                       saveTOMFileBase = "femaleMouseTOM",                       verbose = 3)# 显示模块数量以及各自包含的基因数目# 0表示未分入任何模块的基因# 1是最大的模块，往后依次降序排列，分别对应各自模块的基因table(net$colors)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模块可视化-x3D-》聚类树"><a href="#模块可视化-x3D-》聚类树" class="headerlink" title="模块可视化&#x3D;》聚类树"></a>模块可视化&#x3D;》聚类树</h3><p>将每个模块对应的基因数转换成颜色单位, 灰色默认是无法归类于任何模块的那些基因</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">mergedColors = labels2colors(net$colors)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>先画聚类，后画颜色</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">if(T)&#123;  plotDendroAndColors(net$dendrograms[[1]], mergedColors[net$blockGenes[[1]]],                      "Module colors",                      dendroLabels = FALSE, hang = 0.03,                      addGuide = TRUE, guideHang = 0.05)&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>保存数据</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">moduleLabels = net$colorsmoduleColors = labels2colors(net$colors)MEs = net$MEsgeneTree = net$dendrograms[[1]]save(MEs, moduleLabels, moduleColors, geneTree,     file = "FemaleLiver-02-networkConstruction-auto.RData")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="第三步-模块联系表型信息"><a href="#第三步-模块联系表型信息" class="headerlink" title="第三步 模块联系表型信息"></a>第三步 模块联系表型信息</h2><p>看看哪些表型的哪些模块是自己感兴趣的（一般选热图颜色深的）<br>这样初步表明该模块中基因可能是有研究价值的；<br>下一步，进行一个验证，看看这个模块中基因与表型、模块的相关性，看看与模块相关的基因是不是也与表型相关</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">rm(list = ls())load(file = "FemaleLiver-01-dataInput.RData")load(file = "FemaleLiver-02-networkConstruction-auto.RData")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="模块关联表型"><a href="#模块关联表型" class="headerlink" title="模块关联表型"></a>模块关联表型</h2><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;"># 得到基因、样本数量nGenes = ncol(datExpr)nSamples = nrow(datExpr)# 用color labels重新计算MEs（Module Eigengenes:模块的第一主成分）MEs0 = moduleEigengenes(datExpr, moduleColors)$eigengenesMEs = orderMEs(MEs0)moduleTraitCor = cor(MEs, datTraits, use = "p") #（这是重点）计算ME和表型相关性moduleTraitPvalue = corPvalueStudent(moduleTraitCor, nSamples)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="对moduleTraitCor画热图，看结果挑选自己感兴趣的模块进行下游分析"><a href="#对moduleTraitCor画热图，看结果挑选自己感兴趣的模块进行下游分析" class="headerlink" title="对moduleTraitCor画热图，看结果挑选自己感兴趣的模块进行下游分析"></a>对moduleTraitCor画热图，看结果挑选自己感兴趣的模块进行下游分析</h2><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">if(T)&#123;  # 设置热图上的文字（两行数字：第一行是模块与各种表型的相关系数；  # 第二行是p值）  # signif 取有效数字  textMatrix = paste(signif(moduleTraitCor, 2), "\n(",                     signif(moduleTraitPvalue, 1), ")", sep = "")  dim(textMatrix) = dim(moduleTraitCor)  par(mar = c(6, 8.5, 3, 3))  # 然后对moduleTraitCor画热图  labeledHeatmap(Matrix = moduleTraitCor,                 xLabels = names(datTraits),                 yLabels = names(MEs),                 ySymbols = names(MEs),                 colorLabels = FALSE,                 colors = greenWhiteRed(50),                 textMatrix = textMatrix,                 setStdMargins = FALSE,                 cex.text = 0.5,                 zlim = c(-1,1),                 main = paste("Module-trait relationships"))&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>每种表型都有和它非常相关的模块，因此某个模块可以作为某个表型的代表(signature)，对于非常相关的模块，比如weight表型和brown模块，颜色最深。那么里面的基因是什么？于是进行感兴趣表型中核心模块的基因分析</p><h3 id="计算基因与模块的相关性矩阵（MM-Module-Membership）"><a href="#计算基因与模块的相关性矩阵（MM-Module-Membership）" class="headerlink" title="计算基因与模块的相关性矩阵（MM: Module Membership）"></a>计算基因与模块的相关性矩阵（MM: Module Membership）</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;"># 把各个module的名字提取出来（从第三个字符开始），用于一会重命名modNames = substring(names(MEs), 3)# 得到矩阵geneModuleMembership = as.data.frame(cor(datExpr, MEs, use = "p"))# 矩阵t检验MMPvalue = as.data.frame(corPvalueStudent(as.matrix(geneModuleMembership), nSamples))# 修改列名names(geneModuleMembership) = paste("MM", modNames, sep="")names(MMPvalue) = paste("p.MM", modNames, sep="")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="计算基因与表型的相关性矩阵（GS-Gene-Significance）"><a href="#计算基因与表型的相关性矩阵（GS-Gene-Significance）" class="headerlink" title="计算基因与表型的相关性矩阵（GS: Gene Significance）"></a>计算基因与表型的相关性矩阵（GS: Gene Significance）</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;"># 先将感兴趣表型weight提取出来，用于计算矩阵weight = as.data.frame(datTraits$weight_g)names(weight) = "weight"# 得到矩阵geneTraitSignificance = as.data.frame(cor(datExpr, weight, use = "p"))# 矩阵t检验GSPvalue = as.data.frame(corPvalueStudent(as.matrix(geneTraitSignificance), nSamples))# 修改列名names(geneTraitSignificance) = paste("GS.", names(weight), sep="")names(GSPvalue) = paste("p.GS.", names(weight), sep="")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="合并两个相关性矩阵-找到和模块、表型都高度相关的基因"><a href="#合并两个相关性矩阵-找到和模块、表型都高度相关的基因" class="headerlink" title="合并两个相关性矩阵,找到和模块、表型都高度相关的基因"></a>合并两个相关性矩阵,找到和模块、表型都高度相关的基因</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">if(T)&#123;  module = "brown"  column = match(module, modNames) #找到目标模块所在列  moduleGenes = moduleColors==module #找到模块基因所在行  par(mfrow = c(1,1))  verboseScatterplot(abs(geneModuleMembership[moduleGenes, column]),                     abs(geneTraitSignificance[moduleGenes, 1]),                     xlab = paste("Module Membership in", module, "module"),                     ylab = "Gene significance for body weight",                     main = paste("Module membership vs. gene significance\n"),                     cex.main = 1.2, cex.lab = 1.2, cex.axis = 1.2, col = module)&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>图中看到，MM和GS高度正相关，因此说明和表型高度相关的基因，在与表型相关模块中也是核心元素。</p><p>另外，也可以探索weight表型中其他的模块，比如第一个颜色很浅的magenta模块，它的MM和GS整体负相关</p><h2 id="第四步-网络可视化"><a href="#第四步-网络可视化" class="headerlink" title="第四步 网络可视化"></a>第四步 网络可视化</h2><p>【针对基因】热图的方式展示加权网络，每行每列代表一个基因</p><blockquote><p>还能表示邻近关系和拓扑重叠，浅颜色表示关系弱，深颜色表示关系强</p></blockquote><h3 id="基因的聚类分析和模块颜色画在顶部和左侧"><a href="#基因的聚类分析和模块颜色画在顶部和左侧" class="headerlink" title="基因的聚类分析和模块颜色画在顶部和左侧"></a>基因的聚类分析和模块颜色画在顶部和左侧</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">rm(list = ls())load(file = "FemaleLiver-01-dataInput.RData")load(file = "FemaleLiver-02-networkConstruction-auto.RData")nGenes = ncol(datExpr)nSamples = nrow(datExpr)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="选择400个基因画图"><a href="#选择400个基因画图" class="headerlink" title="选择400个基因画图"></a>选择400个基因画图</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">if(T)&#123;  nSelect = 400  set.seed(10)  # 计算拓扑重叠(TOM: Topological Overlap Matrix)  # 这个过程先计算了邻接矩阵，后把邻接矩阵转换为拓扑重叠矩阵，  # 降低了噪音和假相关，获得距离矩阵dissTOM  dissTOM = 1-TOMsimilarityFromExpr(datExpr, power = 6)  select = sample(nGenes, size = nSelect)  selectTOM = dissTOM[select, select]  # 再计算基因之间的距离树(对于基因的子集，需要重新聚类)  selectTree = hclust(as.dist(selectTOM), method = "average")  selectColors = moduleColors[select]  plotDiss = selectTOM^7  diag(plotDiss) = NA #将对角线设成NA，在图形中显示为白色的点，更清晰显示趋势  TOMplot(plotDiss, selectTree, selectColors, main = "Network heatmap plot, selected genes")&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="选择全部基因画图-耗时较久，生成的文件很大"><a href="#选择全部基因画图-耗时较久，生成的文件很大" class="headerlink" title="选择全部基因画图(耗时较久，生成的文件很大)"></a>选择全部基因画图(耗时较久，生成的文件很大)</h3><blockquote><p>结果可以看到各个区块的颜色差异,沿着对角线的深色区块就是模块Module，如果你发现配色反过来了 ，修改方法是给TOMplot加上参数：</p></blockquote><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">col=gplots::colorpanel(250,'red',"orange",'lemonchiffon')if(T)&#123;  plotTOM = dissTOM^7  diag(plotTOM) = NA  TOMplot(plotTOM, geneTree, moduleColors, main = "Network heatmap plot, all genes")&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="【针对模块与表型】展示模块与表型的相关性"><a href="#【针对模块与表型】展示模块与表型的相关性" class="headerlink" title="【针对模块与表型】展示模块与表型的相关性"></a>【针对模块与表型】展示模块与表型的相关性</h3><blockquote><p>重新计算模块的基因样本相关矩阵（Eigengenes就是基因和样本的相关矩阵）</p></blockquote><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">MEs = moduleEigengenes(datExpr, moduleColors)$eigengenes# 将weight表型信息从trait中提取出来weight = as.data.frame(datTraits$weight_g)names(weight) = "weight"# 把weight表型添加到之前计算的ME矩阵中，并排序MET = orderMEs(cbind(MEs, weight))# 画图=》meta-modules（模块的聚类图加上模块与表型的热图）# marDendro/marHeatmap 设置下、左、上、右的边距if(T)&#123;  par(cex = 0.9)  plotEigengeneNetworks(MET, "", marDendro = c(0,4,1,2), marHeatmap = c(4,4,1,2), cex.lab = 0.8, xLabelsAngle                        = 90)&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>图中可以看到，red、blue、brown模块是高度相关的，并且它们的相关性比各自和weight表型的相关性还大；salmon和weight的相关性也比较强，但是加入red、blue、brown的meta-modules阵营还不够格</p><p>当然分开画也是可以的</p><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">if(T)&#123;  par(cex = 1.0)  plotEigengeneNetworks(MET, "Eigengene dendrogram", marDendro = c(0,4,2,0),                        plotHeatmaps = FALSE)  par(cex = 1.0)  plotEigengeneNetworks(MET, "Eigengene adjacency heatmap", marHeatmap = c(4,5,2,2),                        plotDendrograms = FALSE, xLabelsAngle = 90)&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="第五步-导出网络"><a href="#第五步-导出网络" class="headerlink" title="第五步 导出网络"></a>第五步 导出网络</h2><h3 id="准备过程"><a href="#准备过程" class="headerlink" title="准备过程"></a>准备过程</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;"># 重新计算拓扑重叠矩阵TOM = TOMsimilarityFromExpr(datExpr, power = 6)# 选择导出模块module = "brown"# 选择模块中基因/探针probes = names(datExpr)inModule = (moduleColors==module)modProbes = probes[inModule]# 选择相关模块的拓扑重叠矩阵modTOM = TOM[inModule, inModule]dimnames(modTOM) = list(modProbes, modProbes)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="导出到VisANT"><a href="#导出到VisANT" class="headerlink" title="导出到VisANT"></a>导出到VisANT</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">vis = exportNetworkToVisANT(modTOM,                            file = paste("VisANTInput-", module, ".txt", sep=""),                            weighted = TRUE,                            threshold = 0)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="感觉基因太多，可以截取部分（比如前30）"><a href="#感觉基因太多，可以截取部分（比如前30）" class="headerlink" title="感觉基因太多，可以截取部分（比如前30）"></a>感觉基因太多，可以截取部分（比如前30）</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">nTop = 30IMConn = softConnectivity(datExpr[, modProbes])top = (rank(-IMConn) <= nTop)submodTOM <- modTOM[top, top] #然后用submodTOM代替前面的modTOM导出<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="导出到Cytoscape"><a href="#导出到Cytoscape" class="headerlink" title="导出到Cytoscape"></a>导出到Cytoscape</h3><pre class="line-numbers language-&#123;r&#125;"><code class="language-&#123;r&#125;">modules = c("brown", "red")cyt = exportNetworkToCytoscape(modTOM,                               edgeFile = paste("CytoscapeInput-edges-", paste(modules, collapse="-"), ".txt", sep=""),                               nodeFile = paste("CytoscapeInput-nodes-", paste(modules, collapse="-"), ".txt", sep=""),                               weighted = TRUE,                               threshold = 0.02,                               nodeNames = modProbes,                               nodeAttr = moduleColors[inModule])# 同理，感觉基因太多可以用submodTOM代替modTOM<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>绘图素材|信号通路绘制工具</title>
      <link href="/2020-05-09-hui-tu-su-cai-xin-hao-tong-lu-hui-zhi-gong-ju/"/>
      <url>/2020-05-09-hui-tu-su-cai-xin-hao-tong-lu-hui-zhi-gong-ju/</url>
      
        <content type="html"><![CDATA[<font face="times new roman" size=4><p><strong>绘图素材|信号通路绘制工具</strong></p><span id="more"></span><!-- toc --><hr><p>我们通常可以在CNS这类顶级杂志上看到的通路图都是既有内容还有逼格！今天推荐的3个信号通路绘制工具，一张高质量的信号通路图放到基金申请书&#x2F;课题&#x2F;项目答辩里面，都瞬间提高几个档次！</p><h1 id="IBS（Illustrator-for-Biological-Sequences）"><a href="#IBS（Illustrator-for-Biological-Sequences）" class="headerlink" title="IBS（Illustrator for Biological Sequences）"></a>IBS（Illustrator for Biological Sequences）</h1><p><strong>IBS（Illustrator for Biological Sequences）</strong> 是一个专业的基因及蛋白序列图绘制软件，既可以画蛋白质序列，也可以画可视化核酸序列，同时还拥有多种模板与推荐配色。该软件的制作团队为华中科技大学薛宇教授的团队。</p><p>先看两张用IBS画出来的图，感受一下高级感。<br><img src="http://ibs.biocuckoo.org/demo/images/1.jpg" alt="IBS"></p><p><img src="http://ibs.biocuckoo.org/demo/images/21.jpg" alt="IBS"></p><h2 id="IBS安装包"><a href="#IBS安装包" class="headerlink" title="IBS安装包"></a>IBS安装包</h2><h3 id="IBS电脑桌面版"><a href="#IBS电脑桌面版" class="headerlink" title="IBS电脑桌面版"></a>IBS电脑桌面版</h3><p><a href="http://ibs.biocuckoo.org/download/IBS_1.0.3_windows_20170614.exe">IBS windows platform</a><br>包含有35个蛋白样品图和27个核酸样品图</p><h3 id="IBS网页在线版"><a href="#IBS网页在线版" class="headerlink" title="IBS网页在线版"></a>IBS网页在线版</h3><p>网址：<a href="http://ibs.biocuckoo.org/download.php">http://ibs.biocuckoo.org/download.php</a><br>在线版只有20个蛋白样品图和20个核酸样品图。</p><h2 id="详细用法"><a href="#详细用法" class="headerlink" title="详细用法"></a>详细用法</h2><p>参考：<a href="https://mp.weixin.qq.com/s?__biz=MzUxODM4NjUyOQ==&amp;mid=2247490025&amp;idx=2&amp;sn=edfd09fb046604cb177fb5e82cb82710&amp;chksm=f988ffe7ceff76f1b69e3cffbe2b2727155cee5a7d754841fba779a84f752af59394cae70e75&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzUxODM4NjUyOQ==&amp;mid=2247490025&amp;idx=2&amp;sn=edfd09fb046604cb177fb5e82cb82710&amp;chksm=f988ffe7ceff76f1b69e3cffbe2b2727155cee5a7d754841fba779a84f752af59394cae70e75&amp;scene=21#wechat_redirect</a></p><h1 id="ScienceSlides"><a href="#ScienceSlides" class="headerlink" title="ScienceSlides"></a>ScienceSlides</h1><p>ScienceSlides是一款专门为制作生物医学领域 PPT 所开发的插件，包含大量PPT绘制的生物学、药学和医学相关矢量图像素材，集成了包括信号通路、细胞结构、组织结构、生物化学、分子生物学等几千种素材（其实它就是一个嵌在ppt内的素材库），打开素材即可直接进行修改处理，非常简单易上手，用它做出CNS级的论文配图不是问题！</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>RNA-Seq分析|MicroRazerS-small RNA-seq map</title>
      <link href="/2020-05-05-rna-seq-fen-xi-microrazers-small-rna-seq-map/"/>
      <url>/2020-05-05-rna-seq-fen-xi-microrazers-small-rna-seq-map/</url>
      
        <content type="html"><![CDATA[<font face="times new roman" size=4><p><strong>MicroRazerS - Rapid Alignment of Small RNA-seq Reads</strong></p><span id="more"></span><!-- toc --><hr><img src="/2020-05-05-rna-seq-fen-xi-microrazers-small-rna-seq-map/1.png" class=""><hr><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title=" 1. Overview"></a><font color=BlueViolet> 1. Overview</font></h1><p><a href="http://www.seqan.de/projects/microRazers.html"><strong>MicroRazerS</strong></a> is a tool for mapping millions of short reads obtained from small<br>RNA sequencing onto a reference genome. MicroRazerS searches for the longest<br>perfect prefix match of each read where the minimum prefix match length (the<br>seed length) can currently be varied between 14 and 22. Optionally, one<br>mismatch can be tolerated in the seed. MicroRazerS guarantees to find all<br>matches and reports a configurable maximum number of equally-best matches.<br>Perfect matches are given preference over matches containing mismatches, even<br>if this means mapping a shorter prefix.<br>Similar to RazerS, MicroRazerS uses a k-mer index of all reads and counts<br>common k-mers of reads and the reference genome in parallelograms. In<br>MicroRazerS, this index is built over the first seedlength many bases of each<br>read only. Each parallelogram with a k-mer count above a certain threshold<br>triggers a verification. On success, the genomic subsequence and the read<br>number are stored and later written to the output file.</p><h1 id="2-Installation"><a href="#2-Installation" class="headerlink" title=" 2. Installation"></a><font color=BlueViolet> 2. Installation</font></h1><p><strong>MicroRazerS</strong> is distributed with <a href="http://www.seqan.de/">SeqAn - The C++ Sequence Analysis Library</a>. To build <strong>MicroRazerS</strong> do the following:</p><ol><li>Download the latest snapshot of SeqAn</li><li>Unzip it to a directory of your choice (e.g. snapshot)</li><li>cd snapshot&#x2F;apps</li><li>make micro_razers</li><li>cd micro_razers</li><li>.&#x2F;micro_razers –help</li></ol><p>Alternatively you can check out the latest <code>Git</code> version of <strong>MicroRazerS</strong> and <strong>SeqAn</strong><br>with:</p><ol><li>git clone <a href="https://github.com/seqan/seqan.git">https://github.com/seqan/seqan.git</a></li><li>mkdir seqan&#x2F;buld; cd seqan&#x2F;build</li><li>cmake .. -DCMAKE_BUILD_TYPE&#x3D;Release</li><li>make micro_razers</li><li>.&#x2F;bin&#x2F;micro_razers –help</li></ol><p>On success, an executable file micro_razers was built and a brief usage<br>description was dumped.</p><h1 id="3-Usage"><a href="#3-Usage" class="headerlink" title=" 3. Usage"></a><font color=BlueViolet> 3. Usage</font></h1><p>To get a short usage description of MicroRazerS, you can execute <code>micro_razers -h</code> or<br><code>micro_razers --help</code>.</p><p><strong>Usage</strong>: micro_razers [OPTION]… <GENOME FILE> <READS FILE></p><p>MicroRazerS expects the names of two DNA (multi-)Fasta files. The first contains<br>a reference genome and the second contains the reads that should be<br>mapped against the reference. Without any additional parameters MicroRazerS<br>would map all reads against both strands of the reference genome requiring a perfect<br>prefix seed match of length &gt;&#x3D; 16. The up tp 100 equally best (longest) matches<br>would then be dumped in the default output file, the read file name extended by the<br>suffix <font color=Blue><code>.result</code></font>.</p><p>The default behaviour can be modified by adding the following options to<br>the command line:</p><h2 id="3-1-Main-Options"><a href="#3-1-Main-Options" class="headerlink" title="  3.1. Main Options"></a><font color=BlueViolet>  3.1. Main Options</font></h2><p>  [ -sL NUM ],  [ –seed-length NUM ]</p><p>  Seed length parameter. Minimum length of prefix match.</p><p>  [ -sE ],  [ –seed-error ]</p><p>  Allow for one mismatch in the prefix seed.</p><p>  [ -f ],  [ –forward ]</p><p>  Only map reads against the positive&#x2F;forward strand of the genome. By<br>  default, both strands are scanned.</p><p>  [ -r ],  [ –reverse ]</p><p>  Only map reads against the negative&#x2F;reverse-complement strand of the<br>  genome. By default, both strands are scanned.</p><p>  [ -m NUM ],  [ –max-hits NUM ]</p><p>  Output at most NUM of the best matches.</p><p>  [ -o FILE ],  [ –output FILE ]</p><p>  Change the output filename to FILE. By default, this is the read file<br>  name extended by the suffix “.result”.</p><p>  [ -mN ],  [ –match-N ]</p><p>  By default, ‘N’ characters in read or genome sequences equal to nothing,<br>  not even to another ‘N’. They are considered as errors. By activating this<br>  option, ‘N’ equals to every other character and produces no mismatch in<br>  the verification process. The filtration is not affected by this option.</p><p>  [ -pa ],  [ –purge-ambiguous ]</p><p>  Omit reads with more than #max-hits many equally-best matches.</p><p>  [ -v ],  [ –verbose ]</p><p>  Verbose. Print extra information and running times.</p><p>  [ -vv ],  [ –vverbose ]</p><p>  Very verbose. Like -v, but also print filtering statistics like true and<br>  false positives (TP&#x2F;FP).</p><p>  [ -V ],  [ –version ]</p><p>  Print version information.</p><p>  [ -h ],  [ –help ]</p><p>  Print a brief usage summary.</p><h2 id="3-2-Output-Format-Options"><a href="#3-2-Output-Format-Options" class="headerlink" title=" 3.2. Output Format Options"></a><font color=BlueViolet> 3.2. Output Format Options</font></h2><p>  [ -of NUM ],  [ –outputFormat ]</p><p>  Specify the desired output format:<br>  NUM &#x3D; 0   &#x3D;&gt; MicroRazerS default format<br>  NUM &#x3D; 1   &#x3D;&gt; SAM format</p><p>  [ -a ],  [ –alignment ]</p><p>  Dump the alignment for each match in the “.result” file, only possible for<br>  -of 0, i.e. MicroRazerS default output format. The alignment is written<br>  directly after the match and has the following format:<br>  #Read:   CAGGAGATAAGCTGGATCTTT<br>  #Genome: CAGGAGATAAGCTGGATCTTT</p><p>  [ -gn NUM ],  [ –genome-naming NUM ]</p><p>  Select how genomes are named in the output file. If NUM is 0, the Fasta<br>  ids of the genome sequences are used (default). If NUM is 1, the genome<br>  sequences are enumerated beginning with 1.</p><p>  [ -rn NUM ],  [ –read-naming NUM ]</p><p>  Select how reads are named in the output file. If NUM is 0, the Fasta ids<br>  of the reads are used (default). If NUM is 1, the reads are enumerated<br>  beginning with 1. If NUM is 2, the read sequence itself is used.</p><p>  [ -so NUM ],  [ –sort-order NUM ]</p><p>  Select how matches are ordered in the output file.<br>  If NUM is 0, matches are sorted primarily by the read number and<br>  secondarily by their position in the genome sequence (default).<br>  If NUM is 1, matches are sorted primarily by their position in the genome<br>  sequence and secondarily by the read number.</p><p>  [ -pf NUM ],  [ –position-format NUM ]</p><p>  Select how positions are stored in the output file (only relevant for<br>  MicroRazerS default output format, i.e. -of 0).<br>  If NUM is 0, the gap space is used, i.e. gaps around characters are<br>  enumerated beginning with 0 and the beginning and end position is the<br>  postion of the gap before and after a match (default).<br>  If NUM is 1, the position space is used, i.e. characters are enumerated<br>  beginning with 1 and the beginning and end position is the postion of the<br>  first and last character involved in a match.</p><p>  Example: Consider the string CONCAT. The beginning and end positions<br>  of the substring CAT are (3,6) in gap space and (4,6) in position space.</p><h1 id="4-Output-Format"><a href="#4-Output-Format" class="headerlink" title=" 4. Output Format"></a><font color=BlueViolet> 4. Output Format</font></h1><h2 id="4-1-Default-Output-Format"><a href="#4-1-Default-Output-Format" class="headerlink" title=" 4.1. Default Output Format"></a><font color=BlueViolet> 4.1. Default Output Format</font></h2><p>The default output file is a text file whose lines represent matches. A line<br>consists of different tab-separated match values. In the following format:</p><p>RName 0 RLength GStrand GName GBegin GEnd PercID MatchLen</p><p>Match value description:</p><p>  RName        Name of the read sequence (see –read-naming)<br>  RLength      Length of the read<br>  GStrand      ‘F’&#x3D;forward strand or ‘R’&#x3D;reverse strand<br>  GName        Name of the genome sequence (see –genome-naming)<br>  GBegin       Beginning position in the genome sequence<br>  GEnd         End position in the genome sequence<br>  PercID       Percent sequence identity within matched prefix<br>  MatchLen     Length of prefix match</p><p>For matches on the reverse strand, GBegin and GEnd are positions on the<br>related forward strand.</p><h2 id="4-2-SAM-Output-Format"><a href="#4-2-SAM-Output-Format" class="headerlink" title=" 4.2. SAM Output Format"></a><font color=BlueViolet> 4.2. SAM Output Format</font></h2><p>If -of 1 is specified, the resulting matches will be written out in SAM<br>format. For a full specification of the SAM format please see<br><a href="http://samtools.sourceforge.net/">http://samtools.sourceforge.net</a>.</p><p>MicroRazerS assigns each read with multiple best matches a mapping quality<br>of “0”. If only one best match was found, it will receive a “255” in the<br>mapping quality column. Column 12 informs about the sequence identity in<br>the matched part of the read, e.g. AS:i:100 means that the read match has<br>100% sequence identity, i.e. does not contain any mismatches. Unmapped<br>read suffixes will be given as soft-clipped sequence in the Cigar string.<br>For example, a 30bp read with a 22bp prefix match will have the Cigar string<br>“22M8S”, or “8S22M” if it matches the reverse strand.</p><h2 id="5-Example"><a href="#5-Example" class="headerlink" title="5. Example"></a><font color=BlueViolet>5. Example</font></h2><pre><code>micro_razers -m 20 -pa -sL 18</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>sRNAnalyzer</title>
      <link href="/2020-05-02-srnanalyzer/"/>
      <url>/2020-05-02-srnanalyzer/</url>
      
        <content type="html"><![CDATA[<p>sRNAnalyzer–A pipeline for small RNA sequencing data analysis</p><span id="more"></span><!-- toc --><hr><font face="黑体" color=darkgreen size=2><h1 id="Getting-Started-with-sRNAnalyzer"><a href="#Getting-Started-with-sRNAnalyzer" class="headerlink" title="Getting Started with sRNAnalyzer"></a>Getting Started with <a href="http://srnanalyzer.systemsbiology.net/start.html">sRNAnalyzer</a></h1></font><font face="黑体" color=darkgreen size=4></font><img src="/2020-05-02-srnanalyzer/1.png" class=""><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>sRNAnalyzer is a flexible, modular pipeline for the analysis of small RNA sequencing data. Features include,</p><ol><li>Additional adapter trimming process to generate cleaner data</li><li>Comprehensive microRNA profiling strategies to better handle isomiR issues</li><li>Summarization for each nucleotide to detect potential SNPs on miRNAs</li><li>Multiple assignment to simulate miRNA array and qRT-PCR platforms</li><li>A local probabilistic model to map reads to the most-likely entry IDs</li><li>Comprehensive ribosomal RNA filtering to get more accurate mapping results</li><li>More specific species assignment on exogenous RNAs in circulation</li><li>Taxonomy annotation&#x2F;summarization at major ranks for exogenous species</li></ol><h1 id="Downloads"><a href="#Downloads" class="headerlink" title="Downloads"></a>Downloads</h1><p>Download the sRNAnalyzer pipeline and alignment databases as .tar.gz files.</p><ul><li>sRNAnalyzer Pipeline: <a href="http://srnanalyzer.systemsbiology.net/downloads/sRNAnalyzer.tar.gz">sRNAnalyzer</a>   </li><li>small RNA Databases: <a href="http://srnanalyzer.systemsbiology.net/downloads/sRNA_DBs.tar.gz">sRNA_DBs</a>   </li><li>Human and Exogenous Databases: <a href="http://srnanalyzer.systemsbiology.net/downloads/MainDBs.tar.gz">MainDBs</a>   </li><li>NCBI Non-Human Databases: <a href="http://srnanalyzer.systemsbiology.net/downloads/NCBI_NonHuman.tar.gz">NCBI_NonHuman</a></li><li>E.Coli Samples for Pipeline Evaluation: <a href="http://srnanalyzer.systemsbiology.net/downloads/E_coli_evaluation_samples.tar.gz">E_coli_evaluation_samples</a></li></ul><h1 id="Web-Application"><a href="#Web-Application" class="headerlink" title="Web Application"></a>Web Application</h1><p>To demonstrate how to use sRNAnalyzer, we built a web interface in a local server, which can be accessed at <a href="http://srnanalyzer.systemsbiology.net/webapp.html">Web Application</a> page for uploading data and running sRNAnalyzer pipeline online. For testing purpose, Username – ‘isb’ and Password – ‘password’ can be used. For academic use, free accounts will be provided based on email applications. Please send emails to <a href="https://www.systemsbiology.org/bio/kai-wang-phd/">Dr. Kai Wang</a>.</p><h1 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h1><p>To get started using sRNAnalyzer, download the sRNAnalyzer as a .zip or a .tar.gz file as well as the sRNA databases required. Then head to the <a href="http://srnanalyzer.systemsbiology.net/start.html">Getting Started</a> page for instruction on setting up and running sRNAnalyzer.</p><h1 id="Documentation"><a href="#Documentation" class="headerlink" title="Documentation"></a>Documentation</h1><p>For more information on options and configuration, head to the <a href="http://srnanalyzer.systemsbiology.net/docs.html">Documentation</a>. For documentation on the format of the output and summary files, go to the <a href="http://srnanalyzer.systemsbiology.net/summary_docs.html">Output file documentation</a>.</p><p><strong>1. Download and Install Dependencies</strong><br></font></p><ul><li><p><strong>Make sure you have <code>python 2.6</code> or later and <code>perl 5</code> or later installed.</strong></p></li><li><p><strong>Download and install <a href="http://bowtie-bio.sourceforge.net/index.shtml">bowtie</a></strong>. Make sure the bowtie command is in your system path. Note: bowtie 2 is not supported in sRNAnalyzer.</p></li><li><p><strong>Download and install the <a href="http://hannonlab.cshl.edu/fastx_toolkit/download.html">fastx_toolkit</a></strong>, following the instructions on the website. <strong>Download the fastx 0.0.14 version</strong>. Make sure the command <code>fastx_collapser</code> is in your system path.</p></li><li><p><strong>Download and install <a href="https://cutadapt.readthedocs.io/en/stable/installation.html">cutadapt</a></strong>. This requires python 2.6 or later and a C compiler. The easiest way to install cutadapt is using pip following the instructions on the cutadapt website. Make sure the cutadapt command is in your system path.</p><font face="黑体" color=darkgreen size=4></li></ul><p><strong>2. Download and Setup sRNAnalyzer</strong><br></font></p><ul><li><strong>Download sRNAnalyzer</strong>. Unzip the downloaded archive. You may want to add the sRNAnalzyer directory to your system <code>PATH</code> so you can use the sRNAnalyzer commands directly. Next, we need to download some databases for alignment. There are three options for databases to download: a small RNA database, a database with human DNA and RNA, as well as some bacterial sequences, and the NCBI non-human database. The latter two databases are quite large (&gt; 70GB uncompressed), so it is recommended to begin with the sRNA database. The installation procedure for all three databases is the same. First, download one of the databases and unzip the archive. Open the DB_config file and change the line</li></ul><pre><code>base: Insert the path to this folder here</code></pre><p>by inserting the full path to the folder. For example,</p><pre><code>base: /databases/bowtie/indexes/sRNA_DBs</code></pre><p>Looking at the DB_config, you should see a list of database names with paths. These databases are the ones that you can use in your pipeline now. It is also possible to add many new databases to the pipeline by downloading or building bowtie indexes and specifying their location in the database configuration file. For more information, see the <a href="http://srnanalyzer.systemsbiology.net/docs.html">Configuration File Documentation</a> Now you’re ready to begin using the pipeline.</p><font face="黑体" color=darkgreen size=4><p><strong>3. Using the Pipeline</strong><br></font></p><p>In order to use the pipeline, we need to create a pipeline configuration file, which specifies preprocessing setting, such as adapter sequences, and alignment settings such as database order and maximum mismatch allowances. Go to the <a href="http://srnanalyzer.systemsbiology.net/docs.html">Config Docs</a> to learn how to create a configuration file with the settings required for your project.</p><p>An typical pipeline configuration file is shown below,</p><pre><code>preprocess:  kit:        NEB  gzip:       true  stop-oligo: false        alignment:  type: single  human_miRNA:     2  human_miRNA_sub: 2  human_piRNA:     2  human_snoRNA:    2</code></pre><p><strong>3.1 Preprocessing</strong></p><p>Using a terminal, change the directory so that the fastq or fast.gz files you wish to process are in the current working directory. In order to run preprocessing, run the command</p><pre><code>/Downloads/sRNAnalyzer/preprocess.pl --config pipeline_config.conf</code></pre><p>where pipeline_config.yaml is your pipeline configuration file, and &#x2F;Downloads&#x2F; is replaced with wherever your sRNAnalyzer folder is located. Or if you have added the sRNAnalyzer directory to the system PATH, then simply use</p><pre><code>preprocess.pl --config pipeline_config.conf</code></pre><p>The preprocessing will generated sample_Processed.fa files that have had adapter trimmed, low-quality reads filtered out, and collapsed. Additional report files are also generated with information about adapter trimming and read quality.</p><p><strong>3.2 Alignment</strong></p><p>To perform the alignment, ensure that your database and pipeline configuration files are properly setup. After downloading the initial human small RNA databases, the databases available for alignment, which can be specified in the pipeline configuration file are,</p><pre><code>human_miRNAhuman_miRNA_subhuman_piRNAhuman_snoRNAvirus_miRNAplant_miRNAall_miRNAall_miRNA_sub</code></pre><p>Then, making sure that you are in the directory containing the _Processed.fa files you wish to align, run the command</p><pre><code>/Downloads/sRNAnalyzer/align.pl /home/data pipeline_config.yaml DB_config.conf</code></pre><p>or</p><pre><code>align.pl /home/data pipeline_config.yaml DB_config.conf</code></pre><p>if you have added sRNAnalyzer to the system <code>PATH</code></p><p>In the command, <code>pipeline_config.yaml</code> is the pipeline configuration file and DB_config.conf is the database configuration file.</p><p>The align command will output several files, including feature files, profile files, a read distribution file, and an unmatched sequences file.</p><p><strong>3.3 Summarization</strong><br>The next step in the pipeline is the summarization of the results of the alignment in order to prepare for statistical analysis of the data. An example summarization command is,</p><pre><code>summarize.pl DB_config.conf --project my_project</code></pre><p>This command will sum the feature and profile result from individual samples into result files for all samples. my_project is the name of the project, so all of the result files with start with the prefix my_project_. The general form of the summarize command is,</p><pre><code>summarize.pl &lt;db-config-file&gt; &lt;sample-order-file&gt; --project &lt;project-name&gt;</code></pre><p>where the db-config-file is required, and the sample-order-file and project-name are both optional. The <code>db-config-file</code> is the database configuration file discussed above, and the <code>sample-order-file</code> specifies the order of the samples in the result files. If the sample order file is not provided, the order is alphabetical. The <code>summarize.pl</code> command has two additional options, <code>--miRNA</code> and <code>--exogenous</code>. Use the –miRNA flag if you would like to summarize miRNA separately and get information about possible miRNA SNPs. Use the <code>--exogenous</code> flag if you would like to summarize exogenous reads, including summarizing by taxonomy information. Note that the <code>--exogenous</code> option is only available if the MainDBs or NCBI_NonHuman databases are installed.</p>]]></content>
      
      
      <categories>
          
          <category> RNA-seq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> small RNA-seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Aspera高速下载SRA数据</title>
      <link href="/2020-04-21-shi-yong-aspera-gao-su-xia-zai-sra-shu-ju/"/>
      <url>/2020-04-21-shi-yong-aspera-gao-su-xia-zai-sra-shu-ju/</url>
      
        <content type="html"><![CDATA[<p>使用Aspera高速下载SRA数据</p><span id="more"></span><!-- toc --><hr><font face="黑体" color=black size=4><font face="黑体" color=white size=5><table><tr><td bgcolor=DeepSkyBlue># 下载安装文件</td></tr></table></font><p>首先到<a href="https://www.ibm.com/products/aspera">官网</a>选择对应系统版本，并下载</p><pre><code>wget https://ak-delivery04-mul.dhe.ibm.com/sar/CMA/OSA/08sq3/0/ibm-aspera-connect-3.9.9.177872-linux-g2.12-64.tar.gztar -zxvf ibm-aspera-connect-3.9.9.177872-linux-g2.12-64.tar.gz</code></pre><p>解压之后，得到一个脚本，运行之</p><p><code>sh aspera-connect-3.6.2.117442-linux-64.sh</code></p><p>运行完了之后，整个安装过程就完成了，其会在<code>~</code>目录下生成<code>.aspera</code>目录，其所有文件均在这个文件夹下。<br><font face="黑体" color=white size=5></p><table><tr><td bgcolor=DeepSkyBlue># 准备工作</td></tr></table></font>为了方便使用，我们需要进行一些准备工作，首先，需要将脚本位置加入环境变量以方便使用（不加入环境变量也可以，每次拷贝```~/.aspera/connect/bin/ascp```文件到需要下载的目录）<p><code>sudo vim /etc/profile</code> </p><p>在文件的末尾加入</p><p><code>export PATH=&quot;/home/andy/.aspera/connect/bin:$PATH&quot;</code></p><p>注意替换你的用户名，保存之后为了使其生效<code>source /etc/profile</code></p><p>然后，我们需要拷贝密匙文件，以方便我们使用</p><p><code>cp ~/.aspera/connect/etc/asperaweb_id_dsa.openssh ~/</code></p><p>最后拷贝一个协议文件</p><p><code>sudo cp ~/.aspera/connect/etc/aspera-license /usr/local/bin/</code></p><p><strong>至此，准备工作完成</strong><br><font face="黑体" color=white size=5></p><table><tr><td bgcolor=DeepSkyBlue># 使用方法</td></tr></table></font>一般在NCBI中下载数据，我们能够得到类似的链接<p><a href="ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByExp/sra/SRX/SRX189/SRX189773/SRR576933/SRR576933.sra">ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByExp/sra/SRX/SRX189/SRX189773/SRR576933/SRR576933.sra</a></p><p>在使用Aspera下载时，我们需要去除前面的域名，使用如下命令下载:</p><p><code>ascp -i ~/asperaweb_id_dsa.openssh anonftp@ftp-private.ncbi.nlm.nih.gov:/sra/sra-instant-reads/ByExp/sra/SRX/SRX189/SRX189773/SRR576933/SRR576933.sra .</code></p><p>一定要注意最后的.，表示下载到当前目录！-i指向我们刚刚复制的密匙文件！</p><p>同理，在EBI中下载，我们得到如下的下载链接:</p><p><a href="ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR576/SRR576933/SRR576933.fastq.gz">ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR576/SRR576933/SRR576933.fastq.gz</a></p><p>同样去除其域名，使用如下的命令下载:</p><pre><code>ascp -i ~/asperaweb_id_dsa.openssh era-fasp@fasp.sra.ebi.ac.uk:/vol1/fastq/SRR576/SRR576933/SRR576933.fastq.gz .或者：ascp -v -i ~/.aspera/connect/etc/asperaweb_id_dsa.openssh -k 1 -T -l200m anonftp@ftp-private.ncbi.nlm.nih.gov:/sra/sra instant/reads/ByRun/sra/SRR/SRR949/SRR949627/SRR949627.sra .# 如果报ascp: Source file list not specified, exiting，看下最后那个点是否加了，有空格···注意：最后那个.一定要有，表示下载后的路径，我的速度大概5M/s，比起wget和prefetch已经是在奔跑了。可能的报错：ascp: Failed to open TCP connection for SSH, exiting.Session Stop  (Error: Failed to open TCP connection for SSH)On many Linux systems the default firewall can be configured with iptables. You will have to allow all incoming and outgoing traffic on UDP port 33001 (or whatever your Aspera UDP port is), which you can do with the following commands:# iptables -I INPUT -p tcp --dport 33001 -j ACCEPT# iptables -I OUTPUT -p tcp --dport 33001 -j ACCEPT</code></pre><p>其次，还可以使用批量下载方法，首先我们需要创建一个记录了下载链接的文件file-list,其内容如下:</p><pre><code>/vol1/fastq/SRR576/SRR576933/SRR576933.fastq.gz/vol1/fastq/SRR576/SRR576934/SRR576934.fastq.gz</code></pre><p>然后使用命令:</p><pre><code>ascp -QT -k1 -l 100M -i ~/asperaweb_id_dsa.openssh --mode recv --host fasp.sra.ebi.ac.uk --user era-fasp --file-list file-list</code></pre><p>这其中，还有<code>-QT</code>参数，表示开启断点续传，-l带宽限制，启用该设置能够再次加快速度，从原来的10M&#x2F;s到达20+M&#x2F;s。</p></font>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>代码分析 | Sing-cell Sequencing QC详解</title>
      <link href="/2020-04-20-dai-ma-fen-xi-sing-cell-sequencing-qc-xiang-jie/"/>
      <url>/2020-04-20-dai-ma-fen-xi-sing-cell-sequencing-qc-xiang-jie/</url>
      
        <content type="html"><![CDATA[<p>代码分析 | Sing-cell Sequencing QC详解</p><span id="more"></span><!-- toc --><hr><font face="黑体" color=black size=4><p>最近找到了芬兰CSC-IT科学中心主讲的生物信息课程(<a href="https://www.csc.fi/web/training/-/scrnaseq)%EF%BC%8C">https://www.csc.fi/web/training/-/scrnaseq)，</a><br>官网上还提供了练习素材以及详细代码，今天就来练习一下单细胞数据QC的过程：</p><p>第一部分是使用Seurat（<a href="https://satijalab.org/seurat/%EF%BC%89%E6%9D%A5%E5%AF%B9QC%E8%BF%9B%E8%A1%8C%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B9%B6%E8%BF%9B%E8%A1%8C%E7%BB%86%E8%83%9E%E8%BF%87%E6%BB%A4%EF%BC%9B">https://satijalab.org/seurat/）来对QC进行可视化并进行细胞过滤；</a><br>第二部分将详细探讨scater软件包（<a href="https://bioconductor.org/packages/release/bioc/html/scater.html%EF%BC%89%E3%80%82">https://bioconductor.org/packages/release/bioc/html/scater.html）。</a></p><font face="黑体" color=darkgreen size=3><h1 id="加载环境"><a href="#加载环境" class="headerlink" title="加载环境"></a>加载环境</h1></font><p>如果需要加载conda环境（软件安装不上，可能是网速慢！Conda&#x2F;R&#x2F;pip&#x2F;brew等国内镜像大全拿走不谢~~），请在运行以下代码之前遵循以下说明：<br><a href="https://nbisweden.github.io/excelerate-scRNAseq/computing_environment_instructions.html%E3%80%82">https://nbisweden.github.io/excelerate-scRNAseq/computing_environment_instructions.html。</a></p><font face="黑体" color=darkgreen size=3><h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1></font><p>在本教程中，我们将使用10x Genomics网站上的3个不同的PBMC数据集:<br><a href="https://support.10xgenomics.com/single-cell-gene-expression/datasets">https://support.10xgenomics.com/single-cell-gene-expression/datasets</a></p><p>包括：</p><ul><li>1k PBMCs using 10x v2 chemistry</li><li>1k PBMCs using 10x v3 chemistry</li><li>1k PBMCs using 10x v3 chemistry in combination with cell surface proteins, but disregarding the protein data and only looking at gene expression.</li></ul><p>我们可以通过以下命令进行下载：</p><pre><code>mkdir data  #建立data文件夹cd datacurl -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5curl -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v3/pbmc_1k_v3_filtered_feature_bc_matrix.h5curl -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_10k_v3/pbmc_10k_v3_filtered_feature_bc_matrix.h5</code></pre><font face="黑体" color=darkgreen size=3><h1 id="加载R包"><a href="#加载R包" class="headerlink" title="加载R包"></a>加载R包</h1></font><p>suppressMessages(require(Seurat))<br>suppressMessages(require(scater))<br>suppressMessages(require(Matrix))<br>读入数据<br>v3.1k &lt;- Read10X_h5(“<del>&#x2F;scrna-seq2019&#x2F;day1&#x2F;1-qc&#x2F;pbmc_1k_v3_filtered_feature_bc_matrix.h5”, use.names &#x3D; T)<br>v2.1k &lt;- Read10X_h5(“</del>&#x2F;scrna-seq2019&#x2F;day1&#x2F;1-qc&#x2F;pbmc_1k_v2_filtered_feature_bc_matrix.h5”, use.names &#x3D; T)<br>p3.1k &lt;- Read10X_h5(“~&#x2F;scrna-seq2019&#x2F;day1&#x2F;1-qc&#x2F;pbmc_1k_protein_v3_filtered_feature_bc_matrix.h5”, use.names &#x3D; T)</p><h1 id="CITE-seq-data中只提取基因表达矩阵"><a href="#CITE-seq-data中只提取基因表达矩阵" class="headerlink" title="CITE-seq data中只提取基因表达矩阵"></a>CITE-seq data中只提取基因表达矩阵</h1><p>p3.1k &lt;- p3.1k$<code>Gene Expression</code><br>Hemberg-lab单细胞转录组数据分析（七）- 导入10X和SmartSeq2数据Tabula Muris。<br>Seurat<br>构建Seurat对象</p><p>首先，为每个数据集创建Seurat对象，然后合并为一个大的seurat对象。</p><p>sdata.v2.1k &lt;- CreateSeuratObject(v2.1k, project &#x3D; “v2.1k”)<br>sdata.v3.1k &lt;- CreateSeuratObject(v3.1k, project &#x3D; “v3.1k”)<br>sdata.p3.1k &lt;- CreateSeuratObject(p3.1k, project &#x3D; “p3.1k”)</p><h1 id="使用merge函数合并为一个seurat-object-为了防止数据集之间的barcodes重叠，给细胞添加ID。"><a href="#使用merge函数合并为一个seurat-object-为了防止数据集之间的barcodes重叠，给细胞添加ID。" class="headerlink" title="使用merge函数合并为一个seurat object. 为了防止数据集之间的barcodes重叠，给细胞添加ID。"></a>使用merge函数合并为一个seurat object. 为了防止数据集之间的barcodes重叠，给细胞添加ID。</h1><p>alldata &lt;- merge(sdata.v2.1k, c(sdata.v3.1k,sdata.p3.1k), add.cell.ids&#x3D;c(“v2.1k”,”v3.1k”,”p3.1k”))</p><h1 id="在metadata中添加v2和v3标识。"><a href="#在metadata中添加v2和v3标识。" class="headerlink" title="在metadata中添加v2和v3标识。"></a>在metadata中添加v2和v3标识。</h1><p>chemistry &lt;- rep(“v3”,ncol(alldata))<br>chemistry[Idents(alldata) &#x3D;&#x3D; “v2.1k”] &lt;- “v2”<br>alldata &lt;- AddMetaData(alldata, chemistry, col.name &#x3D; “Chemistry”)<br>alldata</p><h2 id="An-object-of-class-Seurat"><a href="#An-object-of-class-Seurat" class="headerlink" title="An object of class Seurat"></a>An object of class Seurat</h2><h2 id="33538-features-across-2931-samples-within-1-assay"><a href="#33538-features-across-2931-samples-within-1-assay" class="headerlink" title="33538 features across 2931 samples within 1 assay"></a>33538 features across 2931 samples within 1 assay</h2><h2 id="Active-assay-RNA-33538-features"><a href="#Active-assay-RNA-33538-features" class="headerlink" title="Active assay: RNA (33538 features)"></a>Active assay: RNA (33538 features)</h2><h1 id="检查每个样本的细胞数量，将其存储在metadata的orig-ident中，并自动设置为active-ident。"><a href="#检查每个样本的细胞数量，将其存储在metadata的orig-ident中，并自动设置为active-ident。" class="headerlink" title="检查每个样本的细胞数量，将其存储在metadata的orig.ident中，并自动设置为active ident。"></a>检查每个样本的细胞数量，将其存储在metadata的orig.ident中，并自动设置为active ident。</h1><p>table(Idents(alldata))<br>##</p><h2 id="p3-1k-v2-1k-v3-1k"><a href="#p3-1k-v2-1k-v3-1k" class="headerlink" title="p3.1k v2.1k v3.1k"></a>p3.1k v2.1k v3.1k</h2><h2 id="713-996-1222"><a href="#713-996-1222" class="headerlink" title="713   996  1222"></a>713   996  1222</h2><p>计算线粒体比例</p><p>Seurat可以自动计算一些QC统计信息，例如每个细胞的UMI数量和基因数分别存储在metadata的nCount_RNA和nFeature_RNA列（Hemberg-lab单细胞转录组数据分析（六）- 构建表达矩阵，UMI介绍）。</p><p>head(<a href="mailto:&#x61;&#x6c;&#108;&#x64;&#x61;&#x74;&#97;&#64;&#109;&#x65;&#x74;&#97;&#46;&#100;&#97;&#x74;&#97;">&#x61;&#x6c;&#108;&#x64;&#x61;&#x74;&#97;&#64;&#109;&#x65;&#x74;&#97;&#46;&#100;&#97;&#x74;&#97;</a>)</p><h2 id="orig-ident-nCount-RNA-nFeature-RNA-Chemistry"><a href="#orig-ident-nCount-RNA-nFeature-RNA-Chemistry" class="headerlink" title="orig.ident nCount_RNA nFeature_RNA Chemistry"></a>orig.ident nCount_RNA nFeature_RNA Chemistry</h2><h2 id="v2-1k-AAACCTGAGCGCTCCA-1-v2-1k-6631-2029-v2"><a href="#v2-1k-AAACCTGAGCGCTCCA-1-v2-1k-6631-2029-v2" class="headerlink" title="v2.1k_AAACCTGAGCGCTCCA-1      v2.1k       6631         2029        v2"></a>v2.1k_AAACCTGAGCGCTCCA-1      v2.1k       6631         2029        v2</h2><h2 id="v2-1k-AAACCTGGTGATAAAC-1-v2-1k-2196-881-v2"><a href="#v2-1k-AAACCTGGTGATAAAC-1-v2-1k-2196-881-v2" class="headerlink" title="v2.1k_AAACCTGGTGATAAAC-1      v2.1k       2196          881        v2"></a>v2.1k_AAACCTGGTGATAAAC-1      v2.1k       2196          881        v2</h2><h2 id="v2-1k-AAACGGGGTTTGTGTG-1-v2-1k-2700-791-v2"><a href="#v2-1k-AAACGGGGTTTGTGTG-1-v2-1k-2700-791-v2" class="headerlink" title="v2.1k_AAACGGGGTTTGTGTG-1      v2.1k       2700          791        v2"></a>v2.1k_AAACGGGGTTTGTGTG-1      v2.1k       2700          791        v2</h2><h2 id="v2-1k-AAAGATGAGTACTTGC-1-v2-1k-3551-1183-v2"><a href="#v2-1k-AAAGATGAGTACTTGC-1-v2-1k-3551-1183-v2" class="headerlink" title="v2.1k_AAAGATGAGTACTTGC-1      v2.1k       3551         1183        v2"></a>v2.1k_AAAGATGAGTACTTGC-1      v2.1k       3551         1183        v2</h2><h2 id="v2-1k-AAAGCAAGTCTCTTAT-1-v2-1k-3080-1333-v2"><a href="#v2-1k-AAAGCAAGTCTCTTAT-1-v2-1k-3080-1333-v2" class="headerlink" title="v2.1k_AAAGCAAGTCTCTTAT-1      v2.1k       3080         1333        v2"></a>v2.1k_AAAGCAAGTCTCTTAT-1      v2.1k       3080         1333        v2</h2><h2 id="v2-1k-AAAGCAATCCACGAAT-1-v2-1k-5769-1556-v2"><a href="#v2-1k-AAAGCAATCCACGAAT-1-v2-1k-5769-1556-v2" class="headerlink" title="v2.1k_AAAGCAATCCACGAAT-1      v2.1k       5769         1556        v2"></a>v2.1k_AAAGCAATCCACGAAT-1      v2.1k       5769         1556        v2</h2><p>我们将手动计算线粒体reads的比例，并将其添加到metadata中。</p><p>mt.genes &lt;- rownames(alldata)[grep(“^MT-“,rownames(alldata))]<br>C&lt;-GetAssayData(object &#x3D; alldata, slot &#x3D; “counts”)</p><p>percent.mito &lt;- colSums(C[mt.genes,])&#x2F;Matrix::colSums(C)*100<br>alldata &lt;- AddMetaData(alldata, percent.mito, col.name &#x3D; “percent.mito”)<br>计算核糖体比例</p><p>我们用上面一样的方法来计算源自核糖体蛋白的基因表达比例。</p><p>rb.genes &lt;- rownames(alldata)[grep(“^RP[SL]”,rownames(alldata))]<br>percent.ribo &lt;- colSums(C[rb.genes,])&#x2F;Matrix::colSums(C)*100<br>alldata &lt;- AddMetaData(alldata, percent.ribo, col.name &#x3D; “percent.ribo”)<br>Plot QC</p><p>绘制小提琴图展示一些QC指标（feature）（可视化之为什么要使用箱线图？）：</p><p>VlnPlot(alldata, features &#x3D; “nFeature_RNA”, pt.size &#x3D; 0.1) + NoLegend()</p><p>VlnPlot(alldata, features &#x3D; “nCount_RNA”, pt.size &#x3D; 0.1) + NoLegend()</p><p>VlnPlot(alldata, features &#x3D; “percent.mito”, pt.size &#x3D; 0.1) + NoLegend()</p><p>VlnPlot(alldata, features &#x3D; “percent.ribo”, pt.size &#x3D; 0.1) + NoLegend()</p><p>如图所示，v2检测到的基因数较低，但检测出的核糖体蛋白比例却偏高。检测到较少的低表达基因是因为核糖体蛋白发生高表达，使得核糖体基因在转录景观中占较大比例。</p><p>QC方式不同时的散点图：</p><p>FeatureScatter(alldata, feature1 &#x3D; “nCount_RNA”, feature2 &#x3D; “nFeature_RNA”)</p><p>FeatureScatter(alldata, feature1 &#x3D; “nFeature_RNA”, feature2 &#x3D; “percent.mito”)</p><p>FeatureScatter(alldata, feature1&#x3D;”percent.ribo”, feature2&#x3D;”nFeature_RNA”)</p><p>我们还可以展示一个数据集：</p><p>FeatureScatter(alldata, feature1 &#x3D; “nCount_RNA”, feature2 &#x3D; “nFeature_RNA”, cells &#x3D; WhichCells(alldata, expression &#x3D; orig.ident &#x3D;&#x3D; “v3.1k”) )</p><p>过滤</p><p>线粒体过滤</p><p>线粒体reads比例高的细胞有很多，如果过滤掉它们后还剩下足够的细胞，那删除这些细胞可能是较为明智的。另一个选择是从数据集中删除所有线粒体reads，并希望剩余的基因仍然具有足够的生物学信号。第三种选择是在标准化过程中去除percent.mito变量。</p><p>在此次示例中，某些细胞中的线粒体reads比例高达99.7％，细胞信号很好的可能性不高，因此去除这些细胞。</p><p>可以通过展示的图决定合理的cutoff值。在这次例子中，大部分细胞的线粒体reads低于25％，可以将其用作临界值。</p><h1 id="选择线粒体基因百分比-lt-25-的细胞"><a href="#选择线粒体基因百分比-lt-25-的细胞" class="headerlink" title="选择线粒体基因百分比&lt;25%的细胞"></a>选择线粒体基因百分比&lt;25%的细胞</h1><p>selected &lt;- WhichCells(alldata, expression &#x3D; percent.mito &lt; 25)<br>length(selected)</p><h2 id="1-2703"><a href="#1-2703" class="headerlink" title="[1] 2703"></a>[1] 2703</h2><h1 id="对细胞取子集"><a href="#对细胞取子集" class="headerlink" title="对细胞取子集"></a>对细胞取子集</h1><p>data.filt &lt;- subset(alldata, cells &#x3D; selected)</p><h1 id="画小提琴图"><a href="#画小提琴图" class="headerlink" title="画小提琴图"></a>画小提琴图</h1><p>VlnPlot(data.filt, features &#x3D; “percent.mito”)</p><p>如图所示，mito百分比仍有很大差异，因此必须在数据分析步骤中进行处理。</p><p>基因过滤</p><p>检测到的基因数量高的离谱的话可能表明doublets，也有可能是因为样品中某一种细胞具有较多基因表达。</p><p>在这次的数据集中，v2和v3之间在基因检测方面也存在明显差异，因此对所有数据应用相同的临界值可能并不合适。</p><p>同时，在蛋白质测定数据p3.1k中，存在大量细胞几乎没有检测到具有双峰分布的基因。v3.1k和v2.12个数据集中也看不到这种分布类型。考虑到它们都是pbmc数据集，因此可以将这种分布视为低质量的库。</p><p>通过设置cutoff值分别为4100（对于v3 chemistry）和2000（对于v2）过滤测到高基因的（可能的doublets）细胞。</p><p>#从检测到许多基因的细胞开始。<br>high.det.v3 &lt;- WhichCells(data.filt, expression &#x3D; nFeature_RNA &gt; 4100)<br>high.det.v2 &lt;- WhichCells(data.filt, expression &#x3D; nFeature_RNA &gt; 2000 &amp; orig.ident &#x3D;&#x3D; “v2.1k”)</p><h1 id="细胞取子集"><a href="#细胞取子集" class="headerlink" title="细胞取子集"></a>细胞取子集</h1><p>data.filt &lt;- subset(data.filt, cells&#x3D;setdiff(WhichCells(data.filt),c(high.det.v2,high.det.v3)))</p><h1 id="查看细胞数"><a href="#查看细胞数" class="headerlink" title="查看细胞数"></a>查看细胞数</h1><p>ncol(data.filt)</p><h2 id="1-2631"><a href="#1-2631" class="headerlink" title="[1] 2631"></a>[1] 2631</h2><p>用低基因检测（低质量文库）过滤细胞，其中v3的基因数cutoff为1000，v2的基因数cutoff为500。</p><p>#筛选基因<br>low.det.v3 &lt;- WhichCells(data.filt, expression &#x3D; nFeature_RNA &lt; 1000 &amp; orig.ident !&#x3D; “v2.1k”)<br>low.det.v2 &lt;- WhichCells(data.filt, expression &#x3D; nFeature_RNA &lt; 500 &amp; orig.ident &#x3D;&#x3D; “v2.1k”)</p><h1 id="去除细胞"><a href="#去除细胞" class="headerlink" title="去除细胞"></a>去除细胞</h1><p>data.filt &lt;- subset(data.filt, cells&#x3D;setdiff(WhichCells(data.filt),c(low.det.v2,low.det.v3)))</p><h1 id="查看细胞数-1"><a href="#查看细胞数-1" class="headerlink" title="查看细胞数"></a>查看细胞数</h1><p>ncol(data.filt)</p><h2 id="1-2531"><a href="#1-2531" class="headerlink" title="[1] 2531"></a>[1] 2531</h2><p>再次绘制QC图</p><p>VlnPlot(data.filt, features &#x3D; “nFeature_RNA”, pt.size &#x3D; 0.1) + NoLegend()</p><p>VlnPlot(data.filt, features &#x3D; “nCount_RNA”, pt.size &#x3D; 0.1) + NoLegend()</p><p>VlnPlot(data.filt, features &#x3D; “percent.mito”, pt.size &#x3D; 0.1) + NoLegend()</p><h1 id="在过滤前后检查每个样本的细胞数"><a href="#在过滤前后检查每个样本的细胞数" class="headerlink" title="在过滤前后检查每个样本的细胞数"></a>在过滤前后检查每个样本的细胞数</h1><p>table(Idents(alldata))<br>##</p><h2 id="p3-1k-v2-1k-v3-1k-1"><a href="#p3-1k-v2-1k-v3-1k-1" class="headerlink" title="p3.1k v2.1k v3.1k"></a>p3.1k v2.1k v3.1k</h2><h2 id="713-996-1222-1"><a href="#713-996-1222-1" class="headerlink" title="713   996  1222"></a>713   996  1222</h2><p>table(Idents(data.filt))<br>##</p><h2 id="p3-1k-v2-1k-v3-1k-2"><a href="#p3-1k-v2-1k-v3-1k-2" class="headerlink" title="p3.1k v2.1k v3.1k"></a>p3.1k v2.1k v3.1k</h2><h2 id="526-933-1072"><a href="#526-933-1072" class="headerlink" title="526   933  1072"></a>526   933  1072</h2><p>计算细胞周期分数</p><p>Seurat具有根据已知的S期和G2&#x2F;M期基因列表计算细胞周期分数的功能（Seurat亮点之细胞周期评分和回归）。</p><p>data.filt &lt;- CellCycleScoring(<br>  object &#x3D; data.filt,<br>  g2m.features &#x3D; cc.genes$g2m.genes,<br>  s.features &#x3D; cc.genes$s.genes<br>)</p><p>VlnPlot(data.filt, features &#x3D; c(“S.Score”,”G2M.Score”))</p><p>从上图可以看出不同数据集中处于S期和G2M期的细胞Score基本均为0，表明细胞周期对数据质量影响并不大。</p><p>Scater<br>可以使用scater包完成相似的QC绘图和细胞过滤，但是由于我们使用Seurat筛选了细胞，因此现在仅使用scater探索数据中的技术偏差。</p><p>可以直接从count矩阵创建SCE对象，网址为：<a href="https://rdrr.io/bioc/scater/f/vignettes/overview.Rmd">https://rdrr.io/bioc/scater/f/vignettes/overview.Rmd</a></p><p>在该例中，我们可以直接从Seurat对象转换为SCE对象。</p><p>sce &lt;- as.SingleCellExperiment(data.filt)<br>我们用访问函数来评估SingleCellExperiment对象的不同元素。</p><p>counts（object）：用于返回read计数矩阵。如上所示，如果未为该对象定义任何计数，则计数矩阵slot为NULL。<br>exprs（object）：用于返回（对数计数）表达式值的矩阵，实际上为访问对象的对数计数slot（logcounts的同义词）。<br>SCE对象还有的slot：</p><p>细胞元数据（Cell metadata,），可以以DataFrame提供，其中行是细胞，列是细胞属性（例如细胞类型、培养条件、捕获的天数等）。<br>特征元数据（Feature metadata），可以以DataFrame提供，其中行是特征（例如基因），列是特征属性，例如Ensembl ID，生物型，gc含量等。<br>计算QC指标</p><p>默认情况下，QC指标是根据count data计算得出的。但是可以通过exprs_values参数进行更改。我们还可以在函数调用中包加入有关哪些基因是线粒体的信息。</p><h1 id="计算QC指标"><a href="#计算QC指标" class="headerlink" title="计算QC指标"></a>计算QC指标</h1><p>sce &lt;- calculateQCMetrics(sce, feature_controls &#x3D; list(mito &#x3D; mt.genes))</p><h1 id="check-what-all-entries-are"><a href="#check-what-all-entries-are" class="headerlink" title="check what all entries are -"></a>check what all entries are -</h1><p>colnames(colData(sce))</p><h2 id="1-“orig-ident”"><a href="#1-“orig-ident”" class="headerlink" title="[1] “orig.ident”"></a>[1] “orig.ident”</h2><h2 id="2-“nCount-RNA”"><a href="#2-“nCount-RNA”" class="headerlink" title="[2] “nCount_RNA”"></a>[2] “nCount_RNA”</h2><h2 id="3-“nFeature-RNA”"><a href="#3-“nFeature-RNA”" class="headerlink" title="[3] “nFeature_RNA”"></a>[3] “nFeature_RNA”</h2><h2 id="4-“Chemistry”"><a href="#4-“Chemistry”" class="headerlink" title="[4] “Chemistry”"></a>[4] “Chemistry”</h2><h2 id="5-“percent-mito”"><a href="#5-“percent-mito”" class="headerlink" title="[5] “percent.mito”"></a>[5] “percent.mito”</h2><h2 id="6-“percent-ribo”"><a href="#6-“percent-ribo”" class="headerlink" title="[6] “percent.ribo”"></a>[6] “percent.ribo”</h2><h2 id="7-“S-Score”"><a href="#7-“S-Score”" class="headerlink" title="[7] “S.Score”"></a>[7] “S.Score”</h2><h2 id="8-“G2M-Score”"><a href="#8-“G2M-Score”" class="headerlink" title="[8] “G2M.Score”"></a>[8] “G2M.Score”</h2><h2 id="9-“Phase”"><a href="#9-“Phase”" class="headerlink" title="[9] “Phase”"></a>[9] “Phase”</h2><h2 id="10-“ident”"><a href="#10-“ident”" class="headerlink" title="[10] “ident”"></a>[10] “ident”</h2><h2 id="11-“is-cell-control”"><a href="#11-“is-cell-control”" class="headerlink" title="[11] “is_cell_control”"></a>[11] “is_cell_control”</h2><h2 id="12-“total-features-by-counts”"><a href="#12-“total-features-by-counts”" class="headerlink" title="[12] “total_features_by_counts”"></a>[12] “total_features_by_counts”</h2><h2 id="13-“log10-total-features-by-counts”"><a href="#13-“log10-total-features-by-counts”" class="headerlink" title="[13] “log10_total_features_by_counts”"></a>[13] “log10_total_features_by_counts”</h2><h2 id="14-“total-counts”"><a href="#14-“total-counts”" class="headerlink" title="[14] “total_counts”"></a>[14] “total_counts”</h2><h2 id="15-“log10-total-counts”"><a href="#15-“log10-total-counts”" class="headerlink" title="[15] “log10_total_counts”"></a>[15] “log10_total_counts”</h2><h2 id="16-“pct-counts-in-top-50-features”"><a href="#16-“pct-counts-in-top-50-features”" class="headerlink" title="[16] “pct_counts_in_top_50_features”"></a>[16] “pct_counts_in_top_50_features”</h2><h2 id="17-“pct-counts-in-top-100-features”"><a href="#17-“pct-counts-in-top-100-features”" class="headerlink" title="[17] “pct_counts_in_top_100_features”"></a>[17] “pct_counts_in_top_100_features”</h2><h2 id="18-“pct-counts-in-top-200-features”"><a href="#18-“pct-counts-in-top-200-features”" class="headerlink" title="[18] “pct_counts_in_top_200_features”"></a>[18] “pct_counts_in_top_200_features”</h2><h2 id="19-“pct-counts-in-top-500-features”"><a href="#19-“pct-counts-in-top-500-features”" class="headerlink" title="[19] “pct_counts_in_top_500_features”"></a>[19] “pct_counts_in_top_500_features”</h2><h2 id="20-“total-features-by-counts-endogenous”"><a href="#20-“total-features-by-counts-endogenous”" class="headerlink" title="[20] “total_features_by_counts_endogenous”"></a>[20] “total_features_by_counts_endogenous”</h2><h2 id="21-“log10-total-features-by-counts-endogenous”"><a href="#21-“log10-total-features-by-counts-endogenous”" class="headerlink" title="[21] “log10_total_features_by_counts_endogenous”"></a>[21] “log10_total_features_by_counts_endogenous”</h2><h2 id="22-“total-counts-endogenous”"><a href="#22-“total-counts-endogenous”" class="headerlink" title="[22] “total_counts_endogenous”"></a>[22] “total_counts_endogenous”</h2><h2 id="23-“log10-total-counts-endogenous”"><a href="#23-“log10-total-counts-endogenous”" class="headerlink" title="[23] “log10_total_counts_endogenous”"></a>[23] “log10_total_counts_endogenous”</h2><h2 id="24-“pct-counts-endogenous”"><a href="#24-“pct-counts-endogenous”" class="headerlink" title="[24] “pct_counts_endogenous”"></a>[24] “pct_counts_endogenous”</h2><h2 id="25-“pct-counts-in-top-50-features-endogenous”"><a href="#25-“pct-counts-in-top-50-features-endogenous”" class="headerlink" title="[25] “pct_counts_in_top_50_features_endogenous”"></a>[25] “pct_counts_in_top_50_features_endogenous”</h2><h2 id="26-“pct-counts-in-top-100-features-endogenous”"><a href="#26-“pct-counts-in-top-100-features-endogenous”" class="headerlink" title="[26] “pct_counts_in_top_100_features_endogenous”"></a>[26] “pct_counts_in_top_100_features_endogenous”</h2><h2 id="27-“pct-counts-in-top-200-features-endogenous”"><a href="#27-“pct-counts-in-top-200-features-endogenous”" class="headerlink" title="[27] “pct_counts_in_top_200_features_endogenous”"></a>[27] “pct_counts_in_top_200_features_endogenous”</h2><h2 id="28-“pct-counts-in-top-500-features-endogenous”"><a href="#28-“pct-counts-in-top-500-features-endogenous”" class="headerlink" title="[28] “pct_counts_in_top_500_features_endogenous”"></a>[28] “pct_counts_in_top_500_features_endogenous”</h2><h2 id="29-“total-features-by-counts-feature-control”"><a href="#29-“total-features-by-counts-feature-control”" class="headerlink" title="[29] “total_features_by_counts_feature_control”"></a>[29] “total_features_by_counts_feature_control”</h2><h2 id="30-“log10-total-features-by-counts-feature-control”"><a href="#30-“log10-total-features-by-counts-feature-control”" class="headerlink" title="[30] “log10_total_features_by_counts_feature_control”"></a>[30] “log10_total_features_by_counts_feature_control”</h2><h2 id="31-“total-counts-feature-control”"><a href="#31-“total-counts-feature-control”" class="headerlink" title="[31] “total_counts_feature_control”"></a>[31] “total_counts_feature_control”</h2><h2 id="32-“log10-total-counts-feature-control”"><a href="#32-“log10-total-counts-feature-control”" class="headerlink" title="[32] “log10_total_counts_feature_control”"></a>[32] “log10_total_counts_feature_control”</h2><h2 id="33-“pct-counts-feature-control”"><a href="#33-“pct-counts-feature-control”" class="headerlink" title="[33] “pct_counts_feature_control”"></a>[33] “pct_counts_feature_control”</h2><h2 id="34-“pct-counts-in-top-50-features-feature-control”"><a href="#34-“pct-counts-in-top-50-features-feature-control”" class="headerlink" title="[34] “pct_counts_in_top_50_features_feature_control”"></a>[34] “pct_counts_in_top_50_features_feature_control”</h2><h2 id="35-“pct-counts-in-top-100-features-feature-control”"><a href="#35-“pct-counts-in-top-100-features-feature-control”" class="headerlink" title="[35] “pct_counts_in_top_100_features_feature_control”"></a>[35] “pct_counts_in_top_100_features_feature_control”</h2><h2 id="36-“pct-counts-in-top-200-features-feature-control”"><a href="#36-“pct-counts-in-top-200-features-feature-control”" class="headerlink" title="[36] “pct_counts_in_top_200_features_feature_control”"></a>[36] “pct_counts_in_top_200_features_feature_control”</h2><h2 id="37-“pct-counts-in-top-500-features-feature-control”"><a href="#37-“pct-counts-in-top-500-features-feature-control”" class="headerlink" title="[37] “pct_counts_in_top_500_features_feature_control”"></a>[37] “pct_counts_in_top_500_features_feature_control”</h2><h2 id="38-“total-features-by-counts-mito”"><a href="#38-“total-features-by-counts-mito”" class="headerlink" title="[38] “total_features_by_counts_mito”"></a>[38] “total_features_by_counts_mito”</h2><h2 id="39-“log10-total-features-by-counts-mito”"><a href="#39-“log10-total-features-by-counts-mito”" class="headerlink" title="[39] “log10_total_features_by_counts_mito”"></a>[39] “log10_total_features_by_counts_mito”</h2><h2 id="40-“total-counts-mito”"><a href="#40-“total-counts-mito”" class="headerlink" title="[40] “total_counts_mito”"></a>[40] “total_counts_mito”</h2><h2 id="41-“log10-total-counts-mito”"><a href="#41-“log10-total-counts-mito”" class="headerlink" title="[41] “log10_total_counts_mito”"></a>[41] “log10_total_counts_mito”</h2><h2 id="42-“pct-counts-mito”"><a href="#42-“pct-counts-mito”" class="headerlink" title="[42] “pct_counts_mito”"></a>[42] “pct_counts_mito”</h2><h2 id="43-“pct-counts-in-top-50-features-mito”"><a href="#43-“pct-counts-in-top-50-features-mito”" class="headerlink" title="[43] “pct_counts_in_top_50_features_mito”"></a>[43] “pct_counts_in_top_50_features_mito”</h2><h2 id="44-“pct-counts-in-top-100-features-mito”"><a href="#44-“pct-counts-in-top-100-features-mito”" class="headerlink" title="[44] “pct_counts_in_top_100_features_mito”"></a>[44] “pct_counts_in_top_100_features_mito”</h2><h2 id="45-“pct-counts-in-top-200-features-mito”"><a href="#45-“pct-counts-in-top-200-features-mito”" class="headerlink" title="[45] “pct_counts_in_top_200_features_mito”"></a>[45] “pct_counts_in_top_200_features_mito”</h2><h2 id="46-“pct-counts-in-top-500-features-mito”"><a href="#46-“pct-counts-in-top-500-features-mito”" class="headerlink" title="[46] “pct_counts_in_top_500_features_mito”"></a>[46] “pct_counts_in_top_500_features_mito”</h2><p>如您所见，scater为细胞计算了许多不同的QC指标。</p><p>Scater还可以根据基因计算一些统计信息：</p><p>colnames(rowData(sce))</p><h2 id="1-“is-feature-control”-“is-feature-control-mito”"><a href="#1-“is-feature-control”-“is-feature-control-mito”" class="headerlink" title="[1] “is_feature_control”      “is_feature_control_mito”"></a>[1] “is_feature_control”      “is_feature_control_mito”</h2><h2 id="3-“mean-counts”-“log10-mean-counts”"><a href="#3-“mean-counts”-“log10-mean-counts”" class="headerlink" title="[3] “mean_counts”             “log10_mean_counts”"></a>[3] “mean_counts”             “log10_mean_counts”</h2><h2 id="5-“n-cells-by-counts”-“pct-dropout-by-counts”"><a href="#5-“n-cells-by-counts”-“pct-dropout-by-counts”" class="headerlink" title="[5] “n_cells_by_counts”       “pct_dropout_by_counts”"></a>[5] “n_cells_by_counts”       “pct_dropout_by_counts”</h2><h2 id="7-“total-counts”-“log10-total-counts”"><a href="#7-“total-counts”-“log10-total-counts”" class="headerlink" title="[7] “total_counts”            “log10_total_counts”"></a>[7] “total_counts”            “log10_total_counts”</h2><p>绘制QC统计数据</p><p>高变基因：</p><p>让我们看看表达的前50位基因是什么。</p><p>plotHighestExprs(sce, exprs_values &#x3D; “counts”)</p><p>如图所示，MALAT1对应平均约4％的计数。在某些细胞中，一些count高达〜30％，可以考虑在进一步分析和聚类之前删除该基因。而且，线粒体基因在总计数中所占比例很高的话也应该被删除。</p><p>累积表达：</p><p>绘制文库大小的相对比例，该比例由每个细胞的最高表达基因（默认为500个基因）表示。这可以帮助我们寻找样本之间表达分布的差异。</p><h1 id="绘制每个样本"><a href="#绘制每个样本" class="headerlink" title="绘制每个样本"></a>绘制每个样本</h1><p>plotScater(sce, block1 &#x3D; “ident”, nfeatures &#x3D; 1000)</p><p>绘制基因统计：</p><p>函数plotRowData可以绘制rowData中的任何统计信息，例如均值表达与检测到的细胞数。</p><p>plotRowData(sce, x &#x3D; “n_cells_by_counts”, y &#x3D; “mean_counts”)</p><p>绘制细胞统计：</p><p>用函数plotColData可以以相同的方式绘制细胞的任何qc统计分析。</p><p>p1 &lt;- plotColData(sce, x &#x3D; “total_counts”,<br>    y &#x3D; “total_features_by_counts”, colour_by &#x3D; “ident”)<br>p2 &lt;- plotColData(sce, x &#x3D; “pct_counts_feature_control”,<br>    y &#x3D; “total_features_by_counts”, colour_by &#x3D; “ident”)<br>p3 &lt;- plotColData(sce, x &#x3D; “pct_counts_feature_control”,<br>    y &#x3D; “pct_counts_in_top_50_features”, colour_by &#x3D; “ident”)<br>multiplot(p1, p2, p3, cols &#x3D; 2)</p><p>识别QC统计数据中的异常值</p><p>识别低质量细胞的方法是在所有qc-stats上运行PCA，然后在PCA空间中识别异常值（Hemberg-lab单细胞转录组数据分析（十一）- Scater单细胞表达谱PCA可视化）。</p><p>sce &lt;- runPCA(sce, use_coldata &#x3D; TRUE,<br>    detect_outliers &#x3D; TRUE)</p><h2 id="sROC-0-1-2-loaded"><a href="#sROC-0-1-2-loaded" class="headerlink" title="sROC 0.1-2 loaded"></a>sROC 0.1-2 loaded</h2><p>plotReducedDim(sce, use_dimred&#x3D;”PCA_coldata”, colour_by &#x3D; “ident”)</p><p>＃检查是否有异常值<br>table(colData(sce)$outlier)<br>##</p><h2 id="FALSE"><a href="#FALSE" class="headerlink" title="FALSE"></a>FALSE</h2><h2 id="2531"><a href="#2531" class="headerlink" title="2531"></a>2531</h2><p>在这种情况下，我们已经滤除了低质量的细胞，并且在QC PCA中未检测到任何异常值。</p><p>降维<br>建议先用runPCA、runTSNE等函数做降维（ 用了这么多年的PCA可视化竟然是错的！！！），以便将它们存储在SCE对象中，这样就不必在每次绘制时都重新运行这些函数。除了这两个函数可以做降维，还有其他函数，比如plotPCA和plotTSNE等等，或者使用函数plotReducedDim并指定use_dimred &#x3D; “pca”等类似的。</p><p>在使用任意组分信息进行降维之前，请记住要设置随机种子，以便可以完全复现。</p><h1 id="使用前1000高变基因运行PCA"><a href="#使用前1000高变基因运行PCA" class="headerlink" title="使用前1000高变基因运行PCA"></a>使用前1000高变基因运行PCA</h1><p>sce &lt;- runPCA(sce, ntop &#x3D; 1000, exprs_values &#x3D; “logcounts”, ncomponents &#x3D; 20)</p><h1 id="PCA-with-different-coloring-first-4-components"><a href="#PCA-with-different-coloring-first-4-components" class="headerlink" title="PCA - with different coloring, first 4 components"></a>PCA - with different coloring, first 4 components</h1><h1 id="first-by-sample"><a href="#first-by-sample" class="headerlink" title="first by sample"></a>first by sample</h1><p>plotPCA(sce,ncomponents&#x3D;4,colour_by&#x3D;”ident”)</p><h1 id="then-by-Celltype"><a href="#then-by-Celltype" class="headerlink" title="then by Celltype"></a>then by Celltype</h1><p>plotPCA(sce,ncomponents&#x3D;4,colour_by&#x3D;”percent.mito”)</p><h1 id="Diffusion-map-运行需要安装destiny包"><a href="#Diffusion-map-运行需要安装destiny包" class="headerlink" title="Diffusion map, 运行需要安装destiny包!"></a>Diffusion map, 运行需要安装destiny包!</h1><p>set.seed(1)<br>sce &lt;- runDiffusionMap(sce, ntop &#x3D; 1000, ncomponents &#x3D; 4)<br>plotDiffusionMap(sce, colour_by&#x3D;”ident”,ncomponents&#x3D;4)</p><h1 id="tSNE-使用tSNE对降维数据进行可视化，top10PCs"><a href="#tSNE-使用tSNE对降维数据进行可视化，top10PCs" class="headerlink" title="tSNE -使用tSNE对降维数据进行可视化，top10PCs"></a>tSNE -使用tSNE对降维数据进行可视化，top10PCs</h1><p>set.seed(1)<br>sce &lt;- runTSNE(sce, ntop &#x3D; 1000, ncomponents &#x3D; 2, perplexity &#x3D; 30, n_dimred &#x3D; 10)<br>plotTSNE(sce, colour_by&#x3D;”ident”)</p><h1 id="UMAP-需要安装umap包"><a href="#UMAP-需要安装umap包" class="headerlink" title="UMAP,需要安装umap包!"></a>UMAP,需要安装umap包!</h1><p>set.seed(1)<br>sce &lt;- runUMAP(sce)<br>plotUMAP(object &#x3D; sce, colour_by&#x3D;”ident”)</p><p>影响因子的可视化<br>我们可以使用plotExplanatoryVariables函数调查不同因素的相对重要性。当拟合线性模型将每个基因的表达值与该因子进行回归时，我们计算colData（sce）中每个因子的可决系数R2来评估拟合优度，最好是在对数表达式值上执行此操作，可以减少平均值对方差的影响——因此，我们首先要进行归一化（取log值）。</p><p>下面的可视化计算耗时较长。</p><p>plotExplanatoryVariables(sce, variables &#x3D;  c(“ident”,”Chemistry”,”pct_counts_mito”, “total_features_by_counts”, “pct_counts_in_top_50_features”, “pct_counts_in_top_500_features”, “total_counts”, “S.Score”,”G2M.Score”))</p><p>每条线对应一个因子在所有基因中R平方值的分布。</p><p>我们要留意确定与QC或Metadata密切相关的PC。默认情况下是绘制前10个因子，但是在这里我们仅可视化一些特定因子。</p><h1 id="for-total-features"><a href="#for-total-features" class="headerlink" title="for total_features"></a>for total_features</h1><p>plotExplanatoryPCs(sce, variables &#x3D; c(“ident”, “Chemistry”,”pct_counts_mito”, “total_features_by_counts”, “pct_counts_in_top_50_features”, “total_counts”,”S.Score”,”G2M.Score”), npcs_to_plot &#x3D; 20)</p><p>问题：您认为可以在数据中看到一些明显的批次效应吗？您是否认为存在技术偏差？</p><p>PC1显然与数据的分布相关，例如前50-500个高度表达的基因在计数的比例，以及占total_features&#x2F;total_counts的比例。这是scRNAseq数据中的常见问题，可能是技术偏差，或者是大小和转录方式非常不同的细胞类型的生物学特征造成的。</p><p>同样很明显的是，许多topPC（尤其是PC 2、3、6、7、8）在很大程度上是由不同的样本（ident）或仅由v2 vs v3（Chemistry）来解释的。</p><p>Session info<br>sessionInfo()</p><h2 id="R-version-3-5-1-2018-07-02"><a href="#R-version-3-5-1-2018-07-02" class="headerlink" title="R version 3.5.1 (2018-07-02)"></a>R version 3.5.1 (2018-07-02)</h2><h2 id="Platform-x86-64-apple-darwin13-4-0-64-bit"><a href="#Platform-x86-64-apple-darwin13-4-0-64-bit" class="headerlink" title="Platform: x86_64-apple-darwin13.4.0 (64-bit)"></a>Platform: x86_64-apple-darwin13.4.0 (64-bit)</h2><h2 id="Running-under-macOS-10-14-4"><a href="#Running-under-macOS-10-14-4" class="headerlink" title="Running under: macOS  10.14.4"></a>Running under: macOS  10.14.4</h2><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="Matrix-products-default"><a href="#Matrix-products-default" class="headerlink" title="Matrix products: default"></a>Matrix products: default</h2><h2 id="BLAS-x2F-LAPACK-x2F-Users-x2F-asbj-x2F-Programs-x2F-miniconda3-4-2-12-x2F-envs-x2F-elixir-course-x2F-lib-x2F-R-x2F-lib-x2F-libRblas-dylib"><a href="#BLAS-x2F-LAPACK-x2F-Users-x2F-asbj-x2F-Programs-x2F-miniconda3-4-2-12-x2F-envs-x2F-elixir-course-x2F-lib-x2F-R-x2F-lib-x2F-libRblas-dylib" class="headerlink" title="BLAS&#x2F;LAPACK: &#x2F;Users&#x2F;asbj&#x2F;Programs&#x2F;miniconda3_4.2.12&#x2F;envs&#x2F;elixir-course&#x2F;lib&#x2F;R&#x2F;lib&#x2F;libRblas.dylib"></a>BLAS&#x2F;LAPACK: &#x2F;Users&#x2F;asbj&#x2F;Programs&#x2F;miniconda3_4.2.12&#x2F;envs&#x2F;elixir-course&#x2F;lib&#x2F;R&#x2F;lib&#x2F;libRblas.dylib</h2><h2 id="-1"><a href="#-1" class="headerlink" title=""></a></h2><h2 id="locale"><a href="#locale" class="headerlink" title="locale:"></a>locale:</h2><h2 id="1-en-US-UTF-8-x2F-en-US-UTF-8-x2F-en-US-UTF-8-x2F-C-x2F-en-US-UTF-8-x2F-en-US-UTF-8"><a href="#1-en-US-UTF-8-x2F-en-US-UTF-8-x2F-en-US-UTF-8-x2F-C-x2F-en-US-UTF-8-x2F-en-US-UTF-8" class="headerlink" title="[1] en_US.UTF-8&#x2F;en_US.UTF-8&#x2F;en_US.UTF-8&#x2F;C&#x2F;en_US.UTF-8&#x2F;en_US.UTF-8"></a>[1] en_US.UTF-8&#x2F;en_US.UTF-8&#x2F;en_US.UTF-8&#x2F;C&#x2F;en_US.UTF-8&#x2F;en_US.UTF-8</h2><h2 id="-2"><a href="#-2" class="headerlink" title=""></a></h2><h2 id="attached-base-packages"><a href="#attached-base-packages" class="headerlink" title="attached base packages:"></a>attached base packages:</h2><h2 id="1-parallel-stats4-stats-graphics-grDevices-utils-datasets"><a href="#1-parallel-stats4-stats-graphics-grDevices-utils-datasets" class="headerlink" title="[1] parallel  stats4    stats     graphics  grDevices utils     datasets"></a>[1] parallel  stats4    stats     graphics  grDevices utils     datasets</h2><h2 id="8-methods-base"><a href="#8-methods-base" class="headerlink" title="[8] methods   base"></a>[8] methods   base</h2><h2 id="-3"><a href="#-3" class="headerlink" title=""></a></h2><h2 id="other-attached-packages"><a href="#other-attached-packages" class="headerlink" title="other attached packages:"></a>other attached packages:</h2><h2 id="1-Matrix-1-2-17-scater-1-10-1"><a href="#1-Matrix-1-2-17-scater-1-10-1" class="headerlink" title="[1] Matrix_1.2-17               scater_1.10.1"></a>[1] Matrix_1.2-17               scater_1.10.1</h2><h2 id="3-ggplot2-3-1-1-SingleCellExperiment-1-4-0"><a href="#3-ggplot2-3-1-1-SingleCellExperiment-1-4-0" class="headerlink" title="[3] ggplot2_3.1.1               SingleCellExperiment_1.4.0"></a>[3] ggplot2_3.1.1               SingleCellExperiment_1.4.0</h2><h2 id="5-SummarizedExperiment-1-12-0-DelayedArray-0-8-0"><a href="#5-SummarizedExperiment-1-12-0-DelayedArray-0-8-0" class="headerlink" title="[5] SummarizedExperiment_1.12.0 DelayedArray_0.8.0"></a>[5] SummarizedExperiment_1.12.0 DelayedArray_0.8.0</h2><h2 id="7-BiocParallel-1-16-6-matrixStats-0-54-0"><a href="#7-BiocParallel-1-16-6-matrixStats-0-54-0" class="headerlink" title="[7] BiocParallel_1.16.6         matrixStats_0.54.0"></a>[7] BiocParallel_1.16.6         matrixStats_0.54.0</h2><h2 id="9-Biobase-2-42-0-GenomicRanges-1-34-0"><a href="#9-Biobase-2-42-0-GenomicRanges-1-34-0" class="headerlink" title="[9] Biobase_2.42.0              GenomicRanges_1.34.0"></a>[9] Biobase_2.42.0              GenomicRanges_1.34.0</h2><h2 id="11-GenomeInfoDb-1-18-1-IRanges-2-16-0"><a href="#11-GenomeInfoDb-1-18-1-IRanges-2-16-0" class="headerlink" title="[11] GenomeInfoDb_1.18.1         IRanges_2.16.0"></a>[11] GenomeInfoDb_1.18.1         IRanges_2.16.0</h2><h2 id="13-S4Vectors-0-20-1-BiocGenerics-0-28-0"><a href="#13-S4Vectors-0-20-1-BiocGenerics-0-28-0" class="headerlink" title="[13] S4Vectors_0.20.1            BiocGenerics_0.28.0"></a>[13] S4Vectors_0.20.1            BiocGenerics_0.28.0</h2><h2 id="15-Seurat-3-0-0"><a href="#15-Seurat-3-0-0" class="headerlink" title="[15] Seurat_3.0.0"></a>[15] Seurat_3.0.0</h2><h2 id="-4"><a href="#-4" class="headerlink" title=""></a></h2><h2 id="loaded-via-a-namespace-and-not-attached"><a href="#loaded-via-a-namespace-and-not-attached" class="headerlink" title="loaded via a namespace (and not attached):"></a>loaded via a namespace (and not attached):</h2><h2 id="1-reticulate-1-12-R-utils-2-8-0"><a href="#1-reticulate-1-12-R-utils-2-8-0" class="headerlink" title="[1] reticulate_1.12          R.utils_2.8.0"></a>[1] reticulate_1.12          R.utils_2.8.0</h2><h2 id="3-tidyselect-0-2-5-htmlwidgets-1-3"><a href="#3-tidyselect-0-2-5-htmlwidgets-1-3" class="headerlink" title="[3] tidyselect_0.2.5         htmlwidgets_1.3"></a>[3] tidyselect_0.2.5         htmlwidgets_1.3</h2><h2 id="5-grid-3-5-1-trimcluster-0-1-2-1"><a href="#5-grid-3-5-1-trimcluster-0-1-2-1" class="headerlink" title="[5] grid_3.5.1               trimcluster_0.1-2.1"></a>[5] grid_3.5.1               trimcluster_0.1-2.1</h2><h2 id="7-ranger-0-11-1-Rtsne-0-15"><a href="#7-ranger-0-11-1-Rtsne-0-15" class="headerlink" title="[7] ranger_0.11.1            Rtsne_0.15"></a>[7] ranger_0.11.1            Rtsne_0.15</h2><h2 id="9-munsell-0-5-0-destiny-2-12-0"><a href="#9-munsell-0-5-0-destiny-2-12-0" class="headerlink" title="[9] munsell_0.5.0            destiny_2.12.0"></a>[9] munsell_0.5.0            destiny_2.12.0</h2><h2 id="11-codetools-0-2-16-ica-1-0-2"><a href="#11-codetools-0-2-16-ica-1-0-2" class="headerlink" title="[11] codetools_0.2-16         ica_1.0-2"></a>[11] codetools_0.2-16         ica_1.0-2</h2><h2 id="13-umap-0-2-0-0-future-1-12-0"><a href="#13-umap-0-2-0-0-future-1-12-0" class="headerlink" title="[13] umap_0.2.0.0             future_1.12.0"></a>[13] umap_0.2.0.0             future_1.12.0</h2><h2 id="15-sROC-0-1-2-withr-2-1-2"><a href="#15-sROC-0-1-2-withr-2-1-2" class="headerlink" title="[15] sROC_0.1-2               withr_2.1.2"></a>[15] sROC_0.1-2               withr_2.1.2</h2><h2 id="17-colorspace-1-4-1-knitr-1-20"><a href="#17-colorspace-1-4-1-knitr-1-20" class="headerlink" title="[17] colorspace_1.4-1         knitr_1.20"></a>[17] colorspace_1.4-1         knitr_1.20</h2><h2 id="19-ROCR-1-0-7-robustbase-0-93-2"><a href="#19-ROCR-1-0-7-robustbase-0-93-2" class="headerlink" title="[19] ROCR_1.0-7               robustbase_0.93-2"></a>[19] ROCR_1.0-7               robustbase_0.93-2</h2><h2 id="21-vcd-1-4-4-VIM-4-8-0"><a href="#21-vcd-1-4-4-VIM-4-8-0" class="headerlink" title="[21] vcd_1.4-4                VIM_4.8.0"></a>[21] vcd_1.4-4                VIM_4.8.0</h2><h2 id="23-TTR-0-23-4-gbRd-0-4-11"><a href="#23-TTR-0-23-4-gbRd-0-4-11" class="headerlink" title="[23] TTR_0.23-4               gbRd_0.4-11"></a>[23] TTR_0.23-4               gbRd_0.4-11</h2><h2 id="25-listenv-0-7-0-Rdpack-0-10-1"><a href="#25-listenv-0-7-0-Rdpack-0-10-1" class="headerlink" title="[25] listenv_0.7.0            Rdpack_0.10-1"></a>[25] listenv_0.7.0            Rdpack_0.10-1</h2><h2 id="27-labeling-0-3-GenomeInfoDbData-1-2-1"><a href="#27-labeling-0-3-GenomeInfoDbData-1-2-1" class="headerlink" title="[27] labeling_0.3             GenomeInfoDbData_1.2.1"></a>[27] labeling_0.3             GenomeInfoDbData_1.2.1</h2><h2 id="29-cvTools-0-3-2-bit64-0-9-7"><a href="#29-cvTools-0-3-2-bit64-0-9-7" class="headerlink" title="[29] cvTools_0.3.2            bit64_0.9-7"></a>[29] cvTools_0.3.2            bit64_0.9-7</h2><h2 id="31-rhdf5-2-26-2-ggthemes-4-1-1"><a href="#31-rhdf5-2-26-2-ggthemes-4-1-1" class="headerlink" title="[31] rhdf5_2.26.2             ggthemes_4.1.1"></a>[31] rhdf5_2.26.2             ggthemes_4.1.1</h2><h2 id="33-diptest-0-75-7-R6-2-4-0"><a href="#33-diptest-0-75-7-R6-2-4-0" class="headerlink" title="[33] diptest_0.75-7           R6_2.4.0"></a>[33] diptest_0.75-7           R6_2.4.0</h2><h2 id="35-ggbeeswarm-0-6-0-robCompositions-2-0-10"><a href="#35-ggbeeswarm-0-6-0-robCompositions-2-0-10" class="headerlink" title="[35] ggbeeswarm_0.6.0         robCompositions_2.0.10"></a>[35] ggbeeswarm_0.6.0         robCompositions_2.0.10</h2><h2 id="37-rsvd-1-0-0-RcppEigen-0-3-3-5-0"><a href="#37-rsvd-1-0-0-RcppEigen-0-3-3-5-0" class="headerlink" title="[37] rsvd_1.0.0               RcppEigen_0.3.3.5.0"></a>[37] rsvd_1.0.0               RcppEigen_0.3.3.5.0</h2><h2 id="39-mvoutlier-2-0-9-hdf5r-1-2-0"><a href="#39-mvoutlier-2-0-9-hdf5r-1-2-0" class="headerlink" title="[39] mvoutlier_2.0.9          hdf5r_1.2.0"></a>[39] mvoutlier_2.0.9          hdf5r_1.2.0</h2><h2 id="41-flexmix-2-3-15-bitops-1-0-6"><a href="#41-flexmix-2-3-15-bitops-1-0-6" class="headerlink" title="[41] flexmix_2.3-15           bitops_1.0-6"></a>[41] flexmix_2.3-15           bitops_1.0-6</h2><h2 id="43-reshape-0-8-8-assertthat-0-2-1"><a href="#43-reshape-0-8-8-assertthat-0-2-1" class="headerlink" title="[43] reshape_0.8.8            assertthat_0.2.1"></a>[43] reshape_0.8.8            assertthat_0.2.1</h2><h2 id="45-SDMTools-1-1-221-1-scales-1-0-0"><a href="#45-SDMTools-1-1-221-1-scales-1-0-0" class="headerlink" title="[45] SDMTools_1.1-221.1       scales_1.0.0"></a>[45] SDMTools_1.1-221.1       scales_1.0.0</h2><h2 id="47-nnet-7-3-12-beeswarm-0-2-3"><a href="#47-nnet-7-3-12-beeswarm-0-2-3" class="headerlink" title="[47] nnet_7.3-12              beeswarm_0.2.3"></a>[47] nnet_7.3-12              beeswarm_0.2.3</h2><h2 id="49-gtable-0-3-0-npsurv-0-4-0"><a href="#49-gtable-0-3-0-npsurv-0-4-0" class="headerlink" title="[49] gtable_0.3.0             npsurv_0.4-0"></a>[49] gtable_0.3.0             npsurv_0.4-0</h2><h2 id="51-globals-0-12-4-rlang-0-3-4"><a href="#51-globals-0-12-4-rlang-0-3-4" class="headerlink" title="[51] globals_0.12.4           rlang_0.3.4"></a>[51] globals_0.12.4           rlang_0.3.4</h2><h2 id="53-scatterplot3d-0-3-41-splines-3-5-1"><a href="#53-scatterplot3d-0-3-41-splines-3-5-1" class="headerlink" title="[53] scatterplot3d_0.3-41     splines_3.5.1"></a>[53] scatterplot3d_0.3-41     splines_3.5.1</h2><h2 id="55-lazyeval-0-2-2-yaml-2-2-0"><a href="#55-lazyeval-0-2-2-yaml-2-2-0" class="headerlink" title="[55] lazyeval_0.2.2           yaml_2.2.0"></a>[55] lazyeval_0.2.2           yaml_2.2.0</h2><h2 id="57-reshape2-1-4-3-abind-1-4-5"><a href="#57-reshape2-1-4-3-abind-1-4-5" class="headerlink" title="[57] reshape2_1.4.3           abind_1.4-5"></a>[57] reshape2_1.4.3           abind_1.4-5</h2><h2 id="59-tools-3-5-1-zCompositions-1-2-0"><a href="#59-tools-3-5-1-zCompositions-1-2-0" class="headerlink" title="[59] tools_3.5.1              zCompositions_1.2.0"></a>[59] tools_3.5.1              zCompositions_1.2.0</h2><h2 id="61-gplots-3-0-1-1-RColorBrewer-1-1-2"><a href="#61-gplots-3-0-1-1-RColorBrewer-1-1-2" class="headerlink" title="[61] gplots_3.0.1.1           RColorBrewer_1.1-2"></a>[61] gplots_3.0.1.1           RColorBrewer_1.1-2</h2><h2 id="63-proxy-0-4-22-ggridges-0-5-1"><a href="#63-proxy-0-4-22-ggridges-0-5-1" class="headerlink" title="[63] proxy_0.4-22             ggridges_0.5.1"></a>[63] proxy_0.4-22             ggridges_0.5.1</h2><h2 id="65-Rcpp-1-0-1-plyr-1-8-4"><a href="#65-Rcpp-1-0-1-plyr-1-8-4" class="headerlink" title="[65] Rcpp_1.0.1               plyr_1.8.4"></a>[65] Rcpp_1.0.1               plyr_1.8.4</h2><h2 id="67-zlibbioc-1-28-0-purrr-0-3-2"><a href="#67-zlibbioc-1-28-0-purrr-0-3-2" class="headerlink" title="[67] zlibbioc_1.28.0          purrr_0.3.2"></a>[67] zlibbioc_1.28.0          purrr_0.3.2</h2><h2 id="69-RCurl-1-95-4-12-pbapply-1-4-0"><a href="#69-RCurl-1-95-4-12-pbapply-1-4-0" class="headerlink" title="[69] RCurl_1.95-4.12          pbapply_1.4-0"></a>[69] RCurl_1.95-4.12          pbapply_1.4-0</h2><h2 id="71-viridis-0-5-1-cowplot-0-9-4"><a href="#71-viridis-0-5-1-cowplot-0-9-4" class="headerlink" title="[71] viridis_0.5.1            cowplot_0.9.4"></a>[71] viridis_0.5.1            cowplot_0.9.4</h2><h2 id="73-zoo-1-8-5-haven-2-1-0"><a href="#73-zoo-1-8-5-haven-2-1-0" class="headerlink" title="[73] zoo_1.8-5                haven_2.1.0"></a>[73] zoo_1.8-5                haven_2.1.0</h2><h2 id="75-ggrepel-0-8-1-cluster-2-0-9"><a href="#75-ggrepel-0-8-1-cluster-2-0-9" class="headerlink" title="[75] ggrepel_0.8.1            cluster_2.0.9"></a>[75] ggrepel_0.8.1            cluster_2.0.9</h2><h2 id="77-magrittr-1-5-RSpectra-0-14-0"><a href="#77-magrittr-1-5-RSpectra-0-14-0" class="headerlink" title="[77] magrittr_1.5             RSpectra_0.14-0"></a>[77] magrittr_1.5             RSpectra_0.14-0</h2><h2 id="79-data-table-1-12-2-openxlsx-4-1-0"><a href="#79-data-table-1-12-2-openxlsx-4-1-0" class="headerlink" title="[79] data.table_1.12.2        openxlsx_4.1.0"></a>[79] data.table_1.12.2        openxlsx_4.1.0</h2><h2 id="81-lmtest-0-9-36-RANN-2-6"><a href="#81-lmtest-0-9-36-RANN-2-6" class="headerlink" title="[81] lmtest_0.9-36            RANN_2.6"></a>[81] lmtest_0.9-36            RANN_2.6</h2><h2 id="83-truncnorm-1-0-8-mvtnorm-1-0-10"><a href="#83-truncnorm-1-0-8-mvtnorm-1-0-10" class="headerlink" title="[83] truncnorm_1.0-8          mvtnorm_1.0-10"></a>[83] truncnorm_1.0-8          mvtnorm_1.0-10</h2><h2 id="85-fitdistrplus-1-0-14-hms-0-4-2"><a href="#85-fitdistrplus-1-0-14-hms-0-4-2" class="headerlink" title="[85] fitdistrplus_1.0-14      hms_0.4.2"></a>[85] fitdistrplus_1.0-14      hms_0.4.2</h2><h2 id="87-lsei-1-2-0-evaluate-0-13"><a href="#87-lsei-1-2-0-evaluate-0-13" class="headerlink" title="[87] lsei_1.2-0               evaluate_0.13"></a>[87] lsei_1.2-0               evaluate_0.13</h2><h2 id="89-smoother-1-1-rio-0-5-16"><a href="#89-smoother-1-1-rio-0-5-16" class="headerlink" title="[89] smoother_1.1             rio_0.5.16"></a>[89] smoother_1.1             rio_0.5.16</h2><h2 id="91-mclust-5-4-3-readxl-1-3-1"><a href="#91-mclust-5-4-3-readxl-1-3-1" class="headerlink" title="[91] mclust_5.4.3             readxl_1.3.1"></a>[91] mclust_5.4.3             readxl_1.3.1</h2><h2 id="93-gridExtra-2-3-compiler-3-5-1"><a href="#93-gridExtra-2-3-compiler-3-5-1" class="headerlink" title="[93] gridExtra_2.3            compiler_3.5.1"></a>[93] gridExtra_2.3            compiler_3.5.1</h2><h2 id="95-tibble-2-1-1-KernSmooth-2-23-15"><a href="#95-tibble-2-1-1-KernSmooth-2-23-15" class="headerlink" title="[95] tibble_2.1.1             KernSmooth_2.23-15"></a>[95] tibble_2.1.1             KernSmooth_2.23-15</h2><h2 id="97-crayon-1-3-4-R-oo-1-22-0"><a href="#97-crayon-1-3-4-R-oo-1-22-0" class="headerlink" title="[97] crayon_1.3.4             R.oo_1.22.0"></a>[97] crayon_1.3.4             R.oo_1.22.0</h2><h2 id="99-htmltools-0-3-6-pcaPP-1-9-73"><a href="#99-htmltools-0-3-6-pcaPP-1-9-73" class="headerlink" title="[99] htmltools_0.3.6          pcaPP_1.9-73"></a>[99] htmltools_0.3.6          pcaPP_1.9-73</h2><h2 id="101-tidyr-0-8-3-rrcov-1-4-4"><a href="#101-tidyr-0-8-3-rrcov-1-4-4" class="headerlink" title="[101] tidyr_0.8.3              rrcov_1.4-4"></a>[101] tidyr_0.8.3              rrcov_1.4-4</h2><h2 id="103-MASS-7-3-51-4-fpc-2-1-11-1"><a href="#103-MASS-7-3-51-4-fpc-2-1-11-1" class="headerlink" title="[103] MASS_7.3-51.4            fpc_2.1-11.1"></a>[103] MASS_7.3-51.4            fpc_2.1-11.1</h2><h2 id="105-boot-1-3-22-car-3-0-2"><a href="#105-boot-1-3-22-car-3-0-2" class="headerlink" title="[105] boot_1.3-22              car_3.0-2"></a>[105] boot_1.3-22              car_3.0-2</h2><h2 id="107-sgeostat-1-0-27-R-methodsS3-1-7-1"><a href="#107-sgeostat-1-0-27-R-methodsS3-1-7-1" class="headerlink" title="[107] sgeostat_1.0-27          R.methodsS3_1.7.1"></a>[107] sgeostat_1.0-27          R.methodsS3_1.7.1</h2><h2 id="109-gdata-2-18-0-metap-1-1"><a href="#109-gdata-2-18-0-metap-1-1" class="headerlink" title="[109] gdata_2.18.0             metap_1.1"></a>[109] gdata_2.18.0             metap_1.1</h2><h2 id="111-igraph-1-2-4-1-forcats-0-4-0"><a href="#111-igraph-1-2-4-1-forcats-0-4-0" class="headerlink" title="[111] igraph_1.2.4.1           forcats_0.4.0"></a>[111] igraph_1.2.4.1           forcats_0.4.0</h2><h2 id="113-pkgconfig-2-0-2-foreign-0-8-71"><a href="#113-pkgconfig-2-0-2-foreign-0-8-71" class="headerlink" title="[113] pkgconfig_2.0.2          foreign_0.8-71"></a>[113] pkgconfig_2.0.2          foreign_0.8-71</h2><h2 id="115-laeken-0-5-0-sp-1-3-1"><a href="#115-laeken-0-5-0-sp-1-3-1" class="headerlink" title="[115] laeken_0.5.0             sp_1.3-1"></a>[115] laeken_0.5.0             sp_1.3-1</h2><h2 id="117-plotly-4-8-0-vipor-0-4-5"><a href="#117-plotly-4-8-0-vipor-0-4-5" class="headerlink" title="[117] plotly_4.8.0             vipor_0.4.5"></a>[117] plotly_4.8.0             vipor_0.4.5</h2><h2 id="119-XVector-0-22-0-bibtex-0-4-2"><a href="#119-XVector-0-22-0-bibtex-0-4-2" class="headerlink" title="[119] XVector_0.22.0           bibtex_0.4.2"></a>[119] XVector_0.22.0           bibtex_0.4.2</h2><h2 id="121-NADA-1-6-1-stringr-1-4-0"><a href="#121-NADA-1-6-1-stringr-1-4-0" class="headerlink" title="[121] NADA_1.6-1               stringr_1.4.0"></a>[121] NADA_1.6-1               stringr_1.4.0</h2><h2 id="123-digest-0-6-18-sctransform-0-2-0"><a href="#123-digest-0-6-18-sctransform-0-2-0" class="headerlink" title="[123] digest_0.6.18            sctransform_0.2.0"></a>[123] digest_0.6.18            sctransform_0.2.0</h2><h2 id="125-pls-2-7-0-tsne-0-1-3"><a href="#125-pls-2-7-0-tsne-0-1-3" class="headerlink" title="[125] pls_2.7-0                tsne_0.1-3"></a>[125] pls_2.7-0                tsne_0.1-3</h2><h2 id="127-rmarkdown-1-11-cellranger-1-1-0"><a href="#127-rmarkdown-1-11-cellranger-1-1-0" class="headerlink" title="[127] rmarkdown_1.11           cellranger_1.1.0"></a>[127] rmarkdown_1.11           cellranger_1.1.0</h2><h2 id="129-DelayedMatrixStats-1-4-0-curl-3-3"><a href="#129-DelayedMatrixStats-1-4-0-curl-3-3" class="headerlink" title="[129] DelayedMatrixStats_1.4.0 curl_3.3"></a>[129] DelayedMatrixStats_1.4.0 curl_3.3</h2><h2 id="131-kernlab-0-9-27-gtools-3-8-1"><a href="#131-kernlab-0-9-27-gtools-3-8-1" class="headerlink" title="[131] kernlab_0.9-27           gtools_3.8.1"></a>[131] kernlab_0.9-27           gtools_3.8.1</h2><h2 id="133-modeltools-0-2-22-nlme-3-1-139"><a href="#133-modeltools-0-2-22-nlme-3-1-139" class="headerlink" title="[133] modeltools_0.2-22        nlme_3.1-139"></a>[133] modeltools_0.2-22        nlme_3.1-139</h2><h2 id="135-jsonlite-1-6-Rhdf5lib-1-4-3"><a href="#135-jsonlite-1-6-Rhdf5lib-1-4-3" class="headerlink" title="[135] jsonlite_1.6             Rhdf5lib_1.4.3"></a>[135] jsonlite_1.6             Rhdf5lib_1.4.3</h2><h2 id="137-carData-3-0-2-viridisLite-0-3-0"><a href="#137-carData-3-0-2-viridisLite-0-3-0" class="headerlink" title="[137] carData_3.0-2            viridisLite_0.3.0"></a>[137] carData_3.0-2            viridisLite_0.3.0</h2><h2 id="139-pillar-1-3-1-lattice-0-20-38"><a href="#139-pillar-1-3-1-lattice-0-20-38" class="headerlink" title="[139] pillar_1.3.1             lattice_0.20-38"></a>[139] pillar_1.3.1             lattice_0.20-38</h2><h2 id="141-GGally-1-4-0-httr-1-4-0"><a href="#141-GGally-1-4-0-httr-1-4-0" class="headerlink" title="[141] GGally_1.4.0             httr_1.4.0"></a>[141] GGally_1.4.0             httr_1.4.0</h2><h2 id="143-DEoptimR-1-0-8-survival-2-44-1-1"><a href="#143-DEoptimR-1-0-8-survival-2-44-1-1" class="headerlink" title="[143] DEoptimR_1.0-8           survival_2.44-1.1"></a>[143] DEoptimR_1.0-8           survival_2.44-1.1</h2><h2 id="145-xts-0-11-1-glue-1-3-1"><a href="#145-xts-0-11-1-glue-1-3-1" class="headerlink" title="[145] xts_0.11-1               glue_1.3.1"></a>[145] xts_0.11-1               glue_1.3.1</h2><h2 id="147-zip-2-0-1-png-0-1-7"><a href="#147-zip-2-0-1-png-0-1-7" class="headerlink" title="[147] zip_2.0.1                png_0.1-7"></a>[147] zip_2.0.1                png_0.1-7</h2><h2 id="149-prabclus-2-2-7-bit-1-1-14"><a href="#149-prabclus-2-2-7-bit-1-1-14" class="headerlink" title="[149] prabclus_2.2-7           bit_1.1-14"></a>[149] prabclus_2.2-7           bit_1.1-14</h2><h2 id="151-class-7-3-15-stringi-1-4-3"><a href="#151-class-7-3-15-stringi-1-4-3" class="headerlink" title="[151] class_7.3-15             stringi_1.4.3"></a>[151] class_7.3-15             stringi_1.4.3</h2><h2 id="153-HDF5Array-1-10-1-caTools-1-17-1-2"><a href="#153-HDF5Array-1-10-1-caTools-1-17-1-2" class="headerlink" title="[153] HDF5Array_1.10.1         caTools_1.17.1.2"></a>[153] HDF5Array_1.10.1         caTools_1.17.1.2</h2><h2 id="155-dplyr-0-8-0-1-irlba-2-3-3"><a href="#155-dplyr-0-8-0-1-irlba-2-3-3" class="headerlink" title="[155] dplyr_0.8.0.1            irlba_2.3.3"></a>[155] dplyr_0.8.0.1            irlba_2.3.3</h2><h2 id="157-e1071-1-7-0-future-apply-1-1-0"><a href="#157-e1071-1-7-0-future-apply-1-1-0" class="headerlink" title="[157] e1071_1.7-0              future.apply_1.1.0"></a>[157] e1071_1.7-0              future.apply_1.1.0</h2><h2 id="159-ape-5-3"><a href="#159-ape-5-3" class="headerlink" title="[159] ape_5.3"></a>[159] ape_5.3</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>从基因名到GO注释一步到位</title>
      <link href="/2020-04-15-cong-ji-yin-ming-dao-go-zhu-shi-yi-bu-dao-wei/"/>
      <url>/2020-04-15-cong-ji-yin-ming-dao-go-zhu-shi-yi-bu-dao-wei/</url>
      
        <content type="html"><![CDATA[<p>从基因名到GO注释一步到位</p><span id="more"></span><!-- toc --><hr><font face="黑体" color=black size=4><table><tr><td bgcolor=lightblue><p>大部分的生物学高通量数据处理后都是得到基因集，不管是上调下调表达基因集，还是共表达的模块基因集，都是需要注释到生物学功能数据库来看基因集的意义，最常见的是<font color=darkgreen face="黑体"> GO&#x2F;KEGG数据库</font>啦，还有很多其它在<font color=darkgreen face="黑体">MsigDB</font>的，比如<font color=darkgreen face="黑体">reactome和biocarta数据库</font>等等。 </p></td></tr></table></font><font face="黑体" color=black size=4><p>这样分析起来就很麻烦，尤其是GO数据库，还有 BP,CC,MF的区别，这个时候推荐使用Y叔的神器，使用</p></font><pre><code>library(ggplot2)library(stringr)library(clusterProfiler)# 我这里演示的是brown_down_gene，是WGCNA的一个模块，基因集# 因为表达矩阵是symbol，所以需要转为ENTREZID，才能走clusterProfiler的函数。gene.df &lt;- bitr(brown_down_gene$symbol, fromType=&quot;SYMBOL&quot;,                toType=&quot;ENTREZID&quot;,                 OrgDb = &quot;org.Hs.eg.db&quot;)go &lt;- enrichGO(gene = gene.df$ENTREZID, OrgDb = &quot;org.Hs.eg.db&quot;, ont=&quot;all&quot;)barplot(go, split=&quot;ONTOLOGY&quot;)+ facet_grid(ONTOLOGY~., scale=&quot;free&quot;)</code></pre><font face="黑体" color=black size=4>会得到如下所示的图，当然，理解起来需要耗费一点功夫，如果你是第一次看到的话！不仅仅是要理解GO数据库，以及BP,MF,CC的分类系统，超几何分布检验，不同的阈值过滤，筛选指标等等。</font><img src="/2020-04-15-cong-ji-yin-ming-dao-go-zhu-shi-yi-bu-dao-wei/1.png" class=""><font face="黑体" color=black size=4><p>因为上面的代码并没有修改默认的统计学指标筛选参数，如果你的基因确实没有规则，有可能拿不到结果哦！这个时候可以设置：pvalueCutoff &#x3D; 0.9, qvalueCutoff &#x3D;0.9 甚至为1，来不做筛选。而且基因集的大小也是被限制了。  </p></font> <center><font face="黑体" color=white size=5><table><tr><td bgcolor=DeepSkyBlue>如果你想分开计算上下调基因的GO数据库注释</td></tr></table></font></center><font face="黑体" color=black size=4><p>而且还想保留富集分析结果到csv文件，代码如下：</p></font><pre><code>library(ggplot2)library(stringr)library(clusterProfiler)# 通过前面的差异分析，我们拿到了  gene_up 和 gene_down 这两个基因集# 后面的分析，只需要  gene_up 和 gene_down  这两个变量即可go_up &lt;- enrichGO(gene_up,                     OrgDb = &quot;org.Hs.eg.db&quot;,                     ont=&quot;all&quot;,                    pvalueCutoff = 0.9,                    qvalueCutoff =0.9)go_up=DOSE::setReadable(go_up, OrgDb=&#39;org.Hs.eg.db&#39;,keyType=&#39;ENTREZID&#39;)write.csv(go_up@result,paste0(pro,&#39;_go_down.up.csv&#39;))barplot(go_up, split=&quot;ONTOLOGY&quot;,font.size =10)+   facet_grid(ONTOLOGY~., scale=&quot;free&quot;) +   scale_x_discrete(labels=function(x) str_wrap(x, width=50))+  ggsave(paste0(pro,&#39;gene_up_GO_all_barplot.png&#39;)) go_down &lt;- enrichGO(gene_down,                     OrgDb = &quot;org.Hs.eg.db&quot;,                     ont=&quot;all&quot;,                    pvalueCutoff = 0.9,                    qvalueCutoff =0.9)go_down=DOSE::setReadable(go_down, OrgDb=&#39;org.Hs.eg.db&#39;,keyType=&#39;ENTREZID&#39;)write.csv(go_down@result,paste0(pro,&#39;_go_down.up.csv&#39;))barplot(go_down, split=&quot;ONTOLOGY&quot;,font.size =10)+   facet_grid(ONTOLOGY~., scale=&quot;free&quot;) +   scale_x_discrete(labels=function(x) str_wrap(x, width=50))+  ggsave(paste0(pro,&#39;gene_down_GO_all_barplot.png&#39;)) </code></pre><font face="黑体" color=black size=4><p>其实就是两个独立的基因集，独立的走enrichGO流程啦！</p></font><center><font face="黑体" color=white size=5><table><tr><td bgcolor=DeepSkyBlue>多组基因集的KEGG数据库富集</td></tr></table></font></center><font face="黑体" color=black size=4><p>有趣的是，如果你是多组基因，不仅仅是上下调，甚至可以走compareCluster流程，不过Y叔的这个函数总是喜欢在线获取KEGG数据库的最新信息，这一点对很多人来说，考验网速：</p></font><pre><code># 这里需要制作一个 DEG 的数据框，其中有两列ENTREZID，是基因id,和new是分组信息xx.formula &lt;- compareCluster(ENTREZID~new, data=DEG, fun=&#39;enrichKEGG&#39;)dotplot(xx.formula, x=~GeneRatio) + facet_grid(~new)</code></pre><center><font face="黑体" color=white size=5><table><tr><td bgcolor=DeepSkyBlue>如果是多组基因集走GO数据库富集</td></tr></table></font></center><font face="黑体" color=black size=4><p>如下，构建一个数据框，list_de_gene_clusters， 含有两列信息：</p></font><pre><code>list_de_gene_clusters &lt;- split(de_gene_clusters$ENTREZID,                                de_gene_clusters$cluster)# Run full GO enrichment testformula_res &lt;- compareCluster(  ENTREZID~cluster,   data=de_gene_clusters,   fun=&quot;enrichGO&quot;,   OrgDb=&quot;org.Mm.eg.db&quot;,  ont           = &quot;BP&quot;,  pAdjustMethod = &quot;BH&quot;,  pvalueCutoff  = 0.01,  qvalueCutoff  = 0.05)# Run GO enrichment test and merge terms # that are close to each other to remove result redundancylineage1_ego &lt;- simplify(  formula_res,   cutoff=0.5,   by=&quot;p.adjust&quot;,   select_fun=min)</code></pre><center><font face="黑体" color=white size=5><table><tr><td bgcolor=DeepSkyBlue>感兴趣的可以把这个结果跟3个出名的网页工具进行比较</td></tr></table></font></center><font face="黑体" color=black size=4><ul><li><a href="https://amp.pharm.mssm.edu/Enrichr/">https://amp.pharm.mssm.edu/Enrichr/</a></li><li><a href="http://www.webgestalt.org/">http://www.webgestalt.org/</a>   </li><li><a href="https://biit.cs.ut.ee/gprofiler">https://biit.cs.ut.ee/gprofiler</a></li></ul></font><center><font face="黑体" color=white size=5><table><tr><td bgcolor=DeepSkyBlue>另外，强推Y叔clusterProfiler的一些可视化方法</td></tr></table></font></center><font face="黑体" color=black size=4><p>可视化方法函数列表：</p><ul><li>barplot</li><li>cnetplot</li><li>dotplot</li><li>emapplot</li><li>gseaplot</li><li>goplot</li><li>upsetplot</li></ul><p>好几个都是以前没有介绍过的，有趣的是我准备浏览这些可视化函数的帮助文档的时候，看到了这样的话：<br>重点来了，Y叔特意为其包写了一本书来介绍其用法。 </p><p>Please go to <a href="https://yulab-smu.github.io/clusterProfiler-book/">https://yulab-smu.github.io/clusterProfiler-book/</a> for the full vignette.</p></font>]]></content>
      
      
      <categories>
          
          <category> GO-KEGG富集分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GO-KEGG </tag>
            
            <tag> R绘图 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>芯片探针序列的基因组注释</title>
      <link href="/2020-01-02-xin-pian-tan-zhen-xu-lie-de-ji-yin-zu-zhu-shi/"/>
      <url>/2020-01-02-xin-pian-tan-zhen-xu-lie-de-ji-yin-zu-zhu-shi/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><!-- toc --><hr>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>miRNA数据分析专题</title>
      <link href="/2019-12-31-mirna-shu-ju-fen-xi-zhuan-ti/"/>
      <url>/2019-12-31-mirna-shu-ju-fen-xi-zhuan-ti/</url>
      
        <content type="html"><![CDATA[<p>miRNA数据分析专题</p><span id="more"></span><!-- toc --><hr><p> <strong>miRNA</strong>是一类长度在18到36bp的非编码RNA, 其功能属于转后后修饰调控，主要通过和mRNA的3’UTR区进行结合，结合区域称之为<code>seed</code>，当结合区域的序列完全配对时，诱导mRNA降解， 当只有部分序列配对时，抑制mRNA的翻译，从而发挥一个负调控的机制，本文整理了miRNA相关的资料。</p><h1 id="首先是miRNA简介和先关的数据库"><a href="#首先是miRNA简介和先关的数据库" class="headerlink" title="首先是miRNA简介和先关的数据库"></a>首先是miRNA简介和先关的数据库</h1><ol><li>microRNA简介</li><li>miRNA命名规范</li><li>mirbase数据库简介</li><li>Rfam数据库简介</li><li>RNAcentral:非编码RNA数据库</li></ol><h1 id="miRNA研究的核心内容是定量，差异和靶基因调控。定量包括了已知miRNA定量和预测新的miRNA"><a href="#miRNA研究的核心内容是定量，差异和靶基因调控。定量包括了已知miRNA定量和预测新的miRNA" class="headerlink" title="miRNA研究的核心内容是定量，差异和靶基因调控。定量包括了已知miRNA定量和预测新的miRNA"></a>miRNA研究的核心内容是定量，差异和靶基因调控。定量包括了已知miRNA定量和预测新的miRNA</h1><ol><li>已知miRNA定量原理揭秘</li><li>RNA二级结构表示法:Dot-Bracket notation</li><li>RNAfold预测RNA的二级结构</li><li>mirdeep2识别novel miRNA</li></ol><h1 id="miRNA靶基因相关的数据库如下"><a href="#miRNA靶基因相关的数据库如下" class="headerlink" title="miRNA靶基因相关的数据库如下"></a>miRNA靶基因相关的数据库如下</h1><ol><li>miRTarBase:实验验证的miRNA靶基因数据库</li><li>mirDIP:最全面的人类miRNA靶基因数据库</li><li>miRWalk:综合型的miRNA靶基因数据库</li><li>TargetScan:哺乳动物miRNA靶基因数据库</li><li>miRDB:软件预测的哺乳动物miRNA靶基因数据库</li><li>TarBase:有实验数据支持的miRNA靶基因数据库</li><li>HMDD:miRNA相关疾病数据库</li><li>TransmiR:转录因子和miRNA调控关系数据库</li><li>miRcode:人类miRNA结合图谱数据库</li><li>miRanda和mirSVR:预测miRNA结合位点的工具</li></ol><h1 id="通过miRNA与mRNA的调控关系，可以对差异miRNA对应的靶标mRNA进行富集分析"><a href="#通过miRNA与mRNA的调控关系，可以对差异miRNA对应的靶标mRNA进行富集分析" class="headerlink" title="通过miRNA与mRNA的调控关系，可以对差异miRNA对应的靶标mRNA进行富集分析"></a>通过miRNA与mRNA的调控关系，可以对差异miRNA对应的靶标mRNA进行富集分析</h1><ol><li>miRPath:miRNA相关GO和KEGG功能分析</li></ol><h1 id="miRNA的调控机制，使得其参与到很多疾病的发生发展过程中"><a href="#miRNA的调控机制，使得其参与到很多疾病的发生发展过程中" class="headerlink" title="miRNA的调控机制，使得其参与到很多疾病的发生发展过程中"></a>miRNA的调控机制，使得其参与到很多疾病的发生发展过程中</h1><ol><li>mir2disease:miRNA相关疾病数据库</li><li>MirSNP:miRNA相关SNP位点数据库</li><li>miRCancer:肿瘤相关的miRNA表达谱数据库</li></ol><p>单纯的miRNA数据分析，内容较少，更多的是作为一种调控机制，研究其与其他RNA分子的互作，比如ceRNA调控机制的研究，综合mRNA, lncRNA, circRNA和miRNA, 来研究其ceRNA调控网络关系。</p>]]></content>
      
      
      <categories>
          
          <category> miRNA数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> miRNA数据分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>single cell数据分析专题</title>
      <link href="/2019-12-20-dan-xi-bao-zhuan-lu-zu-ce-xu-fen-xi-zhuan-ti/"/>
      <url>/2019-12-20-dan-xi-bao-zhuan-lu-zu-ce-xu-fen-xi-zhuan-ti/</url>
      
        <content type="html"><![CDATA[<p>单细胞转录组数据分析专题</p><span id="more"></span><!-- toc --><hr><h1 id="单细胞转录组数据分析专题"><a href="#单细胞转录组数据分析专题" class="headerlink" title="单细胞转录组数据分析专题"></a>单细胞转录组数据分析专题</h1><p><strong>single cell RNA sequencing</strong>,简称<strong>scRNA_seq</strong>, 指的是针对单个细胞的RNA进行分析。传统的转录组分析其样本为多种细胞的混合物，称之为<strong>bulk RNA seq</strong>, 而scRNA则针对单个细胞进行分析，避免了细胞异质性的问题，对于肿瘤等异质性强的组织,scRNA有着巨大优势。</p><p>同时scRNA可以对细胞亚群进行划分，研究细胞谱系，进一步了解和完善细胞分化过程。<br>目前scRNA的研究可谓是如火如荼，本文整理了scRNA数据分析的相关资料。</p><h1 id="1-10X-Genomics平台是目前最主流的单细胞平台，除了完整的文库制备外，还集成了对应的数据分析软件cell-ranger"><a href="#1-10X-Genomics平台是目前最主流的单细胞平台，除了完整的文库制备外，还集成了对应的数据分析软件cell-ranger" class="headerlink" title="1. 10X Genomics平台是目前最主流的单细胞平台，除了完整的文库制备外，还集成了对应的数据分析软件cell ranger"></a>1. 10X Genomics平台是目前最主流的单细胞平台，除了完整的文库制备外，还集成了对应的数据分析软件<code>cell ranger</code></h1><ul><li>scRNA_seq:单细胞转录组测序简介</li><li>使用cell ranger拆分10X单细胞转录组原始数据</li><li>使用cell ranger进行单细胞转录组定量分析</li><li>cell ranger分析结果详细解读</li><li>使用Loupe Cell Browser查看10X单细胞转录组分析结果</li></ul><h1 id="2-除了cell-ranger外，还有一些下游分析的R包"><a href="#2-除了cell-ranger外，还有一些下游分析的R包" class="headerlink" title="2. 除了cell ranger外，还有一些下游分析的R包:"></a>2. 除了cell ranger外，还有一些下游分析的R包:</h1><ul><li>Seurat:用于分析10X单细胞转录组数据的R包</li><li>单细胞转录组中的pseudotime究竟是什么</li><li>使用scater包对单细胞转录组数据进行降维分析</li><li>使用Rtsne包进行t-SNE降维分析</li><li>使用monocle包进行pseudotime分析</li></ul><p>单细胞转录组技术在发育进化， 肿瘤等疾病的研究领域有着广泛的应用前景，以上的资料只能算是基础概念的扫盲，更多的高级分析还需要深入学习。</p>]]></content>
      
      
      <categories>
          
          <category> single cell数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> scRNA_seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>sci-hub客户端V5.0</title>
      <link href="/2019-11-04-sci-hub-ke-hu-duan-v5-0/"/>
      <url>/2019-11-04-sci-hub-ke-hu-duan-v5-0/</url>
      
        <content type="html"><![CDATA[<p>SCI-HUB客户端 V5.0版强势来袭，免费下载99.9%的文献~</p><span id="more"></span><!-- toc --><hr><h1 id="SCI-HUB客户端（文献神器v5-0）介绍："><a href="#SCI-HUB客户端（文献神器v5-0）介绍：" class="headerlink" title="SCI-HUB客户端（文献神器v5.0）介绍："></a>SCI-HUB客户端（文献神器v5.0）介绍：</h1><center><img src="/2019-11-04-sci-hub-ke-hu-duan-v5-0/1.png" class=""></center><center>文献神器V5.0界面截图</center>- 国内唯一免费下载国内外文献的软件- 你看它小巧玲珑，功能强大，仅489kb- 不仅能下载国内文献，又能下载国外文献。- 被广大研究生誉为文献神器！<h1 id="SCI-HUB客户端（文献神器v5-0）功能："><a href="#SCI-HUB客户端（文献神器v5-0）功能：" class="headerlink" title="SCI-HUB客户端（文献神器v5.0）功能："></a>SCI-HUB客户端（文献神器v5.0）功能：</h1><ul><li>可以可以下载Sci-hub数据库内的全部文献</li><li>提供了<font color=red size=5>谷歌学术入口，谷歌镜像入口，知网文献免费下载入口，百度文库原格式文档下载入口</font>。这款软件不仅可以下载国外数据库文献，国内的数据库文献也可以下载！</li><li>软件检索文献速度超级快，输入DOI号即可秒下文献。再也不用到处寻找sci-hub网址啦，软件包含自动检测sci-hub网址功能，保证你能够及时下载到文献。无论你的电脑是xp&#x2F;win7&#x2F;win8&#x2F;win10系统，32位或者64位，都可使用本软件免费下载文献。</li></ul><h1 id="SCI-HUB客户端（文献神器v5-0）下载文献教程"><a href="#SCI-HUB客户端（文献神器v5-0）下载文献教程" class="headerlink" title="SCI-HUB客户端（文献神器v5.0）下载文献教程"></a>SCI-HUB客户端（文献神器v5.0）下载文献教程</h1><img src="/2019-11-04-sci-hub-ke-hu-duan-v5-0/3.png" class=""><img src="/2019-11-04-sci-hub-ke-hu-duan-v5-0/4.png" class=""><p>查询到文献DOI号后，直接在SCI-HUB搜索栏输入DOI号点击<font color=blue size=5>【立即下载】</font></p><p>希望这款高效的论文下载软件能让你的科研之路如虎添翼，不再为下载文献而烦恼，快来体验吧！</p><center><img src="/2019-11-04-sci-hub-ke-hu-duan-v5-0/6.png" class=""></center><p><font color=green size=5>文献神器v5.0版本下载地址</font>：<a href="http://www.9312.net/download.html">http://www.9312.net/download.html</a></p>]]></content>
      
      
      <categories>
          
          <category> sci-hub </category>
          
      </categories>
      
      
        <tags>
            
            <tag> sci-hub </tag>
            
            <tag> 免费下载文献 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Juicer软件的安装详解</title>
      <link href="/2019-11-02-juicer-ruan-jian-de-an-zhuang-xiang-jie/"/>
      <url>/2019-11-02-juicer-ruan-jian-de-an-zhuang-xiang-jie/</url>
      
        <content type="html"><![CDATA[<p>Juicer软件的安装详解</p><span id="more"></span><!-- toc --><hr><p>软件安装是生物信息实战中最基础的技能之一，只有确保软件安装无误，后续使用起来才会得心应手，不会有很多的bug。juicer软件提供了Hi-C数据一键化分析的pipeline, 这样高度的封装使得用户操作起来更加简便，当然分析能力强大的同时其依赖的软件就会越多，安装过程的复杂程度也会有所提高，本文主要记录下该软件的安装过程，可以分为以下几个步骤</p><ol><li><p>安装依赖软件<br>juicer核心采用java语言进行开发，同时内置了perl, python, bash等开发的脚手架脚本。在序列比对环节使用了bwa软件，而后续操作比对产生的bam文件，会用到samtools软件。所以需要安装以下软件</p><ul><li>java</li><li>perl</li><li>python</li><li>GNU utils</li><li>bwa</li><li>samtools<br>这些软件是生信领域的基本软件，其安装过程就不详细展开了。</li></ul></li><li><p>建立目录结构<br>juicer软件要求一个固定的目录结构，新建一个名为juicer的目录，该目录即为软件的安装目录，在该目录下必须有以下4个子目录</p><img src="/2019-11-02-juicer-ruan-jian-de-an-zhuang-xiang-jie/1.png" class="" title="This is an test image"></li></ol><p><code>references</code>目录用于存放参考基因组相关文件，<code>work</code>用于存放样本的序列文件和分析结果，<code>scripts</code>用于存放软件运行所需的脚本，<code>restriction_sites</code>用于存放参考基因组酶切图谱。</p><ol start="3"><li>下载juicer源代码<br>从github上下载juicer和jcuda的源代码，放置到<code>scripts</code>目录下。juicer可以在单机或者集群系统上运行，其中间脚本也对应了不同的系统，示意如下<img src="/2019-11-02-juicer-ruan-jian-de-an-zhuang-xiang-jie/2.png" class="" title="This is an test image">其中的CPU目录就是单机服务器，而AWS, LSF, PBS等对应公有云和不同的集群系统。以CPU为例，下载过程如下:</li></ol><pre><code># 下载源代码git clone https://github.com/aidenlab/juicer.git# 重命名为scripts目录ln -s juicer/CPU scriptscd scripts/commonwget https://hicfiles.tc4ga.com/public/juicer/juicer_tools.1.9.9_jcuda.0.8.jarln -s juicer_tools.1.9.9_jcuda.0.8.jar  juicer_tools.jar</code></pre><ol start="4"><li>准备参考基因组文件<br>在<code>reference</code>目录下为参考基因组相关文件，其实就是对应的fasta序列文件和bwa 索引，示意如下:</li></ol><pre><code>hg19.fastahg19.fasta.sahg19.fasta.annhg19.fasta.ambhg19.fasta.pachg19.fasta.bwt</code></pre><p>自己根据需要从UCSC,NCBI等数据库中下载基因组fasta文件，并用bwa建立索引就可以了。</p><p>在<code>restriction_sites</code>目录下参考基因组酶切图谱，通过jucier内置的<code>generate_site_positions.py</code>脚本可以产生，该脚本位于源代码中的misc目录下，支持直接输出以下4种内切酶的酶切图谱</p><ol><li>HindIII</li><li>DpnII</li><li>MboI</li><li>Sau3AI</li></ol><p>用法如下:</p><pre><code>generate_site_positions.py HindIII hg19  hg19.fasta</code></pre><p>第一个参数为内切酶的名称，第二个参数为自定义的基因组版本，第三个参数为基因组fasta文件的路径，输出文件的名称为第二个参数和第一个参数用下划线链接，后缀为<code>txt</code>, 上述代码的输出文件为</p><pre><code>hg19_HindIII.txt</code></pre><ol start="5"><li>准备样本的fastq序列<br>执行完前4步软件就已经安装好了，软件运行时对样本文件的存放位置也有要求，必须位于<code>work</code>目录下，以样本名作为一个子目录，序列文件存放于<code>fastq</code>目录下，示意如下:</li></ol><pre><code>/opt/juicer/work/MBR19/fastq/opt/juicer/work/MBR19/fastq/chr19_R1.fastq.gz/opt/juicer/work/MBR19/fastq/chr19_R2.fastq.gz</code></pre><p>关于安装成功后的目录结构，可以参考以下链接:<br><a href="https://bcm.app.box.com/v/juicerawsmirror/folder/11284128669">https://bcm.app.box.com/v/juicerawsmirror/folder/11284128669</a></p><p>juicer的安装过程算不上复杂，就是注意事项有很多，操作起来较为繁琐，只需要按照以上步骤耐心操作，还是可以快速安装成功的。</p>]]></content>
      
      
      <categories>
          
          <category> Hi-C数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hi-C </tag>
            
            <tag> Juicer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Juicer:Hi-C数据处理分析的利器</title>
      <link href="/2019-11-02-juicer-hi-c-shu-ju-chu-li-fen-xi-de-li-qi/"/>
      <url>/2019-11-02-juicer-hi-c-shu-ju-chu-li-fen-xi-de-li-qi/</url>
      
        <content type="html"><![CDATA[<p>Juicer:Hi-C数据处理分析的利器</p><span id="more"></span><!-- toc --><hr><p>通过Hi-C数据可以分析TAD,chromatin loops等染色质空间结构的基本单元，加强我们对染色质三维结构的认知。面对海量的Hi-C数据，如何高效完成数据分析成为了一个挑战。</p><p>目前针对Hi-C数据的分析也有很多的软件可以用，而juicer无疑是使用的最广泛的软件之一。该软件的源代码托管在github上，网址如下</p><p><a href="https://github.com/aidenlab/juicer">https://github.com/aidenlab/juicer</a></p><p>对应的文章发表在cell杂志上，链接如下</p><p><a href="https://www.cell.com/action/showPdf?pii=S2405-4712(16)30219-8">https://www.cell.com/action/showPdf?pii=S2405-4712%2816%2930219-8</a></p><p>如下图所示，和其名字一样，juicer就像是一款榨汁机，输入Hi-C产生的原始fastq数据，经过层层加工，直到产生有效的数据分析结果。在整个数据分析过程中，使用者不需要高深的编程技巧，只需要一些基本的操作规范，人人都可以使用该软件来分析Hi-C数据。</p><img src="/2019-11-02-juicer-hi-c-shu-ju-chu-li-fen-xi-de-li-qi/1.png" class=""><p>juicer作为一款强大的分析软件，有以下几个特点:</p><ol><li><p>可以分析处理TB级别的海量数据，可以有效利用FPGA, GPU，集群等硬件资源来加速处理速度</p></li><li><p>提供了数据预处理，交互图谱创建和可视化，TAD和染色质环结构预测等一些列完整的pipeline</p></li><li><p>简单易用，不需要复杂的背景知识<br>该软件按照功能拆分成了三个大的分析步骤，依次运行即可得到最终的分析结果:</p></li><li><p>数据预处理，将原始的fastq序列比对参考基因组，识别其中的valid pairs, 并生成一个后缀为hic的文件</p></li><li><p>读取hic文件，创建可视化的交互图谱，也称之为contact map, 并进行归一化</p></li><li><p>采用算法预测TAD和染色质环等结构<br>完整功能示意如下：</p><img src="/2019-11-02-juicer-hi-c-shu-ju-chu-li-fen-xi-de-li-qi/2.png" class=""></li></ol><p>juicer采用ArrowHead算法对原始的交互矩阵进行转化，并预测TAD拓扑关联结构域，采用HiCUUPS算法识别染色质环chromatin loops。和其他Hi-C数据处理软件相比，juicer的功能更为齐全</p><img src="/2019-11-02-juicer-hi-c-shu-ju-chu-li-fen-xi-de-li-qi/3.png" class=""><p>juicer独创了一种名为hic的文件格式，用来存储Hi-C数据的相关信息，这种格式是一种高度压缩的二进制文件格式，在以下链接可以查看这种格式的详细信息</p><p><a href="https://github.com/theaidenlab/juicebox/blob/master/HiC_format_v8.docx">https://github.com/theaidenlab/juicebox/blob/master/HiC_format_v8.docx</a></p><p>在后续的文章中，会详细介绍该软件的用法。</p>]]></content>
      
      
      <categories>
          
          <category> Hi-C数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hi-C </tag>
            
            <tag> Juicer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用HiCUP进行Hi-C数据预处理 </title>
      <link href="/2019-11-02-shi-yong-hicup-jin-xing-hi-c-shu-ju-yu-chu-li/"/>
      <url>/2019-11-02-shi-yong-hicup-jin-xing-hi-c-shu-ju-yu-chu-li/</url>
      
        <content type="html"><![CDATA[<p>使用HiCUP进行Hi-C数据预处理</p><span id="more"></span><!-- toc --><hr><p>HiCUP是一款经典的Hi-C数据预处理软件，官网如下</p><ul><li><a href="https://www.bioinformatics.babraham.ac.uk/projects/hicup/">https://www.bioinformatics.babraham.ac.uk/projects/hicup/</a></li></ul><p>数据处理的流程示意如下:</p><img src="/2019-11-02-shi-yong-hicup-jin-xing-hi-c-shu-ju-yu-chu-li/1.png" class=""><p>首先通过<code>hicup_truncater</code>识别原始序列中的<code>junction reads</code>, 最典型的Hi-C的reads如下所示:</p><img src="/2019-11-02-shi-yong-hicup-jin-xing-hi-c-shu-ju-yu-chu-li/2.png" class=""><p>R1和R2来自两个不同的fragments, 当然这取决于插入偏度长度和读长的关系，当连接点与fragment两端的距离小于测序读长是，会发生下图所示的情况:</p><img src="/2019-11-02-shi-yong-hicup-jin-xing-hi-c-shu-ju-yu-chu-li/3.png" class=""><p>其中一端的序列是一个嵌合体序列，这样的序列在后续比对时会被过滤掉。为了保留这部分有效reads,<code>hicup_truncater</code>根据酶切位点的特征来识别所有reads上的连接位点，从而识别上图中的嵌合体序列，并对这样的序列末端进行切割，切除多余的嵌合体序列。切割完之后，这样的序列和普通的R1,R2就一样了，可以进行后续的mapping。</p><p>hicup_mapper将双端reads与参考基因组比对，由于Hi-C文库的R1和R2来源于空间结构近的染色质，其线性距离比传统的双端测序插入片段的长度大的多，如果直接进行双端比对，觉得部分reads都比对不上参考基因组，所以这里是对每一端的序列分别比对，然后再进行合并。</p><p><code>hicup_filter</code>对比对上的序列进行过滤，如下图所示:</p><img src="/2019-11-02-shi-yong-hicup-jin-xing-hi-c-shu-ju-yu-chu-li/4.png" class=""><p>只保留valid di-tags, 其他诸如<code>selft-ligation</code>, <code>Re-ligation</code>等片段都会被过滤掉。</p><p><code>hicup_deduplicator</code>用来去除PCR重复，因为valid reads的多少用来表征染色质互作的频率，PCR重复的reads数量会对这个信息造成干扰，如果不去除PCR重复，junction reads的数目多可能是PCR重复多，不一定是因为染色质交互频率强而导致的reads多。</p><p>软件的安装也很方便，直接下载解压缩即可。使用步骤如下</p><ol><li><p>准备参考基因组的索引文件<br>所有的参考基因组比对软件都需要事先对基因组建立索引，HiCUP支持使用<code>bowtie</code>或<code>bowtie2</code>进行比对，以<code>bowtie2</code>为例，建立基因组索引的方式如下:<br><code>bowite2-build hg19.fa hg19</code><br>第一个参数是基因组的fasta文件，第二个参数是输出的索引文件的名称。</p></li><li><p>准备参考基因组酶切位点图谱<br>采用hicup_digester这个脚本来创建基因组的酶切图谱，基本用法如下:</p></li></ol><pre><code>hicup_digester \    --re1 A^AGCTT,HindIII \    --genome hg19_digester_db \    hg19.fa</code></pre><p>根据限制性内切酶识别的位点，将基因组序列进行模拟酶切，得到所有可能的酶切片段。<code>--re1</code>指定切割位点的序列和内切酶的名字，<code>--genome</code>指定输出文件的名称。最终输出的文件名示例如下:<br><code>Digest_hg19_digester_db_HindIII_None_09-46-07_17-05-2019.txt</code><br>3. 编辑配置文件<br>首先通过如下命令生成一个配置文件的模板</p><pre><code>hicup --example</code></pre><p>该命令会生成一个名为<code>hicup_example.conf</code>的文件，在此基础上进行编辑就可以了。在配置中对每个选项都体用了详细的注释，根据需求修改即可。常用的修改的选项如下：</p><pre><code>#Path to the reference genome indices#Remember to include the basename of the genome indicesIndex: /bi/scratch/Genomes/Human/GRCh38/Homo_sapiens.GRCh38#Path to the genome digest file produced by hicup_digesterDigest: /bi/scratch/Genomes/Human/GRCh38/Digest_Homo_sapiens_GRCh38_HindIII_None_14-43-31_10-02-2016.txt.gz#FASTQ files to be analysed, placing paired files on adjacent liness_1_1_sequence.fastq.gzs_1_2_sequence.fastq.gz</code></pre><p>包括基因组索引和酶切图谱的路径，以及需要处理的Hi-C原始fastq文件的路径。</p><ol start="4"><li>运行<br>准备好配置文件之后，就可以运行了，用法如下</li></ol><pre><code>hicup --config hicup.conf</code></pre><p>在输出结果的目录会生成一个html文件，展示了质控的各项指标，内容如下所示</p><ul><li><strong>1. Truncating and Mapping</strong><img src="/2019-11-02-shi-yong-hicup-jin-xing-hi-c-shu-ju-yu-chu-li/5.png" class=""></li><li><strong>2. Filtering</strong><br>示意如下，可以看到valid  pairs的比例在50%左右<img src="/2019-11-02-shi-yong-hicup-jin-xing-hi-c-shu-ju-yu-chu-li/6.png" class=""></li><li><strong>3. Length Distribution</strong><img src="/2019-11-02-shi-yong-hicup-jin-xing-hi-c-shu-ju-yu-chu-li/7.png" class=""></li><li><strong>4. De-dupliation</strong><img src="/2019-11-02-shi-yong-hicup-jin-xing-hi-c-shu-ju-yu-chu-li/8.png" class="">除此之外，输出目录还有很多的文件，其中后缀为hicup_bam的文件包含了最终的de-duplication之后的reads的比对结果，可以用于下游的分析。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Hi-C数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hi-C </tag>
            
            <tag> HiCUP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Promoter Capture Hi-C:研究启动子区染色质互作的利器</title>
      <link href="/2019-11-02-promoter-capture-hi-c-yan-jiu-qi-dong-zi-qu-ran-se-zhi-hu-zuo-de-li-qi/"/>
      <url>/2019-11-02-promoter-capture-hi-c-yan-jiu-qi-dong-zi-qu-ran-se-zhi-hu-zuo-de-li-qi/</url>
      
        <content type="html"><![CDATA[<p>Promoter Capture Hi-C:研究启动子区染色质互作的利器</p><span id="more"></span><!-- toc --><hr><p>Hi-C文库一次可以获取全基因组范围内互作的染色质片段，可以从全基因组的高度来研究染色质的空间结构特征。在Hi-C图谱中，染色质互作频率通过两个bin之间junction reads的数量来表示，和测序深度的概念类似，只有达到一定量的测序深度时才能够认为其代表的染色质互作信息是可靠的。</p><p>通常情况下，可以用于构建Hi-C图谱的有效reads的比例在50%左右，这样的一个利用率就要求原始的测序量相比其他组学要更多。</p><p>同时对于Hi-C图谱又有一个分辨率的说法，不同分辨率用于分析和识别不同层级的染色质结构，目前一个常用的说法是只有保证80%的bin之间的junction reads的个数在1000以上时，才表明数据适用于bin长度对应的分辨率。</p><p>目前测序深度和分辨率之间并没有一个明确的对应关系，根据经验值，测序深度在100X时，分辨率可以得到40kb左右，这样的一个分辨率也仅仅能达到TAD分析的要求，25kb和5kb分辨率对于测序深度的要求就更高了。</p><p>实验有效率和数据分辨率的要求都使得Hi-C文库的测序量必须非常的大，这样仅仅测序成本就非常的高了。</p><p>如果仅仅只是分析部分染色质片段之间的互作，最经典的莫过于研究promoter与其他染色质片段的互作，比如研究enhancer-promoter的互作，此时利用全基因组的Hi-C文库代价太大，而传统的3C,4C又无法满足要求。基于这样的一个需求驱动，Promoter Capture Hi-C技术应用而生。</p><p>Capture Hi-C技术就是在传统Hi-C文库的基础上，新增了一个捕获的过程，捕获目的片段用于后续的测序。Hi-C和Capture Hi-C的关系就好比全基因组测序和全外显子测序，Hi-C可以得到更加全面的信息，但是代价高昂，而Capture Hi-C只针对目标区域进行研究，同样的测序成本可以达到更高的测序深度，信息更加可靠，更加经济适用。</p><p>Promoter Capture Hi-C的文库构建示意如下:</p><img src="/2019-11-02-promoter-capture-hi-c-yan-jiu-qi-dong-zi-qu-ran-se-zhi-hu-zuo-de-li-qi/1.png" class=""><p>核心就是在Hi-C文库之后，用设计的探针捕获promoter相关的reads,然后在进行测序。在测序深度足够的情况下，可以直接得到启动子区与其他染色质片段互作的可靠信息。</p><p>如果只想通过Hi-C技术来研究启动子的互作，Promoter Capture Hi-C无疑是更好的选择。</p>]]></content>
      
      
      <categories>
          
          <category> Hi-C数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hi-C </tag>
            
            <tag> Promoter Capture Hi-C </tag>
            
            <tag> 启动子区染色质互作 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>chromatin loops:染色质环简介</title>
      <link href="/2019-11-02-chromatin-loops-ran-se-zhi-huan-jian-jie/"/>
      <url>/2019-11-02-chromatin-loops-ran-se-zhi-huan-jian-jie/</url>
      
        <content type="html"><![CDATA[<p>chromatin loops:染色质环简介</p><span id="more"></span><!-- toc --><hr><p>利用5kb分辨率的Hi-C基因组互作图谱，科学家识别到了chromatin loop这种染色质结构，文章发表在cell上,标题如下:<br>**<a href="https://www.cell.com/fulltext/S0092-8674(14)01497-401497-4">A 3D Map of the Human Genome at Kilobase Resolution Reveals Principles of Chromatin Looping</a></p><p>通过对不同分辨率的Hi-C图谱进行分析，检测到了不同层级的染色质结构，从高到低依次为A&#x2F;B compartments, subcompartments, TAD, chromation loop。Hi-C图谱和染色质结构模型的对应关系如下:</p><p>早期研究中利用1MB的Hi-C图谱 ，定义了每条染色质包含了A和B两个compartments。该文章中对100kb分辨率的Hi-C图谱进行聚类分析，发现A&#x2F;B compartments进一步分成了6个子类，即subcompartments。对每条染色质的Hi-C图谱进行不同算法的聚类分析，除了19号染色质外，都得到了5个cluster，对于19号染色质，得到了6个cluster。</p><p>通过分析这些subcompartments与A&#x2F;B compartments的关系，发现其中2个属于A compartments, 标记为A1和A2, 另外4个属于B comprtmants, 标记为B1, B2, B3, B4。</p><p>对于TAD拓扑关联结构域的识别，首创了一种<code>ArrowHead</code>算法，核心是对归一化之后的交互矩阵进行变换，变化的公式如下:</p><img src="/2019-11-02-chromatin-loops-ran-se-zhi-huan-jian-jie/8.png" class=""><p>和DI的算法类似，i-d和i+d分别代表上下游的两个bin, 如果i和上游bin互作频率高，则A值为正数，如果和下游bin互作频率高，则A值为负数，如果相等，则为0。示意如下:</p><img src="/2019-11-02-chromatin-loops-ran-se-zhi-huan-jian-jie/2.png" class=""><p>A图中的正方形区域为一个TAD domain, 经过转换后，变成了图B所示的形状。对应到整个互作矩阵上，看上去就是图E所示的箭头型。利用动态规划算法，识别变换后矩阵中的箭头区域，就可以预测TAD domain。文章中识别到的TAD domain,长度在40kb-3Mb，中位数为185kb。</p><p>对于染色质环，定义为Hi-C图谱中互作频率比周围相邻区域都高的格子区域，这样的区域称之为peak , 而对应的染色质区域称之为peak loci，如下图中蓝色圆点标记的区域:</p><img src="/2019-11-02-chromatin-loops-ran-se-zhi-huan-jian-jie/3.png" class=""><p>如上图所示，通过与四周区域的交互频率进行比较鉴定peak区域，这要去HI-C图谱的分辨率在5kb以下。对于全基因组互作图谱而言，这个计算量是非常大的，文章作者也提供了一种名为HiCCUPS的算法，集成在了开发的juicer软件中。</p><p>进一步比较不同细胞系和不同物种间的染色质环区域，结果如下:</p><img src="/2019-11-02-chromatin-loops-ran-se-zhi-huan-jian-jie/4.png" class=""><img src="/2019-11-02-chromatin-loops-ran-se-zhi-huan-jian-jie/5.png" class=""><p>发现在不同细胞系间相对稳定，在物种间也具有一定进化保守性。对染色质环的分布位置进行分析，发现其处于TAD边界处。进一步分析发现染色质环中有很大部分为promoter-enhancer loops， 这也解释了增强子对靶基因的调控机制，虽然增强子与靶基因线性距离很远，但是增强子与靶基因启动子位于一个染色质环上，空间距离近，通过与启动子结合调控靶基因。</p><p>对染色质环对应区域富集的各种mark进行分析，发现其富集CTCF等转录因子, 如下图所示:</p><img src="/2019-11-02-chromatin-loops-ran-se-zhi-huan-jian-jie/6.png" class=""><p>对于染色质环的空间结构，提出了如下模型:</p><img src="/2019-11-02-chromatin-loops-ran-se-zhi-huan-jian-jie/7.png" class=""><p>通过构建5kb以下分辨率的Hi-C图谱，可以识别染色质环这种染色质结构单元。</p>]]></content>
      
      
      <categories>
          
          <category> Hi-C数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hi-C </tag>
            
            <tag> chromatin loops </tag>
            
            <tag> 染色质环 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TAD:拓扑关联结构域简介</title>
      <link href="/2019-11-02-tad-tuo-bu-guan-lian-jie-gou-yu-jian-jie/"/>
      <url>/2019-11-02-tad-tuo-bu-guan-lian-jie-gou-yu-jian-jie/</url>
      
        <content type="html"><![CDATA[<p>TAD: 拓扑关联结构域简介</p><span id="more"></span><!-- toc --><hr><p>利用更低分辨率的Hi-C基因组互作图谱，科学家对染色质空间结构的了解不断深入。本文主要介绍<code>TAD</code>这种结构，<code>TAD</code>全称如下<strong>Topologically Assocaited Domain</strong><br>中文译作<strong>拓扑关联结构域</strong>，是一种首先在哺乳动物细胞中发现的染色质结构单元，对应的文章发表在<code>nature</code>上，文章标题如下：<br><strong><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3356448/">Topological Domains in Mammalian Genomes Identified by Analysis of Chromatin Interactions</a></strong><br>将Hi-C基因组互作图谱的分辨率提高到100kb以下，发现了互作图谱中出现了一些self-interaction的区域，示意如下:</p><img src="/2019-11-02-tad-tuo-bu-guan-lian-jie-gou-yu-jian-jie/1.png" class=""><p>基因组互作图谱本质是一个对称矩阵，对角线两侧的信息是相等的。上图中只取了原始方阵中对角线一侧的信息，所以看上去是一个大的三角形，三角形的底边对应的是原始方阵中的对角线部分。</p><p>在上图中，互作强度由弱到强，单元格的颜色由白色过渡到红色。可以看到，在底边出重复出现了一些小的三角形区域，这些区域内部几乎全部是红色，说明这些区域内部的染色质片段间的互作频率高，这样的区域称之为self-interaction区域，而相邻的三角形区域间的互作频率较低，如下图所示:</p><img src="/2019-11-02-tad-tuo-bu-guan-lian-jie-gou-yu-jian-jie/2.png" class=""><p>红色三角形区域对应TAD内部区域的互作信息，而黑色区域对应TAD之间的互作信息。呈现到三角形的互作图谱上，对应的就是底边上有很多红色的小三角形，而三角形对应的互作区域则都为白色，科学家将这种重复出现的内部互作频率高，组间互作频率低的domain定义为<strong>topologically assocaited domain</strong>, 简称TAD，对应下图中的模型:</p><img src="/2019-11-02-tad-tuo-bu-guan-lian-jie-gou-yu-jian-jie/3.png" class=""><p>A和B对应两个TAD, 在TAD之间存在了一个边界，称之为TAD  doundary。为了准确地识别染色质中的TAD,定义了一种directionality index的统计量，简称DI，公式如下:</p><img src="/2019-11-02-tad-tuo-bu-guan-lian-jie-gou-yu-jian-jie/4.png" class=""><p>将分辨率降低到40kb,对于每个40kb的bin来说，A代表这个bin与上游2MB区域的互作reads, B代表这个bin与下游2MB区域的互作reads,E代表A和B的均值，采用类似卡方检验统计量的算法。空假设是这个bin与上游和下游的互作频率相同。如果与上下游的互作频率一致，则DI的值趋近于0。如下图所示:</p><img src="/2019-11-02-tad-tuo-bu-guan-lian-jie-gou-yu-jian-jie/5.png" class=""><p>可以看到从TAD的开始到终止，DI的值会有一个从正值逐渐减小到0，然后变为负值，在不断减小的情况。在TAD边界处，DI的值突然趋近于0，因为边界处与上下游的互作频率几乎相同，根据DI的这一分布规律，再结合隐马尔可夫模型，最终在小鼠胚胎干细胞中识别到了2200多个TAD区域，长度的平均值为880kb。</p><p>进一步分别对人和小鼠两种不同细胞系中的TAD进行识别和分析，发现TAD在不同细胞或者组织中相对稳定，在不同物种间也具有一定的保守性，结果如下图所示:</p><img src="/2019-11-02-tad-tuo-bu-guan-lian-jie-gou-yu-jian-jie/6.png" class=""><p>为了进一步探究TAD在染色质上的分布特征，科学家分析了TAD边界内各种mark的分布情况。首先是CTCF，结果如下所示:</p><img src="/2019-11-02-tad-tuo-bu-guan-lian-jie-gou-yu-jian-jie/7.png" class=""><p>发现在TAD边界处存在CTCF的富集，但并不是说所有的CTCF都集中出现在TAD边界处，所以进一步由探究了其他mark，包括各种组蛋白修饰等的分布，结果如下:</p><img src="/2019-11-02-tad-tuo-bu-guan-lian-jie-gou-yu-jian-jie/8.png" class=""><p>发现H3K4me3，H3K36me3, TSS， SINE重复元件等都有富集。进一步分析了基因的分布情况，结果如下</p><img src="/2019-11-02-tad-tuo-bu-guan-lian-jie-gou-yu-jian-jie/9.png" class=""><p>发现管家基因在TAD边界处存在富集。</p><p>通过40kb分辨率的Hi-C互作图谱，鉴定到了TAD这种在哺乳动物中存在的相对稳定，且具有一定进化保守性的染色质结构单元。</p>]]></content>
      
      
      <categories>
          
          <category> Hi-C数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hi-C </tag>
            
            <tag> TAD </tag>
            
            <tag> 拓扑结构域 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A/B compartment:染色质区室简介</title>
      <link href="/2019-11-02-a-b-compartment-ran-se-zhi-qu-shi-jian-jie/"/>
      <url>/2019-11-02-a-b-compartment-ran-se-zhi-qu-shi-jian-jie/</url>
      
        <content type="html"><![CDATA[<p>A&#x2F;B compartment:染色质区室简介</p><span id="more"></span><!-- toc --><hr><p>Hi-C技术的出现推动了三维基因组学的发展，利用Hi-C技术，科学家不仅证实了染色质疆域的存在，而且进一步发现了更多染色质的三维特征。</p><p>Lieberman-Aiden等人利用Hi-C技术研究了人淋巴母细胞的三维结构，首次提出了A&#x2F;B compartment的概念，文章发表在science上，标题如下:<br><strong><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2858594/">Comprehensive Mapping of Long-Range Interactions Reveals Folding Principles of the Human Genome.Science. 2009 Oct 9; 326(5950): 289–293.</a></strong></p><p>构建1Mb分辨率下的基因组互作图谱，然后采用Oberved&#x2F;Expected的算法对交互矩阵进行归一化，对归一化之后的矩阵计算泊松相关系数，矩阵对应的热图示意如下:</p><img src="/2019-11-02-a-b-compartment-ran-se-zhi-qu-shi-jian-jie/1.png" class=""><p>在归一化后的交互矩阵热图中，蓝色代表观测到的交互频率小于期望的交互频率，红色代表观测到的交互频率大于期望的交互频率。在相关系数矩阵的热图中，相关系数从-1到1，颜色从蓝色过渡到红色。</p><p>对相关系数矩阵进行PCA降维分析，在第一主成分PC1轴上，可以将染色质区域明确分成两个部分，称之为A&#x2F;B compartment。对应下图Eigenvector正负两个部分:</p><img src="/2019-11-02-a-b-compartment-ran-se-zhi-qu-shi-jian-jie/2.png" class=""><p>通过对正负区域对应的基因表达量，组蛋白修饰，DNase酶超敏位点情况研究发现，发现在正数区域，包含的基因较多，对应的基因表达量相对较高，H3K36me3和DNA超敏位点的信号也相对较高，这些特征都表明这些区域是更加开放的，可接近的，转录激活的区域，将这个区域定义为A compartment, 对应开放染色质区域；而负数对应区域包含的基因个数较少，含量也低，将其定义为B  compartment, 对应封闭染色质区域。</p><p>后续文章也都基于这个思路来研究A&#x2F;B compartment，现在已有很多成熟的软件可以使用，比如juice，homer 等，之后会详细介绍其用法。</p>]]></content>
      
      
      <categories>
          
          <category> Hi-C数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hi-C </tag>
            
            <tag> A/B compartment </tag>
            
            <tag> 染色质区室 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解密Hi-C数据分析中的分辨率</title>
      <link href="/2019-11-02-jie-mi-hi-c-shu-ju-fen-xi-zhong-de-fen-bian-lu/"/>
      <url>/2019-11-02-jie-mi-hi-c-shu-ju-fen-xi-zhong-de-fen-bian-lu/</url>
      
        <content type="html"><![CDATA[<p>解密Hi-C数据分析中的分辨率</p><span id="more"></span><!-- toc --><hr><p>Hi-C基于传统的染色质构象捕获技术，在DNA连接时引入生物素标记分子，标记交联的染色质，然后富集带有生物素标记的junction reads,  再结合高通量测序和下游的生物信息学分析，可以在全基因组范围内研究染色质的空间互作关系。</p><p>在Hi-C文库中，我们得到的是互作染色质形成的<strong>junciton reads</strong>, 通过将这些reads 比对到参考基因组之后，可以分析染色质之间的互作。以下图为例：</p><img src="/2019-11-02-jie-mi-hi-c-shu-ju-fen-xi-zhong-de-fen-bian-lu/1.png" class=""><p>图中蓝色和红色对应的染色质区域有互作，黑色和黄色对应的染色质区域有互作，在对应的Hi-C文库中，我们可以得到如下所示的junction reads</p><img src="/2019-11-02-jie-mi-hi-c-shu-ju-fen-xi-zhong-de-fen-bian-lu/2.png" class=""><p>将这些reads正确比对到参考基因组上之后，就可以确定对应的染色质区域之间存在互作，而对应的junction reads的数目越多，则代表两个区域交互作用发生的频率越高。</p><img src="/2019-11-02-jie-mi-hi-c-shu-ju-fen-xi-zhong-de-fen-bian-lu/3.png" class=""><p>对于所有区域的互作信息，通常会用一个交互矩阵interaction matirx来表示，该矩阵是一个方阵，每一行或者列都代表一个染色质区域，方格的颜色代表代表两个区域交互作用的强弱，示意如下：</p><img src="/2019-11-02-jie-mi-hi-c-shu-ju-fen-xi-zhong-de-fen-bian-lu/4.png" class=""><p>在构建矩阵的过程中，我们首先需要确定每一行代表的染色质区域的范围，互作的片段是通过酶切来得到的, 理论上存在10的11方种唯一的酶切片段。如果想要精确分析所有酶切片段之间的交互，首先需要足够的测序深度，涵盖所有类型的酶切片段，这就要求非常庞大的测序数据量，其次对于如此庞大的交互矩阵，数数据分析阶段对于计算资源的消耗也是一个天文数字。</p><p>为了有效利用Hi-C文库中的信息，科学家提出了binning的概念，将基因组划分为等长的窗口，这样的窗口称之为bin, 利用窗口内reads的分布来研究不同窗口之间的互作关系。这样的处理相比最原始，最直接的染色质互作数据，其分辨率确实是有一定程度的丢失，但是基于全基因组范围，仍然能够挖掘出很多有效信息。</p><p>bin窗口的长度称之为分辨率。如果分辨率为1Mb,  以人类基因组为例，在交互矩阵中会有3000左右的行。bin窗口的长度越小，则基因组区域的划分越细致，对于染色质三维构象的研究的就越精细。</p><p>不同分辨率对于测序量的要求不同，适用的场景也不同。基于不同分辨率的Hi-C数据，陆续发现了A&#x2F;B  compartments, TAD拓扑结构域，染色质环等空间结构。</p>]]></content>
      
      
      <categories>
          
          <category> Hi-C数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hi-C </tag>
            
            <tag> 分辨率 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3C的衍生技术简介</title>
      <link href="/2019-11-02-3c-de-yan-sheng-ji-zhu-jian-jie/"/>
      <url>/2019-11-02-3c-de-yan-sheng-ji-zhu-jian-jie/</url>
      
        <content type="html"><![CDATA[<p>3C的衍生技术简介</p><span id="more"></span><!-- toc --><hr><p>染色质构象捕获技术的发明，使得科学家可以通过实验手段来研究染色质的空间结构。传统的3C技术通量较低，只适用于分析one_vs_one的染色质互作，为了更加高效的进行3D基因组学的研究，科学家们在3C技术的基础上不断推陈出新，衍生出了各种技术，图示如下:</p><img src="/2019-11-02-3c-de-yan-sheng-ji-zhu-jian-jie/1.png" class=""><p><strong>4C</strong>在junction reads基础上，进行二次酶切，形成包含junction reads的环状序列，然后针对感兴趣的基因组区域，设计PCR引物，将包含该基因组区域的环状片段扩增出来，从而可以研究该基因组片段与其他片段的相互作用关系，称之为one_vs_all。</p><p><strong>5C</strong>采用事先设计好的，两端带有通用引物的探针与junction reads杂交，进行PCR扩增，PCR产物两端包含了通用引物，下游可以结合芯片或者高通量测序来分析基因组区域的互作。事先可以针对感兴趣的多个基因组区域互作设计引探针，所以5C是一种many_vs_many的研究策略。</p><p>3C,4C,5C都是基于最原始的junction reads, 不同之处就在于不同引物设计策略导致的通量的差异。</p><p><strong>Hi-C</strong>在原始3C基础上有所变化，junction reads产生过程中添加生物素标记，然后采用抗体富集带有标记的junction reads, 再构建普通的测序文库，进行高通量测序。没有了针对目标区域设计引物的限制，再结合测序的高通量特点， 使得Hi-C可以一次性研究所有染色质片段之间的互作，称之为all_vs_all。</p><p><strong>ChIP-Ioop</strong>先用抗体捕获交联的染色质片段，后续的步骤和3C一样，针对两个目标区域的互作设计引物来进行one_vs_one的研究；ChIA-PET与之类似，只不过在粘性末端连接的过程中引入一段通用的adapter序列，以此为桥梁将互作的两个染色质片段连接起来，后续在进行酶切，加接头，测序，也可以进行all_vs_all的染色质互作研究。</p><p>考虑到不同技术的成本和限制，各自有不同的应用场景，其中Hi-C和ChIA-PET技术由于其研究对象的高通量性，一次可以获取所有染色质片段互作信息，成为了最热门的3D基因组学研究技术，极大的推动了3D基因组学的发展。</p>]]></content>
      
      
      <categories>
          
          <category> Hi-C数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 3C </tag>
            
            <tag> Hi-C </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>chromosome conformation capture:染色质构象捕获技术</title>
      <link href="/2019-11-02-chromosome-conformation-capture-ran-se-zhi-gou-xiang-bu-huo-ji-zhu/"/>
      <url>/2019-11-02-chromosome-conformation-capture-ran-se-zhi-gou-xiang-bu-huo-ji-zhu/</url>
      
        <content type="html"><![CDATA[<p>chromosome conformation capture:染色质构象捕获技术</p><span id="more"></span><!-- toc --><hr><p><strong>chromosome conformation capture</strong>称之为<strong>染色质构象捕获</strong>，简写为<strong>3C</strong>, 是一种生物化学手段，可以通过实验手段来研究空间结构上相近的染色质，本文简单介绍下3C的实验过程和原理。</p><p>实验流程如下所示:</p><img src="/2019-11-02-chromosome-conformation-capture-ran-se-zhi-gou-xiang-bu-huo-ji-zhu/1.png" class=""><p>可以分成以下4个步骤</p><ol><li>crosslink chromatin, 染色质交联。通过甲醛固定细胞，可以在空间结构相邻的染色质片段之间产生共价氢键</li><li>digest crosslinked chromatin, 采用DNA限制性内切酶消化染色质，在酶切位点会形成粘性末端</li><li>ligation, 连接，通过DNA连接酶链接粘性末端</li><li>reverse crosslinking, 反交联，用蛋白酶消除DNA的交联状态</li></ol><p>通过以上步骤处理之后，可以得到不同染色质片段连接在一起的DNA，这样的片段是一个嵌合体，由来自空间结构相近的两个不同DNA片段构成，称之为junction reads。<br>通过实验处理，将三维结构上相近的染色质转换成了一维的DNA片段，所以这一技术称之为染色质构象捕获。通过分析junction reads中的不同部分分别对应哪些基因组区域，可以得到DNA之间的相互作用关系。</p><p>在传统的3C技术中，得到junction reads后，需要针对感兴趣的两个目标片段设计引物，通过PCR反应将这两个区域构成的junction reads扩增出来，通过PCR产物的有无和定量，可以评估目的片段之间相互作用关系的有无和强度。</p><img src="/2019-11-02-chromosome-conformation-capture-ran-se-zhi-gou-xiang-bu-huo-ji-zhu/2.png" class=""><p>由于需要同时考虑两个DNA片段来设计引物，所以传统的3C技术只适用于研究两个DNA片段之间的相互作用，即one-to-one， 而且受到PCR产物长度的限制，只适用于研究线性距离较近的片段之间的互作。</p><p>科学家们在3C基础上不断革新，陆续发明了4C,5C,Hi-C等等更高通量，更高分辨率的研究手段，促成了三维基因组学的兴起和发展，在后续文章中再进行介绍。</p>]]></content>
      
      
      <categories>
          
          <category> Hi-C数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hi-C </tag>
            
            <tag> chromosome conformation capture </tag>
            
            <tag> 染色质构象捕获技术 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>chromosome-territories:染色质疆域简介</title>
      <link href="/2019-11-02-chromosome-territories-ran-se-zhi-jiang-yu-jian-jie/"/>
      <url>/2019-11-02-chromosome-territories-ran-se-zhi-jiang-yu-jian-jie/</url>
      
        <content type="html"><![CDATA[<p>chromosome-territories:染色质疆域简介</p><span id="more"></span><!-- toc --><hr><p>人类基因组大小在3G左右，这么多的DNA线性排列，完全展开其长度可以达到2米，而细胞直径是微米级别的，这意味着DNA在细胞核内肯定是高度折叠的。众所周知，结构决定功能，这样的空间结构势必对于生命体复杂的功能造成了影响。</p><p>随着基因组学研究的发展，由结构基因组学过渡到功能基因组学，科学家对于基因组各种元件的功能及其调控关系有了进一步的了解，为研究基因组三维结构和基因功能之间的关系提供了坚实的基础，进而诞生了一种新的研究领域，称之为三维基因组学，专注于研究基因组的空间结构和基因表达，调控功能的关系和影响。</p><p>随着更高分辨率的显微镜的发明，科学家对于细胞组成的不断深入，于此类似，对于染色质空间结构的认知也是一个分辨率不断提高的过程。对于染色质在细胞核内的分布，最早提出的概念为<strong>chromosome territories</strong>，翻译成染色质疆域，简写为CT,也有叫做染色质边界的。</p><p>这个概念指的是染色质在细胞核内分布的并不是随机分布的，而是不同染色体占据不同的空间。科学家通过染色体损伤实验证明了这一现象，如下图所示：</p><img src="/2019-11-02-chromosome-territories-ran-se-zhi-jiang-yu-jian-jie/1.png" class=""><p>左侧的图代表染色质疆域分布模型，右侧图代表染色质随机分布模型。通过激光造成基因组的局部损伤，如果随机分布，则受损区域会分布在多个染色体上，如果是疆域模型的话，则只会集中在部分染色体。显微观察的结果如下:</p><img src="/2019-11-02-chromosome-territories-ran-se-zhi-jiang-yu-jian-jie/2.png" class=""><p>每行代表一个样本，黑色区域为损伤区域，可以看到损伤区域只集中在部分染色体上。</p><p>染色质疆域是科学家对染色质空间结构认知的第一步，在此基础上，随着染色质构建捕获技术的发明和发展，人们对染色质空间结构的认知不断加深，相继提出了拓扑结构域TAD,染色质环等更高分辨率的构成单元，示意如下:</p><img src="/2019-11-02-chromosome-territories-ran-se-zhi-jiang-yu-jian-jie/3.png" class="">]]></content>
      
      
      <categories>
          
          <category> Hi-C数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hi-C </tag>
            
            <tag> chromosome-territories </tag>
            
            <tag> 染色质疆域 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SCALE准确鉴定单细胞ATAC-seq数据中染色质开放特征</title>
      <link href="/2019-10-30-scale-zhun-que-jian-ding-dan-xi-bao-atac-seq-shu-ju-zhong-ran-se-zhi-kai-fang-te-zheng/"/>
      <url>/2019-10-30-scale-zhun-que-jian-ding-dan-xi-bao-atac-seq-shu-ju-zhong-ran-se-zhi-kai-fang-te-zheng/</url>
      
        <content type="html"><![CDATA[<p>SCALE准确鉴定单细胞ATAC-seq数据中染色质开放特征</p><span id="more"></span><!-- toc --><p><strong>SCALE</strong>全称是Single-Cell ATAC-seq analysis vie Latent feature Extraction, 从名字中就能知道这个软件是通过隐特征提取的方式分析单细胞ATAC-seq数据。</p><p>在文章中，作者从开发者的角度列出了目前的scATAC-seq分析软件，chromVAR, scABC, cisTopic, scVI，发现每个软件都有一定的不足之处，而从我们软件使用者的角度，其实可以考虑都试试这些工具。</p><p>SCALE结合了深度生成模型(Depp Generative Models)变分自动编码器框架(Variational Autoencoder, VAE)与概率高斯混合模型(Gaussian Mixture Model, GMM)去学习隐特征，用于准确地鉴定scATAC-seq数据中的特征。</p><p>文章通过一张图来解释了软件的工作机制：</p><img src="/2019-10-30-scale-zhun-que-jian-ding-dan-xi-bao-atac-seq-shu-ju-zhong-ran-se-zhi-kai-fang-te-zheng/1.png" class=""><p>SCALE将sc-ATAC-seq的输入数据x(Cells-by-Peaks矩阵)建模成一个联合分布，</p><p>p(x,z,c)，c是GMM组件中对应的预定义的K个聚类，z是一个隐变量，是细胞在所有peak中实际可能的值，用于后续的聚类和可视化。z通过<br>z&#x3D;μz+σZ×ϵ计算而得，公式里面的 μzσz是编码器网络从x中学习而得，<br>ϵ则是从 $\mathbb(0,\mathbf)$ 抽样而成。</p><p>从公式中我们还可以发现z其实和GMM的c有关，所以p(x,z,c)也可以写成P(x|z)p(z|c)p(c)，而p(c)是K个预定义聚类分布的离散概率分布，p(z|c)服从混合高斯分布，而p(x|z)则是服从多变量伯努利分布(multivartiable Bernoulli distribution), 通过解码者网络建模而成。<br>当然从一个软件使用者的角度而言，我们不会去关心代码，也不会关心原理，我们更关心的是这个工具能做什么。SCALE能做以下的分析<br>SCALE可以对隐特征聚类识别细胞类群<br>SCALE可以降噪，恢复缺失的peak<br>SCALE能够区分批次效应和生物学细胞类群之间的差异</p><h1 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a>软件安装</h1><p>推荐使用conda的方式进行软件安装（我测试过了，运行没有问题）</p><p>第一步：创建一个环境，名字就是 <code>SCALE</code>，并且启动该环境</p><pre><code>conda create -n SCALE python=3.6 pytorchconda activate SCALE</code></pre><p>第二步：从GitHub上克隆该项目</p><pre><code>git clone git://github.com/jsxlei/SCALE.git</code></pre><p>第三步：安装SCALE</p><pre><code>cd SCALEpython setup.py install</code></pre><p>之后分析的时候，只需要通过<code>conda activate SCALE</code>就能启动分析环境。</p><p>考虑后续要交互的读取数据和可视化，那么建议再安装一个Jupyter</p><pre><code>conda install jupyter</code></pre><h1 id="软件使用"><a href="#软件使用" class="headerlink" title="软件使用"></a>软件使用</h1><p>SCALE支持两类输入文件：</p><ul><li>count矩阵，行为peak，列为barcode</li><li>10X输出文件: count.mtx.gz, peak.tsv, barcode.tsv</li></ul><p>我们以官方提供的<strong>Forebrain</strong>数据集为例进行介绍，因为这个数据相对于另外一个数据集Mouse Atlas小多了。</p><p>我们在服务器上新建一个文件夹，用于存放从<a href="https://cloud.tsinghua.edu.cn/d/bda0332212154163a647/%E4%B8%8B%E8%BD%BD%E7%9A%84%E6%95%B0%E6%8D%AE">https://cloud.tsinghua.edu.cn/d/bda0332212154163a647/下载的数据</a></p><pre><code>mkdir -p Forebrain</code></pre><p>保证Forebrain有下载好的数据</p><pre><code>$ ls Forebraindata.txt</code></pre><p>之后运行程序</p><pre><code>SCALE.py -d Forebrain/data.txt -k 8 --impute</code></pre><p>软件运行步骤为：</p><ul><li>加载数据: Loading data</li><li>模型训练: Training Model</li><li>输出结果: Saving imputed data</li></ul><p>其中模型训练这一步时间比较久，可以尝试用GPU加速（我是普通CPU服务器没有办法）。最终会在当前文件夹看到一个output文件夹，里面有如下内容:</p><ul><li><p>imputed_data.txt: 每个细胞在每个特征的推断值，建议用–binary保存二进制格式</p></li><li><p>model.pt: 用于重复结果的模型文件，–pretrain参数能够读取该模型</p></li><li><p>feature.txt: 每个细胞的隐特征，用于聚类和可视化</p></li><li><p>cluster_assignments.txt: 两列，barcode和所属类群</p></li><li><p>tsne.txt, tsne.pdf: tSNE的坐标和PDF文件，坐标文件可以导入到R语言进行可视化</p></li></ul><p>上面是命令行部分，下面则是Python环境进行交互式操作，输入jupyter notebook，之后在网页上打开</p><p>首先是导入各种Python库</p><pre><code>import pandas as pdimport numpy as npfrom sklearn.metrics import confusion_matrixfrom matplotlib import pyplot as pltimport seaborn as snsfrom scale.plot import plot_embedding, plot_heatmap</code></pre><p>然后加载分析结果，包括聚类信息和特征信息</p><pre><code>y = pd.read_csv(&#39;output/cluster_assignments.txt&#39;, sep=&#39;\t&#39;, index_col=0, header=None)[1].valuesfeature = pd.read_csv(&#39;output/feature.txt&#39;, sep=&#39;\t&#39;, index_col=0, header=None)</code></pre><p>通过热图展示不同聚类细胞之间的差异图</p><pre><code>plot_heatmap(feature.T, y,              figsize=(8, 3), cmap=&#39;RdBu_r&#39;, vmax=8, vmin=-8, center=0,             ylabel=&#39;Feature dimension&#39;, yticklabels=np.arange(10)+1,              cax_title=&#39;Feature value&#39;, legend_font=6, ncol=1,             bbox_to_anchor=(1.1, 1.1), position=(0.92, 0.15, .08, .04))</code></pre><img src="/2019-10-30-scale-zhun-que-jian-ding-dan-xi-bao-atac-seq-shu-ju-zhong-ran-se-zhi-kai-fang-te-zheng/2.png" class=""><p>如果要矫正批次效应，可以通过根据feature的heatmap，去掉和batch相关的feature来实现<br>我们可以展示SCALE对原始数据纠正后的值(imputed data), 该结果也能提高chromVAR鉴定motif的效果</p><pre><code>imputed = pd.read_csv(&#39;output/imputed_data.txt&#39;, sep=&#39;\t&#39;, index_col=0)</code></pre><p>展示聚类特异性的peak， 分析由<code>mat_specificity_score</code>和<code>cluster_specific</code>完成</p><pre><code>from scale.specifity import cluster_specific, mat_specificity_scorescore_mat = mat_specificity_score(imputed, y)peak_index, peak_labels = cluster_specific(score_mat, np.unique(y), top=200)plot_heatmap(imputed.iloc[peak_index], y=y, row_labels=peak_labels, ncol=3, cmap=&#39;Reds&#39;,              vmax=1, row_cluster=False, legend_font=6, cax_title=&#39;Peak Value&#39;,             figsize=(8, 10), bbox_to_anchor=(0.4, 1.2), position=(0.8, 0.76, 0.1, 0.015))</code></pre><img src="/2019-10-30-scale-zhun-que-jian-ding-dan-xi-bao-atac-seq-shu-ju-zhong-ran-se-zhi-kai-fang-te-zheng/3.png" class=""><h1 id="参数介绍"><a href="#参数介绍" class="headerlink" title="参数介绍"></a>参数介绍</h1><p>通过<code>SCALE.py -h</code>可以输出SCALE的所有可用参数</p><ul><li><p>-d&#x2F;–dataset: 单个文件矩阵应该指定文件路径，10X输出的多个文件则是文件目录</p></li><li><p>-k: 设定输出结果的聚类数</p></li><li><p>-o: 输出文件路径</p></li><li><p>–pretrain: 读取之前训练的模型</p></li><li><p>–lr: 修改起始学习速率, 默认是0.002，和模型训练有关</p></li><li><p>–batch_size: 批处理大小， 默认就行，不需要修改（和批次效应处理无关）</p></li><li><p>-g GPU: 选择GPU设备数目，非GPU服务器用不到</p></li><li><p>–seed: 初始随机数种子，通常在遇到nan缺失时考虑修改</p></li><li><p>-encode_dim, -decode_dim: 编码器和解码器的维度，通常也不需要修改</p></li><li><p>-latent 隐藏层维度</p></li><li><p>–low, –high: 过滤低质量的peak, 即出现比例高于或者低于某个阈值的peak，默认是0.01和0.9。作者推荐保留1万-3万的peak用于SCALE分析。如果数据质量很高，且peak数不多于10万，那么可以不过滤。</p></li><li><p>–min_peaks: 过滤低质量细胞，如果该细胞的peak低于阈值</p></li><li><p>log_transform: log2(x+1)的变换</p></li><li><p>–max_iter: 最大迭代数，默认是30000, 可以观察损失收敛的情况来修改，也就是训练模型这一步输出的信息</p></li><li><p>-weight_decay: 没有说明</p></li><li><p>–impute: 保存推断数据，默认开启</p></li><li><p>–binary: 推荐加上该参数，减少imputed data占用空间</p></li><li><p>–no_tsne: 不需要保存t-SNE结果</p></li><li><p>–reference: 参考细胞类型</p></li><li><p>-t: 如果输出矩阵是列为peak，行为barcode，用该参数进行转置</p></li></ul><p>对于使用者而言，我们一般只用修改-k更改最后的聚类数，–low, –high, —min_peaks来对原始数据进行过滤，以及加上–binary节约空间。</p><p>假如在训练模型阶段，发现输出信息为loss&#x3D;nan recon_loss&#x3D;nan kl_loss&#x3D;nan,十有八九最终会报错退出， 可以如下的参数调整</p><ul><li><p>更改–seed</p></li><li><p>用更加严格的条件过滤peak，例如-x 0.04 或 -x 0.06</p></li><li><p>降低初始的学习速率，–lr 0.0002</p></li></ul><p>ChIP-seq基本分析流程适用于ATAC-seq的前期分析。            </p>]]></content>
      
      
      <categories>
          
          <category> Single-Cell-RNA-Sequencing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> scRNA-Seq </tag>
            
            <tag> ATAC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Single Cell ATAC Install and Usage</title>
      <link href="/2019-10-30-single-cell-atac-usage/"/>
      <url>/2019-10-30-single-cell-atac-usage/</url>
      
        <content type="html"><![CDATA[<p>Single Cell ATAC Install and Usage</p><span id="more"></span><!-- toc --><h1 id="Single-Cell-ATAC-Install-and-Usage"><a href="#Single-Cell-ATAC-Install-and-Usage" class="headerlink" title="Single Cell ATAC Install and Usage"></a>Single Cell ATAC Install and Usage</h1><p>参考文献：<a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=Massively+parallel+single-cell+chromatin+landscapes+of+human+immune+cell+development+and+intratumoral+T+cell+exhaustion">Massively parallel single-cell chromatin landscapes of human immune cell development and intratumoral T cell exhaustion.Nat Biotechnol. 2019 Aug;37(8):925-936.</a></p><h2 id="System-Requirements"><a href="#System-Requirements" class="headerlink" title="System Requirements"></a>System Requirements</h2><p><strong>Hardware:</strong><br>Cell Ranger ATAC pipelines run on Linux systems that meet these minimum requirements:</p><ul><li>8-core Intel or AMD processor (16 cores recommended)</li><li>64GB RAM (128GB recommended)</li><li>1TB free disk space</li><li>64-bit CentOS&#x2F;RedHat 6.0 or Ubuntu 12.04</li></ul><p><strong>Software:</strong><br>In order to run cellranger-atac mkfastq, the following software needs to be installed:</p><ul><li>Illumina® bcl2fastq: bcl2fastq must be version 2.17 or higher. It supports most sequencers running RTA version 1.18.54 or higher. If you are using NovaSeq™, the pipelines require version 2.20 or higher. If your sequencer is running an older version of RTA, then the pipelines require bcl2fastq 1.8.4.</li></ul><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作:"></a>准备工作:</h2><h3 id="1-软件下载"><a href="#1-软件下载" class="headerlink" title="1.软件下载:"></a>1.软件下载:</h3><p>先去10xgenomics官网下载需要用到的数据和软件。因为上面提到的文章是Greenleaf教授和10xgenomics公司合作一起做的，所以前期的处理都是用cellranger-atac来做的。而且10xgenomics官网还提供了示例数据可以让我们这群菜鸡们学习。</p><p>代码直接copy：</p><pre><code>wget -O cellranger-atac-1.1.0.tar.gz &quot;http://cf.10xgenomics.com/releases/cell-atac/cellranger-atac-1.1.0.tar.gz?Expires=1572437506&amp;Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cDovL2NmLjEweGdlbm9taWNzLmNvbS9yZWxlYXNlcy9jZWxsLWF0YWMvY2VsbHJhbmdlci1hdGFjLTEuMS4wLnRhci5neiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTU3MjQzNzUwNn19fV19&amp;Signature=d23dUiAoSbRdnq3o8QfltPWgc7CfTRgA7-LzC4rC-m5kEPTKOUpCfcBT8AhWzQH-vo6pIxEc-GNGME~Yzqt9zDVFlHo-h6thslW~vCGuvgbR8Dl3F7R7iPF3p8I61EW~tyM5okumiOirqswpEXpAnHyWwU2fg2cguFfhwOSQpWuVMvebZOc70HFPskV5H6AG2EWkbpkIadfPAPfhpygV0Opn-D5V2~Oqty6c6f2y8cgASw-KYVA4azy3Gv9bFlTVOfahuFvVl0Gdbb90vWOa7Cb1HiGZwTe5N9yI1buXTLzVIuyksMr7rNG0rYncgQKxT1xedsDj9BWAcCwUjK4hrw__&amp;Key-Pair-Id=APKAI7S6A5RYOXBWRPDA&quot;</code></pre><p>解压后得到一个cellranger-atac-1.1.0的路径：</p><p>同样的，我们需要把这个路径加入到环境变量中，这样以后用的时候就会比较方便了。（建议将下面代码加入到~&#x2F;.bashrc中，这样就会永久生效了）:</p><pre><code>export PATH=~/scATAC/cellranger-atac-1.1.0:$PATH</code></pre><p>大家自行修改自己的家目录路径。<br><strong>Site Check Script:</strong></p><ul><li>Next, run the bundled site check script and send the output to 10x Genomics. We will review the information to ensure that Cell Ranger ATAC will run smoothly once you have generated your own Chromium data. Assuming you have installed Cell Ranger ATAC as described above, run the following commands.</li></ul><pre><code>$ cellranger-atac sitecheck &gt; sitecheck.txt$ cellranger-atac upload your@email.edu sitecheck.txt</code></pre><p><strong>Verify Installation:</strong></p><ul><li>To ensure that the cellranger-atac pipeline is installed correctly, use cellranger-atac testrun. This test can take up to 60 minutes on a sixteen-core workstation. Assuming you have installed Cell Ranger ATAC into &#x2F;opt, the command to run the test would look like the following:</li></ul><pre><code>cellranger-atac testrun --id=tiny cellranger-atac testrun 1.1.0Copyright (c) 2018 10x Genomics, Inc.  All rights reserved.-------------------------------------------------------------------------------Running Cell Ranger ATAC in test mode...Martian Runtime - 3.2.1Running preflight checks (please wait)...2018-09-17 20:44:33 [runtime] (ready)           ID.tiny.SC_ATAC_COUNTER_CS.SC_ATAC_COUNTER._BASIC_SC_ATAC_COUNTER._ALIGNER.SETUP_CHUNKS2018-09-17 20:44:33 [runtime] (run:local)       ID.tiny.SC_ATAC_COUNTER_CS.SC_ATAC_COUNTER._BASIC_SC_ATAC_COUNTER._ALIGNER.SETUP_CHUNKS.fork0.chnk0.main...Pipestance completed successfully!Saving diagnostics to tiny/tiny.mri.tgz</code></pre><h3 id="2-参考基因组下载"><a href="#2-参考基因组下载" class="headerlink" title="2.参考基因组下载"></a>2.参考基因组下载</h3><p><strong>GRCh38 Reference - 1.1.0 (April 16, 2019)</strong></p><ul><li>Human reference (GRCh38) dataset required for Cell Ranger ATAC.</li></ul><pre><code>wget http://cf.10xgenomics.com/supp/cell-atac/refdata-cellranger-atac-GRCh38-1.1.0.tar.gz</code></pre><p><strong>hg19 Reference - 1.1.0 (April 16, 2019)</strong></p><ul><li>Human reference (hg19) dataset required for Cell Ranger ATAC.</li></ul><pre><code>wget http://cf.10xgenomics.com/supp/cell-atac/refdata-cellranger-atac-b37-1.1.0.tar.gz</code></pre><p><strong>mm10 Reference - 1.1.0 (April 16, 2019)</strong></p><ul><li>Mouse reference (mm10) dataset required for Cell Ranger ATAC.</li></ul><pre><code>wget http://cf.10xgenomics.com/supp/cell-atac/refdata-cellranger-atac-mm10-1.1.0.tar.gz</code></pre><h3 id="示例数据下载"><a href="#示例数据下载" class="headerlink" title="示例数据下载"></a>示例数据下载</h3><p><strong>demo数据</strong>地址在：<a href="https://support.10xgenomics.com/single-cell-atac/datasets">https://support.10xgenomics.com/single-cell-atac/datasets</a></p><p>下了一个1k Peripheral blood mononuclear cells (PBMCs) from a healthy donor (v1.0)的数据:<br>代码如下：</p><pre><code>wget http://cf.10xgenomics.com/samples/cell-atac/1.1.0/atac_pbmc_1k_v1/atac_pbmc_1k_v1_fastqs.tar</code></pre><h2 id="cellranger-atac运行代码："><a href="#cellranger-atac运行代码：" class="headerlink" title="cellranger-atac运行代码："></a>cellranger-atac运行代码：</h2><p><a href="https://support.10xgenomics.com/single-cell-atac/software/pipelines/latest/using/count">官网说明贴</a></p><pre><code>cellranger-atac count         --id=ID         --fastqs=PATH         --reference=PATH         [--sample=PREFIX]        [options]                   必须参数： --id=ID：这里写上一个ID号，程序一旦运行就会生成一个同名的目录用来存放输出结果 --fastqs=PATH：这里写上你的数据位置 --reference=PATH：写上你的参考基因组文件路径 --sample=PREFIX：这里根据你的fastq文件来填写，规则和cellranger的文件命名格式有关，反正就是写“_S1”前面的一系列字符串  可选参数： --localvmem=NUM：指定程序可用的内存GB --localcores=NUM：指定程序可用的核心数</code></pre><h2 id="关于输出文件："><a href="#关于输出文件：" class="headerlink" title="关于输出文件："></a>关于输出文件：</h2><pre><code>2018-09-17 22:26:56 [runtime] (join_complete)   ID.sample345.SC_ATAC_COUNTER_CS.SC_ATAC_COUNTER.CLOUPE_PREPROCESS Outputs:- Per-barcode fragment counts &amp; metrics:        /opt/sample345/outs/singlecell.csv- Position sorted BAM file:                     /opt/sample345/outs/possorted_bam.bam- Position sorted BAM index:                    /opt/sample345/outs/possorted_bam.bam.bai- Summary of all data metrics:                  /opt/sample345/outs/summary.json- HTML file summarizing data &amp; analysis:        /opt/sample345/outs/web_summary.html- Bed file of all called peak locations:        /opt/sample345/outs/peaks.bed- Raw peak barcode matrix in hdf5 format:       /opt/sample345/outs/raw_peak_bc_matrix.h5- Raw peak barcode matrix in mex format:        /opt/sample345/outs/raw_peak_bc_matrix- Directory of analysis files:                  /opt/sample345/outs/analysis- Filtered peak barcode matrix in hdf5 format:  /opt/sample345/outs/filtered_peak_bc_matrix.h5- Filtered peak barcode matrix:                 /opt/sample345/outs/filtered_peak_bc_matrix- Barcoded and aligned fragment file:           /opt/sample345/outs/fragments.tsv.gz- Fragment file index:                          /opt/sample345/outs/fragments.tsv.gz.tbi- Filtered tf barcode matrix in hdf5 format:    /opt/sample345/outs/filtered_tf_bc_matrix.h5- Filtered tf barcode matrix in mex format:     /opt/sample345/outs/filtered_tf_bc_matrix- Loupe Cell Browser input file:                /opt/sample345/outs/cloupe.cloupe- csv summarizing important metrics and values: /opt/sample345/outs/summary.csv Pipestance completed successfully!</code></pre><p>The output of the pipeline will be contained in a folder named with the sample ID you specified (e.g. sample345). The subfolder named outs will contain the main pipeline output files:</p><table><thead><tr><th>File Name</th><th align="left">Description</th></tr></thead><tbody><tr><td>singlecell.csv</td><td align="left">Per-barcode fragment counts &amp; metrics</td></tr><tr><td>possorted_bam.bam</td><td align="left">Position sorted BAM file</td></tr><tr><td>possorted_bam.bam.bai</td><td align="left">Position sorted BAM index</td></tr><tr><td>summary.json</td><td align="left">Summary of all data metrics</td></tr><tr><td>web_summary.html</td><td align="left">HTML file summarizing data &amp; analysis</td></tr><tr><td>peaks.bed</td><td align="left">Bed file of all called peak locations</td></tr><tr><td>raw_peak_bc_matrix.h5</td><td align="left">Raw peak barcode matrix in hdf5 format</td></tr><tr><td>raw_peak_bc_matrix</td><td align="left">Raw peak barcode matrix in mex format</td></tr><tr><td>analysis</td><td align="left">Directory of analysis files</td></tr><tr><td>filtered_peak_bc_matrix.h5</td><td align="left">Filtered peak barcode matrix in hdf5 format</td></tr><tr><td>filtered_peak_bc_matrix</td><td align="left">Filtered peak barcode matrix</td></tr><tr><td>fragments.tsv.gz</td><td align="left">Barcoded and aligned fragment file</td></tr><tr><td>fragments.tsv.gz.tbi</td><td align="left">Fragment file index</td></tr><tr><td>filtered_tf_bc_matrix.h5</td><td align="left">Filtered tf barcode matrix in hdf5 format</td></tr><tr><td>filtered_tf_bc_matrix</td><td align="left">Filtered tf barcode matrix in mex format</td></tr><tr><td>cloupe.cloupe</td><td align="left">Loupe Cell Browser input file</td></tr><tr><td><strong>web_summary.html</strong></td><td align="left"></td></tr></tbody></table><ul><li>cellranger-atac和最基础的cellranger一样，也是会生成一个html的结果报表（很长，没有截全，后面分开单独展示）:<strong>Sample</strong></li><li>这一列几乎就是总结了下运行时各个文件的情况，包括文件在哪里，基因组在哪里之类的。</li></ul><p><strong>Sequencing</strong></p><ul><li>主要是一些质控的指标QC metrics</li></ul><p><strong>Cells</strong></p><ul><li>主要是关于细胞的一些metadata数据，同时提供了2个图：左图中如果峰越陡峭，则说明有细胞的油滴和没有细胞的空油滴分开的效果好。<br>右图中则展示了有细胞油滴和空油滴中捕获到的序列片段数目。</li></ul><p><strong>Cell Clustering</strong></p><ul><li>根据染色体可及性的关系做了一个细胞分群的图，有相似的染色体开放模式的细胞被分到了一群（左图）。右图：根据左图的分群情况，展示the number of unique fragments，也就是fragments 的种类数吧（不是绝对数目，而是一个种类数目。例如：一个细胞表达3个a，4个b，那么这里the number of unique fragments就是2。如果另一个细胞表达1个a，1个b，1个c，那么这里the number of unique fragments就是3），有多少种类型，就会有一个具体的数值，根据数值大小进行上色。在这个图里则是：颜色越黄，那么这群细胞中找到的fragments类型越多。</li></ul><p><strong>Insert Sizes</strong><br>这里的插入片段也就是ATAC建库时切取的片段大小。根据之前讲过的Tn5酶的原理可以知道，我们的建库时Tn5酶会把开放的染色体区域给切割，形成的片段都是以核小体为基本单位的，而每个核小体由146bp的DNA缠绕组蛋白八聚体1.75圈形成，组蛋白H1在核心颗粒外结合额外20bp DNA。</p><p>10x官网对于上面两个参数的解释是：<br><em>Fragments in nucleosome-free regions</em>：Fragments ＜147bp的片段数，因为核小体的长度为146bp，所以这个指标说的应该是那些核小体之间的连接片段。<br><em>Fragments flanking a single nucleosome</em>：147bp＜Fragments ＜294bp的片段数，这个应该是关于核小体缠绕的序列片段，加上建库时的接头序列，肯定长度要比146bp要长。</p><p><strong>Targeting</strong><br>这里参数有很多</p><ul><li><p><strong>Enrichment score of transcription start sites:</strong><br>这个值反映了染色体可及性的一个信号，对于每个细胞都会有一个这个值，但是这里只展示了一个最大值。</p></li><li><p><strong>Fraction of fragments overlapping TSS：</strong><br>测序得到的fragments 在 GENCODE 注释文件里能比对上去的比例。（如果值比较低可能是之前没人报道）</p></li><li><p><strong>Fraction of fragments overlapping called peaks：</strong><br>The fraction of fragments (that passed all filters) overlapping the  set of peaks called for the library.</p></li><li><p><strong>Fraction of fragments overlapping any targeted region:</strong><br>测序得到的fragments能够比对到 targeted regions （ transcription start sites, DNase hypersensitive regions, enhancer or promoter regions ）这些位置的比例。</p></li><li><p><strong>Fraction of total read pairs mapped confidently to genome (&gt;30 mapq)</strong><br>有着较高比对质量的 Fraction 比例</p></li><li><p><strong>Fraction of total read pairs that are unmapped and in cell barcodes</strong><br>在一定可信程度下，没能比对到参考基因组上的片段</p></li><li><p><strong>Fraction of total read pairs in mitochondria and in cell barcodes</strong><br>比对到线粒体基因上的 Fraction 比例</p></li></ul><p>关于两个图：<br>左图：TSS的具体情况<br>右图：每个点代表一个细胞。横坐标是每个细胞中的Fraction 数目，纵坐标是比对到基因组上的Fraction 百分比。<br>红色的是没有细胞的液滴，蓝色是有细胞的液滴。</p><p><strong>Library Complexity</strong><br>先看左边的3个指标：</p><ul><li><strong>Percent duplicates</strong><br>PCR重复的比例</li><li><strong>Sequencing saturation</strong><br>unique read pairs &#x2F;  estimated library complexity 算出来的一个比值</li><li><strong>Estimated bulk library complexity</strong><br>当前测序条件下，预估的测序文库的复杂度关于右图：<br>横坐标是每个细胞中的reads数目，纵坐标是每个细胞中的Fraction种类数目。</li></ul><p><strong>peak_annotation.tsv</strong></p><pre><code> $ head peak_annotation.tsv peakgenedistancepeak_type chr1_629780_630114OR4F1656559distal chr1_633810_634239OR4F1652434distal chr1_778340_779198OR4F16-91668distal chr1_827065_827882SAMD11-97856distal chr1_869626_870213SAMD11-55525distal chr1_904458_905535SAMD11-20203distal chr1_923844_923904SAMD11-1834distal chr1_941868_941942SAMD1116128distal chr1_958890_959787NOC2L0promoter</code></pre><p><strong>gene</strong>指的是找到一个离peaks最近的基因。因为我们关注的是找到motif后，当TF结合在motif后对相应基因的表达调控情况，到底是会因此该基因的过表达还是表达减弱。</p><p><strong>distance</strong>指的是peak距离那个基因的TSS（转录起始位点）的距离。负数表示在TSS上游，0表示peaks包含了TSS，正数表示在TSS下游。</p><p><strong>peak_type</strong>有3种类型，分别为 “promoter”, “distal” or “intergenic”。根据我对peak_annotation.tsv文件的探索，发现：distal型的peak一般距离TSS非常远，一般成千bp。</p><h2 id="Generating-FASTQs-with-cellranger-atac-mkfastq"><a href="#Generating-FASTQs-with-cellranger-atac-mkfastq" class="headerlink" title="Generating FASTQs with cellranger-atac mkfastq"></a>Generating FASTQs with cellranger-atac mkfastq</h2><p><strong>Table of Contents</strong></p><ul><li>Overview</li><li>Example Workflows</li><li>Arguments and Options</li><li>Example Data</li><li>Running mkfastq with a simple CSV samplesheet</li><li>Running mkfastq with an Illumina® Experiment Manager sample sheet</li><li>Checking FASTQ output</li><li>Reading Quality Control Metrics</li><li>Troubleshooting</li></ul><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a><strong>Overview</strong></h3><p>The cellranger-atac workflow starts by demultiplexing the Illumina® sequencer’s base call files (BCLs) for each flowcell directory into FASTQ files. 10x recommends using cellranger-atac mkfastq, a pipeline that wraps bcl2fastq from Illumina® and provides a number of convenient features in addition to the features of bcl2fastq:</p><ul><li>Translates 10x sample index set names into the corresponding list of four sample index oligonucleotides. For example, well A1 can be specified in the samplesheet as SI-NA-A1, and cellranger-atac mkfastq will recognize the four oligos AAACGGCG, CCTACCAT, GGCGTTTC, and TTGTAAGA and merge the resulting FASTQ files.</li><li>Supports a simplified CSV samplesheet format to handle 10x use cases.</li><li>Generates sequencing and 10x-specific quality control metrics, including barcode quality, accuracy, and diversity.</li><li>Supports most bcl2fastq arguments, such as –use-bases-mask.</li></ul><h3 id="Example-Workflows"><a href="#Example-Workflows" class="headerlink" title="Example Workflows"></a><strong>Example Workflows</strong></h3><p>In this example, we have two 10x libraries (each processed through a separate Chromium chip channel) that are multiplexed on a single flowcell. Note that after running cellranger-atac mkfastq, we run a separate instance of the pipeline on each library:</p><p>In this example, we have one 10x library sequenced on two flowcells. Note that after running cellranger-atac mkfastq, we run a single instance of the pipeline on all the FASTQ files generated:</p><h3 id="Example-Data"><a href="#Example-Data" class="headerlink" title="Example Data"></a><strong>Example Data</strong></h3><p><code>cellranger-atac mkfastq</code> recognizes two file formats for describing samples: a simple, three-column CSV format, and the Illumina® Experiment Manager (IEM) sample sheet format used by bcl2fastq. There is an example below for running <code>mkfastq</code> with each format.</p><p>To follow along, please do the following:</p><ol><li><a href="http://cf.10xgenomics.com/supp/cell-atac/cellranger-atac-tiny-bcl-1.0.0.tar.gz">Download the tiny-bcl tar file</a>.</li><li>Untar the tiny-bcl tar file in a convenient location. This will create a new tiny-bcl subdirectory.</li><li>Download the simple CSV layout file: <a href="http://cf.10xgenomics.com/supp/cell-atac/cellranger-atac-tiny-bcl-simple-1.0.0.csv">cellranger-atac-tiny-bcl-simple-1.0.0.csv</a>.</li><li>Download the Illumina® Experiment Manager sample sheet: <a href="http://cf.10xgenomics.com/supp/cell-atac/cellranger-atac-tiny-bcl-samplesheet-1.0.0.csv">cellranger-atac-tiny-bcl-samplesheet-1.0.0.csv</a>.</li></ol><h3 id="Running-mkfastq-with-a-simple-CSV-samplesheet"><a href="#Running-mkfastq-with-a-simple-CSV-samplesheet" class="headerlink" title="Running mkfastq with a simple CSV samplesheet"></a><strong>Running mkfastq with a simple CSV samplesheet</strong></h3><p><strong>We recommend the simple CSV samplesheet for most sequencing experiments.</strong> The simple CSV format has only three columns (Lane, Sample, Index), and is thus less prone to formatting errors. You can see an example of this in cellranger-atac-tiny-bcl-simple-1.0.0.csv:</p><pre><code>Lane,Sample,Index1,test_sample,SI-NA-C1</code></pre><p>Here are the options for each column:</p><ul><li><strong>Lane</strong>Which lane(s) of the flowcell to process. Can be either a single lane, a range (e.g., 2-4) or ‘*’ for all lanes in the flowcell.</li><li><strong>Sample</strong>The name of the sample. This name will be the prefix to all the generated FASTQs, and will correspond to the –sample argument in all downstream 10x pipelines.<br>Sample names must conform to the Illumina® bcl2fastq naming requirements. Only letters, numbers, underscores and hyphens are allowed; no other symbols, including dots (“.”) are allowed.</li><li><strong>Index</strong>The 10x sample index set that was used in library construction, e.g., SI-NA-A12.</li></ul><p>To run <code>mkfastq</code> with a simple layout CSV, use the <code>--csv</code> argument. Here’s how to run <code>mkfastq</code> on the <code>tiny-bcl</code> sequencing run with the simple layout:</p><pre><code>$ cellranger-atac mkfastq --id=tiny-bcl \                     --run=/path/to/tiny_bcl \                     --csv=cellranger-atac-tiny-bcl-simple-1.0.0.csv cellranger-atac mkfastqCopyright (c) 2018 10x Genomics, Inc.  All rights reserved.-------------------------------------------------------------------------------Martian Runtime - 1.1.0-3.2.1Running preflight checks (please wait)...2018-08-09 16:33:54 [runtime] (ready)           ID.tiny-bcl.MAKE_FASTQS_CS.MAKE_FASTQS.PREPARE_SAMPLESHEET2018-08-09 16:33:57 [runtime] (split_complete)  ID.tiny-bcl.MAKE_FASTQS_CS.MAKE_FASTQS.PREPARE_SAMPLESHEET2018-08-09 16:33:57 [runtime] (run:local)       ID.tiny-bcl.MAKE_FASTQS_CS.MAKE_FASTQS.PREPARE_SAMPLESHEET.fork0.chnk0.main2018-08-09 16:34:00 [runtime] (chunks_complete) ID.tiny-bcl.MAKE_FASTQS_CS.MAKE_FASTQS.PREPARE_SAMPLESHEET...</code></pre><h3 id="Running-mkfastq-with-an-Illumina®-Experiment-Manager-sample-sheet"><a href="#Running-mkfastq-with-an-Illumina®-Experiment-Manager-sample-sheet" class="headerlink" title="Running mkfastq with an Illumina® Experiment Manager sample sheet"></a><strong>Running mkfastq with an Illumina® Experiment Manager sample sheet</strong></h3><p>The <code>cellranger-atac mkfastq</code> pipeline can also be run with a samplesheet in the Illumina® Experiment Manager (IEM) format. If you didn’t sequence with an i7 index, you’ll need to use this format. Let’s briefly look at <code>cellranger-atac-tiny-bcl-samplesheet-1.0.0.csv</code> before running the pipeline. You will see a number of fields specific to running on Illumina® platforms, and then a [Data] section.</p><p>That section is where to put your sample, lane and index information. Here’s an example:</p><pre><code>[Data]Lane,Sample_ID,index,Sample_Project1,Sample1,SI-NA-C1,tiny-bcl</code></pre><p>Here, <code>SI-NA-C1</code> refers to a 10x sample index, a set of four oligo sequences. cellranger-atac mkfastq also supports listing oligo sequences explicitly.</p><p>In this example, only reads from lane 1 will be used. To demultiplex the given sample index across all lanes, omit the lanes column entirely.</p><p>Sample names must conform to the Illumina® <code>bcl2fastq</code> naming requirements. Specifcally only letters, numbers, underscores and hyphens area allowed. No other symbols, including dots (.) are allowed.</p><p>Also note that while an authentic IEM sample sheet will contain other sections above the [Data] section, these are optional for demultiplexing. For demultiplexing an existing run with <code>cellranger-atac mkfastq</code>, only the [Data] section is required.</p><p>Next, run the <code>cellranger-atac mkfastq</code> pipeline, using the <code>--samplesheet</code> argument:</p><pre><code>$ cellranger-atac mkfastq --id=tiny-bcl \                     --run=/path/to/tiny_bcl \                     --samplesheet=cellranger-atac-tiny-bcl-samplesheet-1.0.0.csv cellranger-atac mkfastqCopyright (c) 2018 10x Genomics, Inc.  All rights reserved.-------------------------------------------------------------------------------Martian Runtime - 3.2.1Running preflight checks (please wait)...2018-08-09 16:25:49 [runtime] (ready)           ID.tiny-bcl.MAKE_FASTQS_CS.MAKE_FASTQS.PREPARE_SAMPLESHEET2018-08-09 16:25:52 [runtime] (split_complete)  ID.tiny-bcl.MAKE_FASTQS_CS.MAKE_FASTQS.PREPARE_SAMPLESHEET2018-08-09 16:25:52 [runtime] (run:local)       ID.tiny-bcl.MAKE_FASTQS_CS.MAKE_FASTQS.PREPARE_SAMPLESHEET.fork0.chnk0.main2018-08-09 16:25:58 [runtime] (chunks_complete) ID.tiny-bcl.MAKE_FASTQS_CS.MAKE_FASTQS.PREPARE_SAMPLESHEET...</code></pre><h3 id="Checking-FASTQ-output"><a href="#Checking-FASTQ-output" class="headerlink" title="Checking FASTQ output"></a>Checking FASTQ output</h3><p>Once the <code>cellranger-atac mkfastq</code> pipeline has successfully completed, the output can be found in a new folder named with the value you provided to <code>cellranger-atac mkfastq</code> in the <code>--id</code> option (if not specified, defaults to the name of the flowcell):</p><pre><code>$ ls -ldrwxr-xr-x 4 jdoe  jdoe     4096 Sep 13 12:05 tiny-bcl</code></pre><p>The key output files can be found in outs&#x2F;fastq_path, and is organized in the same manner as a conventional bcl2fastq run:</p><pre><code>$ ls -l tiny-bcl/outs/fastq_path/drwxr-xr-x 3 jdoe jdoe         3 Aug  9 12:26 Reportsdrwxr-xr-x 2 jdoe jdoe         8 Aug  9 12:26 Statsdrwxr-xr-x 3 jdoe jdoe         3 Aug  9 12:26 tiny-bcl-rw-r--r-- 1 jdoe jdoe  20615106 Aug  9 12:26 Undetermined_S0_L001_I1_001.fastq.gz-rw-r--r-- 1 jdoe jdoe 151499694 Aug  9 12:26 Undetermined_S0_L001_R1_001.fastq.gz-rw-r--r-- 1 jdoe jdoe  52692701 Aug  9 12:26 Undetermined_S0_L001_R2_001.fastq.gz-rw-r--r-- 1 jdoe jdoe 151499694 Aug  9 12:26 Undetermined_S0_L001_R3_001.fastq.gz $ tree tiny-bcl/outs/fastq_path/tiny_bcl/tiny-bcl/outs/fastq_path/tiny_bcl/  Sample1    Sample1_S1_L001_I1_001.fastq.gz    Sample1_S1_L001_R1_001.fastq.gz    Sample1_S1_L001_R2_001.fastq.gz    Sample1_S1_L001_R3_001.fastq.gz</code></pre>]]></content>
      
      
      <categories>
          
          <category> Single-Cell-RNA-Sequencing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> scRNA-Seq </tag>
            
            <tag> ATAC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PCA analysis using GCAT</title>
      <link href="/2019-10-22-pca-gcat/"/>
      <url>/2019-10-22-pca-gcat/</url>
      
        <content type="html"><![CDATA[<p>PCA analysis using GCAT</p><span id="more"></span><!-- toc --><h1 id="About-GCAT"><a href="#About-GCAT" class="headerlink" title="About GCAT"></a>About GCAT</h1><p>GCAT(Genome-wide Complex Trait Analysis)在全基因组关联分析中是一款十分好用的软件，更多功能可去官网(<a href="http://cnsgenomics.com/software/gcta/#Overview)%E6%9F%A5%E7%9C%8B%E3%80%82%E5%9C%A8%E5%88%86%E6%9E%90%E7%9A%84%E6%97%B6%E5%80%99%E8%AE%A1%E7%AE%97LD%EF%BC%8CPCA%E4%BB%A5%E5%8F%8A%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90%E6%88%91%E4%BC%9A%E9%80%89%E6%8B%A9GCTA%EF%BC%8C%E4%B8%BB%E8%A6%81%E6%98%AF%E5%8F%AF%E4%BB%A5%E5%A4%9A%E7%BA%BF%E7%A8%8B%EF%BC%8C%E4%B8%94%E5%85%8D%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%EF%BC%8C%E4%BD%BF%E7%94%A8%E8%B5%B7%E6%9D%A5%E5%8D%81%E5%88%86%E6%96%B9%E4%BE%BF%E3%80%82">http://cnsgenomics.com/software/gcta/#Overview)查看。在分析的时候计算LD，PCA以及关联分析我会选择GCTA，主要是可以多线程，且免编译安装，使用起来十分方便。</a><br><strong>GCTA</strong>(Genome-wide Complex Trait Analysis) was initially designed to estimate the proportion of phenotypic variance explained by all genome-wide SNPs for complex traits (i.e., the GREML method). It has been subsequently extended for many other analyses to better understand the genetic architecture of complex traits. GCTA currently supports the following analyses:<br><strong>GRM</strong>: estimating the genetic relationships among individuals in GWAS data;<br>Estimating the inbreeding coefficients of individuals in GWAS data;<br><strong>GREML</strong>: estimating the proportion of variance in a phenotype explained by all GWAS SNPs (i.e. the SNP-based heritability);<br>Partitioning the genetic variance onto individual chromosomes, MAF bins or functional categories;<br>Estimating the genetic variance attributed to the X chromosome, and testing for the effect of dosage compensation;<br><strong>GREMLd</strong>: estimating the dominance variance in unrelated individuals using GWAS data;<br><strong>Bivariate GREML</strong>: estimating the genetic correlation between two traits (diseases) using GWAS data;<br>PCA analysis and estimation of Fst in GWAS data;<br>Computing LD scores and searching for LD friends for a list of target SNPs;<br>Simulating a phenotype based on GWAS data;<br>Conditional &amp; joint (COJO) analysis of GWAS summary statistics without individual-level genotype data;<br><strong>mtCOJO</strong>: multi-trait-based conditional &amp; joint analysis using GWAS summary data;<br><strong>GSMR</strong>: generalised summary-data-based mendelian randomisaion;<br><strong>MLMA and MLMA-LOCO</strong>: mixed linear model association analysis;<br><strong>fastBAT</strong>: gene- or set-based association analysis;<br><strong>sBLUP</strong>: summary-data based BLUP analysis for genomic risk prediction;<br>Haseman-Elston regression to estimate the the SNP-based heritability for a trait and the genetic correlation between two traits;<br><strong>fastGWA</strong>: an extremely source-efficient (mixed) linear model association tool.</p><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h1><p><strong>GCTA</strong>: A Tool for Genome-wide Complex Trait Analysis,Am J Hum Genet. 2011 Jan 7; 88(1): 76–82.(<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3014363/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3014363/</a>)</p><hr><h1 id="software"><a href="#software" class="headerlink" title="software:"></a>software:</h1><p><strong>Genome-wide Complex Trait Analysis (GCTA)</strong>(<a href="http://cnsgenomics.com/software/gcta/#Overview">http://cnsgenomics.com/software/gcta/#Overview</a>)</p><hr><h1 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h1><p>下载后添加环境变量即可使用。</p><hr><h1 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h1><p>1.首先使用plink将vcf 格式的文件转化成所以.bed，.bim，.pam结尾的输入文件。</p><pre class="line-numbers language-bash"><code class="language-bash">./plink --allow-extra-chr --out myplink_test --recode --vcf Gpan.prune.in.vcf./plink --allow-extra-chr --file myplink_test --noweb --make-bed --out tmp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2.利用GCTA进行PCA构建</p><pre class="line-numbers language-bash"><code class="language-bash">./gcta64 --bfile tmp --make-grm --autosome --out tmp./gcta64 --grm tmp --pca --out pcatmp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>3.运行玩后会生成三个文件</p><pre class="line-numbers language-bash"><code class="language-bash">-rw-r----- 1 hhu pawsey0149 1.1K Oct  5 12:32 pcatmp.log-rw-r----- 1 hhu pawsey0149 8.0K Oct  5 12:32 pcatmp.eigenval-rw-r----- 1 hhu pawsey0149  45K Oct  5 12:34 pcatmp.eigenvec<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>打开用以后续分析的pcatmp.eigenvec查看一下.</p><p>4.打开文本编辑器，将下面这一行加到分析文件的第一行中，以便后面的分析：</p><pre class="line-numbers language-bash"><code class="language-bash">ID Group PC1 PC2 PC3 <span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5.使用的R包进行可视化，这里没有具体将每个个体就行分群，我全部标记为一个组。真实的结果是根据你strcture图或者系统进化树对群体进行适当的分组，这样画出来的效果会更好，图例中PC1,PC2,PC3的值根据你生成的pcatmp.eigenval文件来。</p><pre class="line-numbers language-&#123;r"><code class="language-&#123;r">setwd("F:\\you_scripts\\gcta")library(ggplot2)#pdf(file="apvc12hweDEL46.pca_gcat.plot.pdf")data <-read.table(file="apvc12hweDEL46_gcta.eigenvec",header=T)par(mfrow<-c(3,1))ggplot(data = data, aes(x = PC1, y = PC2, group = Group)) +  geom_point(alpha = 0.5) + xlab("PC1") + ylab("PC2")ggplot(data = data, aes(x = PC1, y = PC3, group = Group)) +  geom_point(alpha = 0.5) + xlab("PC1") + ylab("PC3")ggplot(data = data, aes(x = PC2, y = PC3, group = Group)) +  geom_point(alpha = 0.5) + xlab("PC2") + ylab("PC3")#dev.off()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> PCA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PCA </tag>
            
            <tag> GCAT </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
